[build_datasets] windows: total=783  train=469  val=156  test=158

[train] dataset:
  y_mean: [[[139.28694 210.00957  82.88394]]]
  y_std : [[[ 81.20469 104.45502  49.48185]]]
  sample Y: min=-1.652e+00, max=2.854e+00, mean=-1.949e-02, std=9.796e-01

[val] dataset:
  y_mean: [[[139.28694 210.00957  82.88394]]]
  y_std : [[[ 81.20469 104.45502  49.48185]]]
  sample Y: min=-1.618e+00, max=2.854e+00, mean=5.182e-03, std=1.023e+00

[test] dataset:
  y_mean: [[[139.28694 210.00957  82.88394]]]
  y_std : [[[ 81.20469 104.45502  49.48185]]]
  sample Y: min=-1.676e+00, max=2.660e+00, mean=-8.993e-02, std=1.021e+00
âœ… Saved flux histograms in ./mnt/data/myrun_logs_deep_debug
ðŸŸ¦ Starting epoch 1/20 (train steps â‰ˆ 59)
[1864626] Î¦2FluxDeep forward: input (8, 64, 2, 324, 1, 16)
  ... step 0/59  loss=1.2665  (3.2s since last print)
  â†˜ grad L2 norm â‰ˆ 1.703e+01 (batch 0)
  ... step 2/59  loss=0.9388  (1.5s since last print)
  â†˜ grad L2 norm â‰ˆ 1.503e+01 (batch 2)
  ... step 4/59  loss=1.3179  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 1.379e+01 (batch 4)
  ... step 6/59  loss=0.5402  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 9.090e+00 (batch 6)
  ... step 8/59  loss=2.2815  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 1.967e+01 (batch 8)
  ... step 10/59  loss=1.2730  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 1.152e+01 (batch 10)
  ... step 12/59  loss=1.0111  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 1.175e+01 (batch 12)
  ... step 14/59  loss=1.1406  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 8.842e+00 (batch 14)
  ... step 16/59  loss=1.1191  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 1.390e+01 (batch 16)
  ... step 18/59  loss=1.0641  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 8.746e+00 (batch 18)
  ... step 20/59  loss=1.6253  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 9.523e+00 (batch 20)
  ... step 22/59  loss=1.0139  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 1.011e+01 (batch 22)
  ... step 24/59  loss=0.4968  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 4.472e+00 (batch 24)
  ... step 26/59  loss=0.5526  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 4.584e+00 (batch 26)
  ... step 28/59  loss=1.2635  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 1.324e+01 (batch 28)
  ... step 30/59  loss=1.5970  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 8.168e+00 (batch 30)
  ... step 32/59  loss=0.9318  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 1.097e+01 (batch 32)
  ... step 34/59  loss=0.5848  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 6.034e+00 (batch 34)
  ... step 36/59  loss=0.6326  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 5.730e+00 (batch 36)
  ... step 38/59  loss=0.4178  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 4.184e+00 (batch 38)
  ... step 40/59  loss=0.7764  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 6.108e+00 (batch 40)
  ... step 42/59  loss=0.4453  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 5.731e+00 (batch 42)
  ... step 44/59  loss=0.9330  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 1.133e+01 (batch 44)
  ... step 46/59  loss=1.7803  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 9.805e+00 (batch 46)
  ... step 48/59  loss=1.0369  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 8.788e+00 (batch 48)
  ... step 50/59  loss=1.1777  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 1.053e+01 (batch 50)
  ... step 52/59  loss=1.3154  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 7.433e+00 (batch 52)
  ... step 54/59  loss=0.8756  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 5.831e+00 (batch 54)
  ... step 56/59  loss=0.9630  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 1.065e+01 (batch 56)
  ... step 58/59  loss=0.5685  (1.3s since last print)
  â†˜ grad L2 norm â‰ˆ 7.360e+00 (batch 58)
âœ… epoch 1 forward/backward done in 68.7s
  ðŸ”Ž val step 0: batch (8, 64, 2, 324, 1, 16) loss=1.4946
[01] train=0.9835  val=1.2574  RMSE(std)=[Qi:1.093, Qe:1.144, Î“:1.126]  RMSE(phys)=[Qi:88.744, Qe:119.549, Î“:55.721]  (4.2s)
âœ… Saved unified NN â†’ ./mnt/data/bin.cgyro.nn
ðŸŸ¦ Starting epoch 2/20 (train steps â‰ˆ 59)
  ... step 0/59  loss=0.8044  (0.3s since last print)
  â†˜ grad L2 norm â‰ˆ 5.102e+00 (batch 0)
  ... step 2/59  loss=0.5680  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 6.071e+00 (batch 2)
  ... step 4/59  loss=0.9024  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 9.305e+00 (batch 4)
  ... step 6/59  loss=1.3004  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 7.353e+00 (batch 6)
  ... step 8/59  loss=1.0135  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 7.108e+00 (batch 8)
  ... step 10/59  loss=1.2555  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 1.082e+01 (batch 10)
  ... step 12/59  loss=0.8683  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 7.932e+00 (batch 12)
  ... step 14/59  loss=0.6621  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 6.027e+00 (batch 14)
  ... step 16/59  loss=0.9294  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 9.716e+00 (batch 16)
  ... step 18/59  loss=0.7086  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 7.006e+00 (batch 18)
  ... step 20/59  loss=0.9923  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 1.014e+01 (batch 20)
  ... step 22/59  loss=0.5901  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 8.367e+00 (batch 22)
  ... step 24/59  loss=0.5032  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 7.506e+00 (batch 24)
  ... step 26/59  loss=0.8382  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 1.272e+01 (batch 26)
  ... step 28/59  loss=0.3630  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 5.524e+00 (batch 28)
  ... step 30/59  loss=0.3817  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 4.570e+00 (batch 30)
  ... step 32/59  loss=0.2175  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 4.071e+00 (batch 32)
  ... step 34/59  loss=0.9000  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 1.084e+01 (batch 34)
  ... step 36/59  loss=1.0106  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 1.012e+01 (batch 36)
  ... step 38/59  loss=0.9406  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 1.087e+01 (batch 38)
  ... step 40/59  loss=0.6257  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 5.862e+00 (batch 40)
  ... step 42/59  loss=0.5526  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 5.362e+00 (batch 42)
  ... step 44/59  loss=0.4365  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 5.131e+00 (batch 44)
  ... step 46/59  loss=0.5636  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 7.032e+00 (batch 46)
  ... step 48/59  loss=0.5767  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 8.620e+00 (batch 48)
  ... step 50/59  loss=0.1831  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 3.276e+00 (batch 50)
  ... step 52/59  loss=0.7055  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 6.357e+00 (batch 52)
  ... step 54/59  loss=0.3418  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 5.018e+00 (batch 54)
  ... step 56/59  loss=0.7726  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 1.047e+01 (batch 56)
  ... step 58/59  loss=0.9872  (1.3s since last print)
  â†˜ grad L2 norm â‰ˆ 1.042e+01 (batch 58)
âœ… epoch 2 forward/backward done in 66.5s
  ðŸ”Ž val step 0: batch (8, 64, 2, 324, 1, 16) loss=5.1010
[02] train=0.7255  val=4.0051  RMSE(std)=[Qi:1.778, Qe:2.044, Î“:2.162]  RMSE(phys)=[Qi:144.408, Qe:213.519, Î“:106.982]  (4.2s)
âœ… Saved unified NN â†’ ./mnt/data/bin.cgyro.nn
ðŸŸ¦ Starting epoch 3/20 (train steps â‰ˆ 59)
  ... step 0/59  loss=0.8224  (0.3s since last print)
  â†˜ grad L2 norm â‰ˆ 8.217e+00 (batch 0)
  ... step 2/59  loss=0.5322  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 6.592e+00 (batch 2)
  ... step 4/59  loss=0.6282  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 8.677e+00 (batch 4)
  ... step 6/59  loss=0.9025  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 1.580e+01 (batch 6)
  ... step 8/59  loss=0.5646  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 6.773e+00 (batch 8)
  ... step 10/59  loss=0.7429  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 7.842e+00 (batch 10)
  ... step 12/59  loss=0.5436  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 5.175e+00 (batch 12)
  ... step 14/59  loss=0.6472  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 6.581e+00 (batch 14)
  ... step 16/59  loss=0.5911  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 6.625e+00 (batch 16)
  ... step 18/59  loss=0.2709  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 5.152e+00 (batch 18)
  ... step 20/59  loss=0.5488  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 5.755e+00 (batch 20)
  ... step 22/59  loss=0.7539  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 7.444e+00 (batch 22)
  ... step 24/59  loss=0.8249  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 8.119e+00 (batch 24)
  ... step 26/59  loss=0.5348  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 5.212e+00 (batch 26)
  ... step 28/59  loss=0.3163  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 2.884e+00 (batch 28)
  ... step 30/59  loss=1.0784  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 9.941e+00 (batch 30)
  ... step 32/59  loss=0.7072  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 7.573e+00 (batch 32)
  ... step 34/59  loss=0.4843  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 4.756e+00 (batch 34)
  ... step 36/59  loss=0.4625  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 4.813e+00 (batch 36)
  ... step 38/59  loss=0.3874  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 5.695e+00 (batch 38)
  ... step 40/59  loss=0.9433  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 7.847e+00 (batch 40)
  ... step 42/59  loss=0.3604  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 3.347e+00 (batch 42)
  ... step 44/59  loss=0.6947  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 8.796e+00 (batch 44)
  ... step 46/59  loss=0.8663  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 6.562e+00 (batch 46)
  ... step 48/59  loss=0.7766  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 1.081e+01 (batch 48)
  ... step 50/59  loss=0.7555  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 6.648e+00 (batch 50)
  ... step 52/59  loss=0.4867  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 5.260e+00 (batch 52)
  ... step 54/59  loss=0.3423  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 3.620e+00 (batch 54)
  ... step 56/59  loss=0.7190  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 6.261e+00 (batch 56)
  ... step 58/59  loss=0.1755  (1.3s since last print)
  â†˜ grad L2 norm â‰ˆ 3.682e+00 (batch 58)
âœ… epoch 3 forward/backward done in 66.5s
  ðŸ”Ž val step 0: batch (8, 64, 2, 324, 1, 16) loss=9.8841
[03] train=0.6460  val=8.7900  RMSE(std)=[Qi:2.697, Qe:2.831, Î“:3.328]  RMSE(phys)=[Qi:219.045, Qe:295.737, Î“:164.692]  (4.2s)
âœ… Saved unified NN â†’ ./mnt/data/bin.cgyro.nn
ðŸŸ¦ Starting epoch 4/20 (train steps â‰ˆ 59)
  ... step 0/59  loss=0.3060  (0.3s since last print)
  â†˜ grad L2 norm â‰ˆ 4.475e+00 (batch 0)
  ... step 2/59  loss=0.7173  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 5.889e+00 (batch 2)
  ... step 4/59  loss=0.5631  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 5.179e+00 (batch 4)
  ... step 6/59  loss=0.9142  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 5.655e+00 (batch 6)
  ... step 8/59  loss=0.2617  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 2.821e+00 (batch 8)
  ... step 10/59  loss=0.4325  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 4.713e+00 (batch 10)
  ... step 12/59  loss=0.2813  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 3.563e+00 (batch 12)
  ... step 14/59  loss=0.4266  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 3.954e+00 (batch 14)
  ... step 16/59  loss=0.3777  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 4.087e+00 (batch 16)
  ... step 18/59  loss=0.2827  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 4.390e+00 (batch 18)
  ... step 20/59  loss=0.4499  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 5.203e+00 (batch 20)
  ... step 22/59  loss=1.0250  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 8.202e+00 (batch 22)
  ... step 24/59  loss=0.8896  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 7.840e+00 (batch 24)
  ... step 26/59  loss=0.8182  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 5.383e+00 (batch 26)
  ... step 28/59  loss=0.6961  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 6.953e+00 (batch 28)
  ... step 30/59  loss=0.6507  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 7.310e+00 (batch 30)
  ... step 32/59  loss=0.3041  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 3.597e+00 (batch 32)
  ... step 34/59  loss=0.7358  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 4.933e+00 (batch 34)
  ... step 36/59  loss=0.6728  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 5.249e+00 (batch 36)
  ... step 38/59  loss=0.3737  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 3.391e+00 (batch 38)
  ... step 40/59  loss=0.2081  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 2.482e+00 (batch 40)
  ... step 42/59  loss=0.8594  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 4.720e+00 (batch 42)
  ... step 44/59  loss=0.4087  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 2.901e+00 (batch 44)
  ... step 46/59  loss=0.7206  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 6.055e+00 (batch 46)
  ... step 48/59  loss=0.4615  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 4.498e+00 (batch 48)
  ... step 50/59  loss=0.4735  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 4.067e+00 (batch 50)
  ... step 52/59  loss=0.5758  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 6.249e+00 (batch 52)
  ... step 54/59  loss=0.3261  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 4.870e+00 (batch 54)
  ... step 56/59  loss=0.4482  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 4.666e+00 (batch 56)
  ... step 58/59  loss=0.9720  (1.3s since last print)
  â†˜ grad L2 norm â‰ˆ 9.975e+00 (batch 58)
âœ… epoch 4 forward/backward done in 66.5s
  ðŸ”Ž val step 0: batch (8, 64, 2, 324, 1, 16) loss=14.2510
[04] train=0.5705  val=12.4461  RMSE(std)=[Qi:3.459, Qe:3.551, Î“:3.572]  RMSE(phys)=[Qi:280.906, Qe:370.934, Î“:176.765]  (4.2s)
âœ… Saved unified NN â†’ ./mnt/data/bin.cgyro.nn
ðŸŸ¦ Starting epoch 5/20 (train steps â‰ˆ 59)
  ... step 0/59  loss=0.6853  (0.3s since last print)
  â†˜ grad L2 norm â‰ˆ 5.396e+00 (batch 0)
  ... step 2/59  loss=1.2991  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 8.708e+00 (batch 2)
  ... step 4/59  loss=0.6037  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 5.475e+00 (batch 4)
  ... step 6/59  loss=0.5235  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 5.597e+00 (batch 6)
  ... step 8/59  loss=0.7885  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 4.996e+00 (batch 8)
  ... step 10/59  loss=0.3539  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 4.720e+00 (batch 10)
  ... step 12/59  loss=0.4606  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 3.657e+00 (batch 12)
  ... step 14/59  loss=0.2982  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 4.558e+00 (batch 14)
  ... step 16/59  loss=0.6665  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 4.700e+00 (batch 16)
  ... step 18/59  loss=0.2726  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 2.689e+00 (batch 18)
  ... step 20/59  loss=0.6523  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 5.506e+00 (batch 20)
  ... step 22/59  loss=0.4478  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 5.253e+00 (batch 22)
  ... step 24/59  loss=0.8018  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 5.629e+00 (batch 24)
  ... step 26/59  loss=0.3282  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 3.184e+00 (batch 26)
  ... step 28/59  loss=0.9914  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 5.893e+00 (batch 28)
  ... step 30/59  loss=0.3777  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 3.708e+00 (batch 30)
  ... step 32/59  loss=0.2705  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 3.255e+00 (batch 32)
  ... step 34/59  loss=0.7327  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 5.705e+00 (batch 34)
  ... step 36/59  loss=0.5032  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 3.753e+00 (batch 36)
  ... step 38/59  loss=0.8334  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 5.729e+00 (batch 38)
  ... step 40/59  loss=0.4415  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 4.409e+00 (batch 40)
  ... step 42/59  loss=0.5931  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 4.462e+00 (batch 42)
  ... step 44/59  loss=0.2899  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 3.094e+00 (batch 44)
  ... step 46/59  loss=0.4882  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 4.135e+00 (batch 46)
  ... step 48/59  loss=0.5198  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 5.274e+00 (batch 48)
  ... step 50/59  loss=1.0171  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 1.029e+01 (batch 50)
  ... step 52/59  loss=0.8356  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 6.087e+00 (batch 52)
  ... step 54/59  loss=0.4240  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 4.356e+00 (batch 54)
  ... step 56/59  loss=0.2927  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 3.308e+00 (batch 56)
  ... step 58/59  loss=0.6849  (1.3s since last print)
  â†˜ grad L2 norm â‰ˆ 6.642e+00 (batch 58)
âœ… epoch 5 forward/backward done in 66.5s
  ðŸ”Ž val step 0: batch (8, 64, 2, 324, 1, 16) loss=7.4640
[05] train=0.5314  val=6.0377  RMSE(std)=[Qi:2.520, Qe:2.428, Î“:2.422]  RMSE(phys)=[Qi:204.653, Qe:253.606, Î“:119.853]  (4.2s)
âœ… Saved unified NN â†’ ./mnt/data/bin.cgyro.nn
ðŸŸ¦ Starting epoch 6/20 (train steps â‰ˆ 59)
  ... step 0/59  loss=0.2917  (0.3s since last print)
  â†˜ grad L2 norm â‰ˆ 3.067e+00 (batch 0)
  ... step 2/59  loss=0.4321  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 3.532e+00 (batch 2)
  ... step 4/59  loss=0.8908  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 5.870e+00 (batch 4)
  ... step 6/59  loss=0.5524  (1.5s since last print)
  â†˜ grad L2 norm â‰ˆ 4.372e+00 (batch 6)
  ... step 8/59  loss=0.4061  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 5.529e+00 (batch 8)
  ... step 10/59  loss=0.6463  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 5.729e+00 (batch 10)
  ... step 12/59  loss=0.4201  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 4.265e+00 (batch 12)
  ... step 14/59  loss=0.5899  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 5.987e+00 (batch 14)
  ... step 16/59  loss=0.6336  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 5.199e+00 (batch 16)
  ... step 18/59  loss=0.2964  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 3.352e+00 (batch 18)
  ... step 20/59  loss=0.5441  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 6.562e+00 (batch 20)
  ... step 22/59  loss=0.3304  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 4.830e+00 (batch 22)
  ... step 24/59  loss=0.5308  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 3.972e+00 (batch 24)
  ... step 26/59  loss=0.5679  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 5.081e+00 (batch 26)
  ... step 28/59  loss=1.2413  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 8.160e+00 (batch 28)
  ... step 30/59  loss=0.2513  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 2.729e+00 (batch 30)
  ... step 32/59  loss=0.3940  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 4.763e+00 (batch 32)
  ... step 34/59  loss=0.3256  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 3.376e+00 (batch 34)
  ... step 36/59  loss=0.2819  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 3.663e+00 (batch 36)
  ... step 38/59  loss=0.8594  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 7.240e+00 (batch 38)
  ... step 40/59  loss=0.2859  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 3.116e+00 (batch 40)
  ... step 42/59  loss=1.0692  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 7.141e+00 (batch 42)
  ... step 44/59  loss=0.4354  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 4.228e+00 (batch 44)
  ... step 46/59  loss=0.6066  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 5.288e+00 (batch 46)
  ... step 48/59  loss=0.9145  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 8.408e+00 (batch 48)
  ... step 50/59  loss=0.9307  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 7.652e+00 (batch 50)
  ... step 52/59  loss=0.5345  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 5.261e+00 (batch 52)
  ... step 54/59  loss=0.9443  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 4.675e+00 (batch 54)
  ... step 56/59  loss=0.4567  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 5.136e+00 (batch 56)
  ... step 58/59  loss=0.4653  (1.3s since last print)
  â†˜ grad L2 norm â‰ˆ 7.697e+00 (batch 58)
âœ… epoch 6 forward/backward done in 66.5s
  ðŸ”Ž val step 0: batch (8, 64, 2, 324, 1, 16) loss=3.9420
[06] train=0.5262  val=2.9689  RMSE(std)=[Qi:1.817, Qe:1.662, Î“:1.687]  RMSE(phys)=[Qi:147.512, Qe:173.607, Î“:83.455]  (4.2s)
âœ… Saved unified NN â†’ ./mnt/data/bin.cgyro.nn
ðŸŸ¦ Starting epoch 7/20 (train steps â‰ˆ 59)
  ... step 0/59  loss=0.3078  (0.3s since last print)
  â†˜ grad L2 norm â‰ˆ 3.375e+00 (batch 0)
  ... step 2/59  loss=0.6485  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 6.393e+00 (batch 2)
  ... step 4/59  loss=0.2898  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 3.997e+00 (batch 4)
  ... step 6/59  loss=0.2560  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 2.882e+00 (batch 6)
  ... step 8/59  loss=0.3029  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 4.196e+00 (batch 8)
  ... step 10/59  loss=0.5075  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 4.289e+00 (batch 10)
  ... step 12/59  loss=0.4224  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 3.456e+00 (batch 12)
  ... step 14/59  loss=0.7867  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 4.904e+00 (batch 14)
  ... step 16/59  loss=0.4075  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 4.265e+00 (batch 16)
  ... step 18/59  loss=0.5849  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 5.876e+00 (batch 18)
  ... step 20/59  loss=0.6330  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 4.941e+00 (batch 20)
  ... step 22/59  loss=0.3784  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 5.707e+00 (batch 22)
  ... step 24/59  loss=0.6049  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 5.017e+00 (batch 24)
  ... step 26/59  loss=0.5299  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 5.682e+00 (batch 26)
  ... step 28/59  loss=0.5309  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 3.995e+00 (batch 28)
  ... step 30/59  loss=0.3681  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 3.719e+00 (batch 30)
  ... step 32/59  loss=0.8888  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 5.549e+00 (batch 32)
  ... step 34/59  loss=0.8950  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 8.826e+00 (batch 34)
  ... step 36/59  loss=0.6657  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 5.213e+00 (batch 36)
  ... step 38/59  loss=0.8307  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 4.700e+00 (batch 38)
  ... step 40/59  loss=0.2863  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 2.711e+00 (batch 40)
  ... step 42/59  loss=0.3729  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 3.001e+00 (batch 42)
  ... step 44/59  loss=0.2351  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 2.230e+00 (batch 44)
  ... step 46/59  loss=0.6059  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 6.266e+00 (batch 46)
  ... step 48/59  loss=0.6557  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 5.482e+00 (batch 48)
  ... step 50/59  loss=0.5493  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 4.025e+00 (batch 50)
  ... step 52/59  loss=0.6494  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 5.203e+00 (batch 52)
  ... step 54/59  loss=0.7729  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 4.711e+00 (batch 54)
  ... step 56/59  loss=0.6969  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 4.661e+00 (batch 56)
  ... step 58/59  loss=0.2145  (1.3s since last print)
  â†˜ grad L2 norm â‰ˆ 2.907e+00 (batch 58)
âœ… epoch 7 forward/backward done in 66.5s
  ðŸ”Ž val step 0: batch (8, 64, 2, 324, 1, 16) loss=17.3502
[07] train=0.5193  val=14.9562  RMSE(std)=[Qi:4.059, Qe:3.628, Î“:3.903]  RMSE(phys)=[Qi:329.604, Qe:378.963, Î“:193.113]  (4.2s)
âœ… Saved unified NN â†’ ./mnt/data/bin.cgyro.nn
ðŸŸ¦ Starting epoch 8/20 (train steps â‰ˆ 59)
  ... step 0/59  loss=0.2070  (0.3s since last print)
  â†˜ grad L2 norm â‰ˆ 1.669e+00 (batch 0)
  ... step 2/59  loss=0.4110  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 3.741e+00 (batch 2)
  ... step 4/59  loss=0.2251  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 2.689e+00 (batch 4)
  ... step 6/59  loss=0.2812  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 3.086e+00 (batch 6)
  ... step 8/59  loss=0.5899  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 4.420e+00 (batch 8)
  ... step 10/59  loss=0.3069  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 2.945e+00 (batch 10)
  ... step 12/59  loss=0.1872  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 1.706e+00 (batch 12)
  ... step 14/59  loss=0.3217  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 3.055e+00 (batch 14)
  ... step 16/59  loss=0.2211  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 1.970e+00 (batch 16)
  ... step 18/59  loss=0.3500  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 2.284e+00 (batch 18)
  ... step 20/59  loss=0.9066  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 5.127e+00 (batch 20)
  ... step 22/59  loss=0.7418  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 4.483e+00 (batch 22)
  ... step 24/59  loss=0.2607  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 2.023e+00 (batch 24)
  ... step 26/59  loss=0.4201  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 3.354e+00 (batch 26)
  ... step 28/59  loss=0.8693  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 4.901e+00 (batch 28)
  ... step 30/59  loss=0.6173  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 3.103e+00 (batch 30)
  ... step 32/59  loss=0.3759  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 3.018e+00 (batch 32)
  ... step 34/59  loss=0.2752  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 2.492e+00 (batch 34)
  ... step 36/59  loss=0.4586  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 3.989e+00 (batch 36)
  ... step 38/59  loss=0.2850  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 2.149e+00 (batch 38)
  ... step 40/59  loss=0.6516  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 4.255e+00 (batch 40)
  ... step 42/59  loss=0.7943  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 4.245e+00 (batch 42)
  ... step 44/59  loss=0.4127  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 2.705e+00 (batch 44)
  ... step 46/59  loss=0.2894  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 2.702e+00 (batch 46)
  ... step 48/59  loss=0.4823  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 3.567e+00 (batch 48)
  ... step 50/59  loss=0.4585  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 4.139e+00 (batch 50)
  ... step 52/59  loss=0.7005  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 4.196e+00 (batch 52)
  ... step 54/59  loss=0.2653  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 3.227e+00 (batch 54)
  ... step 56/59  loss=0.8249  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 4.085e+00 (batch 56)
  ... step 58/59  loss=0.3397  (1.3s since last print)
  â†˜ grad L2 norm â‰ˆ 3.544e+00 (batch 58)
âœ… epoch 8 forward/backward done in 66.5s
  ðŸ”Ž val step 0: batch (8, 64, 2, 324, 1, 16) loss=0.6606
[08] train=0.5047  val=0.8285  RMSE(std)=[Qi:0.910, Qe:0.919, Î“:0.901]  RMSE(phys)=[Qi:73.918, Qe:96.040, Î“:44.578]  (4.2s)
âœ… Saved unified NN â†’ ./mnt/data/bin.cgyro.nn
ðŸŸ¦ Starting epoch 9/20 (train steps â‰ˆ 59)
  ... step 0/59  loss=0.6405  (0.3s since last print)
  â†˜ grad L2 norm â‰ˆ 3.509e+00 (batch 0)
  ... step 2/59  loss=0.4594  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 3.730e+00 (batch 2)
  ... step 4/59  loss=0.5978  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 4.521e+00 (batch 4)
  ... step 6/59  loss=0.3854  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 2.808e+00 (batch 6)
  ... step 8/59  loss=0.4383  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 4.133e+00 (batch 8)
  ... step 10/59  loss=0.3339  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 3.233e+00 (batch 10)
  ... step 12/59  loss=0.4438  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 3.948e+00 (batch 12)
  ... step 14/59  loss=0.2883  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 3.783e+00 (batch 14)
  ... step 16/59  loss=0.1889  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 2.000e+00 (batch 16)
  ... step 18/59  loss=0.4178  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 3.599e+00 (batch 18)
  ... step 20/59  loss=0.4721  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 4.013e+00 (batch 20)
  ... step 22/59  loss=0.5730  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 3.676e+00 (batch 22)
  ... step 24/59  loss=0.5812  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 4.740e+00 (batch 24)
  ... step 26/59  loss=0.4861  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 3.656e+00 (batch 26)
  ... step 28/59  loss=0.5639  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 4.464e+00 (batch 28)
  ... step 30/59  loss=0.3308  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 3.017e+00 (batch 30)
  ... step 32/59  loss=0.3368  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 2.933e+00 (batch 32)
  ... step 34/59  loss=0.4990  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 3.908e+00 (batch 34)
  ... step 36/59  loss=0.5765  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 3.627e+00 (batch 36)
  ... step 38/59  loss=0.4077  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 3.061e+00 (batch 38)
  ... step 40/59  loss=0.2210  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 1.873e+00 (batch 40)
  ... step 42/59  loss=0.8155  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 4.123e+00 (batch 42)
  ... step 44/59  loss=0.5416  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 4.735e+00 (batch 44)
  ... step 46/59  loss=0.5160  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 3.870e+00 (batch 46)
  ... step 48/59  loss=0.3797  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 3.091e+00 (batch 48)
  ... step 50/59  loss=0.6014  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 5.174e+00 (batch 50)
  ... step 52/59  loss=0.6628  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 6.728e+00 (batch 52)
  ... step 54/59  loss=0.2482  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 2.898e+00 (batch 54)
  ... step 56/59  loss=0.9900  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 7.022e+00 (batch 56)
  ... step 58/59  loss=0.6964  (1.3s since last print)
  â†˜ grad L2 norm â‰ˆ 6.018e+00 (batch 58)
âœ… epoch 9 forward/backward done in 66.5s
  ðŸ”Ž val step 0: batch (8, 64, 2, 324, 1, 16) loss=0.6588
[09] train=0.4665  val=0.7335  RMSE(std)=[Qi:0.857, Qe:0.863, Î“:0.849]  RMSE(phys)=[Qi:69.589, Qe:90.154, Î“:42.022]  (4.2s)
âœ… Saved unified NN â†’ ./mnt/data/bin.cgyro.nn
ðŸŸ¦ Starting epoch 10/20 (train steps â‰ˆ 59)
  ... step 0/59  loss=0.3805  (0.3s since last print)
  â†˜ grad L2 norm â‰ˆ 3.351e+00 (batch 0)
  ... step 2/59  loss=0.5449  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 4.365e+00 (batch 2)
  ... step 4/59  loss=0.4005  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 3.535e+00 (batch 4)
  ... step 6/59  loss=0.4713  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 4.344e+00 (batch 6)
  ... step 8/59  loss=0.2872  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 2.529e+00 (batch 8)
  ... step 10/59  loss=0.2979  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 2.242e+00 (batch 10)
  ... step 12/59  loss=0.7806  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 6.103e+00 (batch 12)
  ... step 14/59  loss=0.3994  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 2.876e+00 (batch 14)
  ... step 16/59  loss=0.5352  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 4.211e+00 (batch 16)
  ... step 18/59  loss=0.4670  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 3.852e+00 (batch 18)
  ... step 20/59  loss=0.7192  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 4.894e+00 (batch 20)
  ... step 22/59  loss=0.6012  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 4.372e+00 (batch 22)
  ... step 24/59  loss=0.3633  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 3.166e+00 (batch 24)
  ... step 26/59  loss=0.5136  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 3.977e+00 (batch 26)
  ... step 28/59  loss=0.3466  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 2.622e+00 (batch 28)
  ... step 30/59  loss=0.6593  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 4.303e+00 (batch 30)
  ... step 32/59  loss=0.3505  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 2.898e+00 (batch 32)
  ... step 34/59  loss=0.2983  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 2.903e+00 (batch 34)
  ... step 36/59  loss=0.6553  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 4.356e+00 (batch 36)
  ... step 38/59  loss=0.7692  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 5.010e+00 (batch 38)
  ... step 40/59  loss=0.7812  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 4.463e+00 (batch 40)
  ... step 42/59  loss=0.2674  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 2.843e+00 (batch 42)
  ... step 44/59  loss=0.6346  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 5.423e+00 (batch 44)
  ... step 46/59  loss=0.3386  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 3.475e+00 (batch 46)
  ... step 48/59  loss=0.2610  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 2.190e+00 (batch 48)
  ... step 50/59  loss=0.3041  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 3.415e+00 (batch 50)
  ... step 52/59  loss=0.4136  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 3.014e+00 (batch 52)
  ... step 54/59  loss=0.3989  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 3.675e+00 (batch 54)
  ... step 56/59  loss=1.0118  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 5.463e+00 (batch 56)
  ... step 58/59  loss=0.7762  (1.3s since last print)
  â†˜ grad L2 norm â‰ˆ 7.081e+00 (batch 58)
âœ… epoch 10 forward/backward done in 66.5s
  ðŸ”Ž val step 0: batch (8, 64, 2, 324, 1, 16) loss=0.4681
[10] train=0.4740  val=0.4539  RMSE(std)=[Qi:0.671, Qe:0.686, Î“:0.664]  RMSE(phys)=[Qi:54.469, Qe:71.671, Î“:32.857]  (4.2s)
âœ… Saved unified NN â†’ ./mnt/data/bin.cgyro.nn
ðŸŸ¦ Starting epoch 11/20 (train steps â‰ˆ 59)
  ... step 0/59  loss=0.3685  (0.3s since last print)
  â†˜ grad L2 norm â‰ˆ 3.353e+00 (batch 0)
  ... step 2/59  loss=0.2609  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 2.567e+00 (batch 2)
  ... step 4/59  loss=0.3328  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 3.406e+00 (batch 4)
  ... step 6/59  loss=0.8453  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 4.236e+00 (batch 6)
  ... step 8/59  loss=1.3471  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 6.681e+00 (batch 8)
  ... step 10/59  loss=0.3005  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 2.999e+00 (batch 10)
  ... step 12/59  loss=0.7604  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 5.105e+00 (batch 12)
  ... step 14/59  loss=0.2991  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 2.307e+00 (batch 14)
  ... step 16/59  loss=0.2671  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 2.538e+00 (batch 16)
  ... step 18/59  loss=0.5211  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 4.067e+00 (batch 18)
  ... step 20/59  loss=0.4064  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 3.830e+00 (batch 20)
  ... step 22/59  loss=0.3405  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 3.332e+00 (batch 22)
  ... step 24/59  loss=0.3315  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 2.872e+00 (batch 24)
  ... step 26/59  loss=0.1403  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 1.255e+00 (batch 26)
  ... step 28/59  loss=0.4750  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 2.977e+00 (batch 28)
  ... step 30/59  loss=0.2000  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 1.981e+00 (batch 30)
  ... step 32/59  loss=0.3838  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 3.560e+00 (batch 32)
  ... step 34/59  loss=0.5002  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 2.960e+00 (batch 34)
  ... step 36/59  loss=0.8064  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 3.490e+00 (batch 36)
  ... step 38/59  loss=0.1502  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 1.483e+00 (batch 38)
  ... step 40/59  loss=0.3256  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 2.356e+00 (batch 40)
  ... step 42/59  loss=0.4843  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 3.360e+00 (batch 42)
  ... step 44/59  loss=0.2347  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 2.567e+00 (batch 44)
  ... step 46/59  loss=0.3102  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 2.761e+00 (batch 46)
  ... step 48/59  loss=0.5532  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 5.421e+00 (batch 48)
  ... step 50/59  loss=0.2882  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 2.188e+00 (batch 50)
  ... step 52/59  loss=0.4407  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 4.282e+00 (batch 52)
  ... step 54/59  loss=0.6474  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 3.825e+00 (batch 54)
  ... step 56/59  loss=0.6379  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 6.237e+00 (batch 56)
  ... step 58/59  loss=0.5084  (1.3s since last print)
  â†˜ grad L2 norm â‰ˆ 4.436e+00 (batch 58)
âœ… epoch 11 forward/backward done in 66.5s
  ðŸ”Ž val step 0: batch (8, 64, 2, 324, 1, 16) loss=0.4359
[11] train=0.4295  val=0.4871  RMSE(std)=[Qi:0.700, Qe:0.711, Î“:0.683]  RMSE(phys)=[Qi:56.822, Qe:74.217, Î“:33.812]  (4.2s)
âœ… Saved unified NN â†’ ./mnt/data/bin.cgyro.nn
ðŸŸ¦ Starting epoch 12/20 (train steps â‰ˆ 59)
  ... step 0/59  loss=0.4936  (0.3s since last print)
  â†˜ grad L2 norm â‰ˆ 2.881e+00 (batch 0)
  ... step 2/59  loss=0.1749  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 1.779e+00 (batch 2)
  ... step 4/59  loss=0.5161  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 4.553e+00 (batch 4)
  ... step 6/59  loss=0.3149  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 2.634e+00 (batch 6)
  ... step 8/59  loss=0.2942  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 2.955e+00 (batch 8)
  ... step 10/59  loss=0.2627  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 3.360e+00 (batch 10)
  ... step 12/59  loss=0.2255  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 3.183e+00 (batch 12)
  ... step 14/59  loss=0.4830  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 3.501e+00 (batch 14)
  ... step 16/59  loss=0.3966  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 3.647e+00 (batch 16)
  ... step 18/59  loss=0.3578  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 3.457e+00 (batch 18)
  ... step 20/59  loss=0.3872  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 4.277e+00 (batch 20)
  ... step 22/59  loss=0.2773  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 3.244e+00 (batch 22)
  ... step 24/59  loss=0.3717  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 4.022e+00 (batch 24)
  ... step 26/59  loss=0.3143  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 4.047e+00 (batch 26)
  ... step 28/59  loss=0.3470  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 3.842e+00 (batch 28)
  ... step 30/59  loss=0.3164  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 3.565e+00 (batch 30)
  ... step 32/59  loss=0.3812  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 3.662e+00 (batch 32)
  ... step 34/59  loss=0.3134  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 3.635e+00 (batch 34)
  ... step 36/59  loss=0.6230  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 3.702e+00 (batch 36)
  ... step 38/59  loss=0.4152  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 3.388e+00 (batch 38)
  ... step 40/59  loss=0.3568  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 4.138e+00 (batch 40)
  ... step 42/59  loss=0.4474  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 3.383e+00 (batch 42)
  ... step 44/59  loss=0.4817  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 3.411e+00 (batch 44)
  ... step 46/59  loss=0.2367  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 3.090e+00 (batch 46)
  ... step 48/59  loss=0.5581  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 5.583e+00 (batch 48)
  ... step 50/59  loss=0.5528  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 4.853e+00 (batch 50)
  ... step 52/59  loss=0.3137  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 3.397e+00 (batch 52)
  ... step 54/59  loss=0.8326  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 6.450e+00 (batch 54)
  ... step 56/59  loss=0.2410  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 2.475e+00 (batch 56)
  ... step 58/59  loss=0.2806  (1.3s since last print)
  â†˜ grad L2 norm â‰ˆ 2.800e+00 (batch 58)
âœ… epoch 12 forward/backward done in 66.5s
  ðŸ”Ž val step 0: batch (8, 64, 2, 324, 1, 16) loss=4.5513
[12] train=0.4254  val=3.5608  RMSE(std)=[Qi:1.896, Qe:1.837, Î“:1.927]  RMSE(phys)=[Qi:153.942, Qe:191.888, Î“:95.358]  (4.2s)
âœ… Saved unified NN â†’ ./mnt/data/bin.cgyro.nn
ðŸŸ¦ Starting epoch 13/20 (train steps â‰ˆ 59)
  ... step 0/59  loss=0.2669  (0.3s since last print)
  â†˜ grad L2 norm â‰ˆ 2.339e+00 (batch 0)
  ... step 2/59  loss=0.5860  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 4.094e+00 (batch 2)
  ... step 4/59  loss=0.4915  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 3.785e+00 (batch 4)
  ... step 6/59  loss=0.4666  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 4.975e+00 (batch 6)
  ... step 8/59  loss=0.3293  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 3.035e+00 (batch 8)
  ... step 10/59  loss=0.3551  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 3.574e+00 (batch 10)
  ... step 12/59  loss=0.2944  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 4.270e+00 (batch 12)
  ... step 14/59  loss=0.4191  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 3.904e+00 (batch 14)
  ... step 16/59  loss=0.4717  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 4.813e+00 (batch 16)
  ... step 18/59  loss=0.4465  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 3.596e+00 (batch 18)
  ... step 20/59  loss=0.2644  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 3.050e+00 (batch 20)
  ... step 22/59  loss=0.1228  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 1.669e+00 (batch 22)
  ... step 24/59  loss=0.3392  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 3.221e+00 (batch 24)
  ... step 26/59  loss=0.3447  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 3.294e+00 (batch 26)
  ... step 28/59  loss=0.3481  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 2.874e+00 (batch 28)
  ... step 30/59  loss=0.4852  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 3.197e+00 (batch 30)
  ... step 32/59  loss=0.2572  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 3.796e+00 (batch 32)
  ... step 34/59  loss=0.1945  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 2.056e+00 (batch 34)
  ... step 36/59  loss=0.3535  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 3.024e+00 (batch 36)
  ... step 38/59  loss=0.3343  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 3.366e+00 (batch 38)
  ... step 40/59  loss=0.4780  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 3.507e+00 (batch 40)
  ... step 42/59  loss=0.2906  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 2.665e+00 (batch 42)
  ... step 44/59  loss=0.1632  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 1.799e+00 (batch 44)
  ... step 46/59  loss=0.5895  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 3.632e+00 (batch 46)
  ... step 48/59  loss=0.1533  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 1.506e+00 (batch 48)
  ... step 50/59  loss=0.2611  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 2.700e+00 (batch 50)
  ... step 52/59  loss=0.2760  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 4.182e+00 (batch 52)
  ... step 54/59  loss=0.3513  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 2.382e+00 (batch 54)
  ... step 56/59  loss=0.2722  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 2.542e+00 (batch 56)
  ... step 58/59  loss=0.4640  (1.3s since last print)
  â†˜ grad L2 norm â‰ˆ 5.500e+00 (batch 58)
âœ… epoch 13 forward/backward done in 66.5s
  ðŸ”Ž val step 0: batch (8, 64, 2, 324, 1, 16) loss=3.6789
[13] train=0.3988  val=2.7843  RMSE(std)=[Qi:1.677, Qe:1.606, Î“:1.721]  RMSE(phys)=[Qi:136.155, Qe:167.760, Î“:85.163]  (4.2s)
âœ… Saved unified NN â†’ ./mnt/data/bin.cgyro.nn
ðŸŸ¦ Starting epoch 14/20 (train steps â‰ˆ 59)
  ... step 0/59  loss=0.1495  (0.3s since last print)
  â†˜ grad L2 norm â‰ˆ 1.752e+00 (batch 0)
  ... step 2/59  loss=0.4331  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 6.206e+00 (batch 2)
  ... step 4/59  loss=0.2445  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 3.348e+00 (batch 4)
  ... step 6/59  loss=0.4231  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 4.694e+00 (batch 6)
  ... step 8/59  loss=0.3123  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 3.861e+00 (batch 8)
  ... step 10/59  loss=0.2888  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 2.723e+00 (batch 10)
  ... step 12/59  loss=0.2917  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 2.633e+00 (batch 12)
  ... step 14/59  loss=0.3453  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 2.872e+00 (batch 14)
  ... step 16/59  loss=0.3201  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 3.580e+00 (batch 16)
  ... step 18/59  loss=0.8809  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 6.873e+00 (batch 18)
  ... step 20/59  loss=0.2412  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 3.555e+00 (batch 20)
  ... step 22/59  loss=0.5220  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 4.026e+00 (batch 22)
  ... step 24/59  loss=0.2506  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 2.471e+00 (batch 24)
  ... step 26/59  loss=0.3337  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 3.765e+00 (batch 26)
  ... step 28/59  loss=0.5780  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 4.140e+00 (batch 28)
  ... step 30/59  loss=0.2573  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 1.866e+00 (batch 30)
  ... step 32/59  loss=0.2985  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 3.013e+00 (batch 32)
  ... step 34/59  loss=0.5707  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 3.994e+00 (batch 34)
  ... step 36/59  loss=0.5959  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 5.075e+00 (batch 36)
  ... step 38/59  loss=0.2996  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 2.580e+00 (batch 38)
  ... step 40/59  loss=0.3806  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 1.875e+00 (batch 40)
  ... step 42/59  loss=0.4004  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 2.941e+00 (batch 42)
  ... step 44/59  loss=0.5985  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 3.346e+00 (batch 44)
  ... step 46/59  loss=0.3776  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 3.068e+00 (batch 46)
  ... step 48/59  loss=0.2139  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 1.724e+00 (batch 48)
  ... step 50/59  loss=0.3170  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 2.816e+00 (batch 50)
  ... step 52/59  loss=0.4019  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 3.225e+00 (batch 52)
  ... step 54/59  loss=0.4752  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 3.931e+00 (batch 54)
  ... step 56/59  loss=0.3731  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 2.491e+00 (batch 56)
  ... step 58/59  loss=0.3476  (1.3s since last print)
  â†˜ grad L2 norm â‰ˆ 2.967e+00 (batch 58)
âœ… epoch 14 forward/backward done in 66.5s
  ðŸ”Ž val step 0: batch (8, 64, 2, 324, 1, 16) loss=0.4112
[14] train=0.3977  val=0.4330  RMSE(std)=[Qi:0.655, Qe:0.669, Î“:0.651]  RMSE(phys)=[Qi:53.154, Qe:69.874, Î“:32.189]  (4.2s)
âœ… Saved unified NN â†’ ./mnt/data/bin.cgyro.nn
ðŸŸ¦ Starting epoch 15/20 (train steps â‰ˆ 59)
  ... step 0/59  loss=0.2046  (0.3s since last print)
  â†˜ grad L2 norm â‰ˆ 2.416e+00 (batch 0)
  ... step 2/59  loss=0.5115  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 3.358e+00 (batch 2)
  ... step 4/59  loss=0.2451  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 2.182e+00 (batch 4)
  ... step 6/59  loss=0.3448  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 3.134e+00 (batch 6)
  ... step 8/59  loss=0.3052  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 2.927e+00 (batch 8)
  ... step 10/59  loss=0.3735  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 4.030e+00 (batch 10)
  ... step 12/59  loss=0.3541  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 2.944e+00 (batch 12)
  ... step 14/59  loss=0.2501  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 2.116e+00 (batch 14)
  ... step 16/59  loss=0.3880  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 2.993e+00 (batch 16)
  ... step 18/59  loss=0.6336  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 4.430e+00 (batch 18)
  ... step 20/59  loss=0.0939  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 1.399e+00 (batch 20)
  ... step 22/59  loss=0.4242  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 3.212e+00 (batch 22)
  ... step 24/59  loss=0.5577  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 5.096e+00 (batch 24)
  ... step 26/59  loss=0.3836  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 4.042e+00 (batch 26)
  ... step 28/59  loss=0.3475  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 3.421e+00 (batch 28)
  ... step 30/59  loss=0.1957  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 2.640e+00 (batch 30)
  ... step 32/59  loss=0.3454  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 2.534e+00 (batch 32)
  ... step 34/59  loss=0.2784  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 2.309e+00 (batch 34)
  ... step 36/59  loss=0.1805  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 1.813e+00 (batch 36)
  ... step 38/59  loss=0.4410  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 4.798e+00 (batch 38)
  ... step 40/59  loss=0.5025  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 2.792e+00 (batch 40)
  ... step 42/59  loss=0.2234  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 1.804e+00 (batch 42)
  ... step 44/59  loss=0.2161  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 2.019e+00 (batch 44)
  ... step 46/59  loss=0.3359  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 2.897e+00 (batch 46)
  ... step 48/59  loss=0.4142  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 3.977e+00 (batch 48)
  ... step 50/59  loss=0.3564  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 3.154e+00 (batch 50)
  ... step 52/59  loss=0.6112  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 4.429e+00 (batch 52)
  ... step 54/59  loss=0.3141  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 2.648e+00 (batch 54)
  ... step 56/59  loss=0.4236  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 3.280e+00 (batch 56)
  ... step 58/59  loss=0.3786  (1.3s since last print)
  â†˜ grad L2 norm â‰ˆ 3.116e+00 (batch 58)
âœ… epoch 15 forward/backward done in 66.5s
  ðŸ”Ž val step 0: batch (8, 64, 2, 324, 1, 16) loss=0.5982
[15] train=0.3507  val=0.5950  RMSE(std)=[Qi:0.769, Qe:0.779, Î“:0.765]  RMSE(phys)=[Qi:62.466, Qe:81.401, Î“:37.875]  (4.2s)
âœ… Saved unified NN â†’ ./mnt/data/bin.cgyro.nn
ðŸŸ¦ Starting epoch 16/20 (train steps â‰ˆ 59)
  ... step 0/59  loss=0.3744  (0.3s since last print)
  â†˜ grad L2 norm â‰ˆ 3.541e+00 (batch 0)
  ... step 2/59  loss=0.4269  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 3.569e+00 (batch 2)
  ... step 4/59  loss=0.1923  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 1.530e+00 (batch 4)
  ... step 6/59  loss=0.3279  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 3.752e+00 (batch 6)
  ... step 8/59  loss=0.2113  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 2.081e+00 (batch 8)
  ... step 10/59  loss=0.0842  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 9.401e-01 (batch 10)
  ... step 12/59  loss=0.2791  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 2.964e+00 (batch 12)
  ... step 14/59  loss=0.2906  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 2.751e+00 (batch 14)
  ... step 16/59  loss=0.6816  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 6.757e+00 (batch 16)
  ... step 18/59  loss=0.3743  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 3.542e+00 (batch 18)
  ... step 20/59  loss=0.4393  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 4.020e+00 (batch 20)
  ... step 22/59  loss=0.1942  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 2.702e+00 (batch 22)
  ... step 24/59  loss=0.7562  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 3.625e+00 (batch 24)
  ... step 26/59  loss=0.2757  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 2.871e+00 (batch 26)
  ... step 28/59  loss=0.6701  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 3.848e+00 (batch 28)
  ... step 30/59  loss=0.1944  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 1.794e+00 (batch 30)
  ... step 32/59  loss=0.3710  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 4.243e+00 (batch 32)
  ... step 34/59  loss=0.4956  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 3.799e+00 (batch 34)
  ... step 36/59  loss=0.4572  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 3.913e+00 (batch 36)
  ... step 38/59  loss=0.3001  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 2.433e+00 (batch 38)
  ... step 40/59  loss=0.4565  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 3.878e+00 (batch 40)
  ... step 42/59  loss=0.3128  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 3.463e+00 (batch 42)
  ... step 44/59  loss=0.3289  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 3.056e+00 (batch 44)
  ... step 46/59  loss=0.2470  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 2.575e+00 (batch 46)
  ... step 48/59  loss=0.1932  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 3.090e+00 (batch 48)
  ... step 50/59  loss=0.2867  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 3.156e+00 (batch 50)
  ... step 52/59  loss=0.3981  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 4.082e+00 (batch 52)
  ... step 54/59  loss=0.3807  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 3.434e+00 (batch 54)
  ... step 56/59  loss=0.3121  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 2.283e+00 (batch 56)
  ... step 58/59  loss=0.3369  (1.3s since last print)
  â†˜ grad L2 norm â‰ˆ 4.177e+00 (batch 58)
âœ… epoch 16 forward/backward done in 66.5s
  ðŸ”Ž val step 0: batch (8, 64, 2, 324, 1, 16) loss=0.6566
[16] train=0.3409  val=0.7935  RMSE(std)=[Qi:0.893, Qe:0.896, Î“:0.884]  RMSE(phys)=[Qi:72.484, Qe:93.564, Î“:43.743]  (4.2s)
âœ… Saved unified NN â†’ ./mnt/data/bin.cgyro.nn
ðŸŸ¦ Starting epoch 17/20 (train steps â‰ˆ 59)
  ... step 0/59  loss=0.1696  (0.3s since last print)
  â†˜ grad L2 norm â‰ˆ 2.465e+00 (batch 0)
  ... step 2/59  loss=0.3100  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 3.747e+00 (batch 2)
  ... step 4/59  loss=0.2331  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 2.846e+00 (batch 4)
  ... step 6/59  loss=0.4917  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 3.612e+00 (batch 6)
  ... step 8/59  loss=0.3478  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 2.732e+00 (batch 8)
  ... step 10/59  loss=0.2901  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 3.480e+00 (batch 10)
  ... step 12/59  loss=0.2321  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 2.022e+00 (batch 12)
  ... step 14/59  loss=0.4605  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 4.022e+00 (batch 14)
  ... step 16/59  loss=0.2993  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 3.555e+00 (batch 16)
  ... step 18/59  loss=0.1912  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 2.813e+00 (batch 18)
  ... step 20/59  loss=0.1151  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 1.482e+00 (batch 20)
  ... step 22/59  loss=0.4185  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 3.846e+00 (batch 22)
  ... step 24/59  loss=0.2544  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 1.853e+00 (batch 24)
  ... step 26/59  loss=0.3190  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 2.618e+00 (batch 26)
  ... step 28/59  loss=0.2755  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 2.203e+00 (batch 28)
  ... step 30/59  loss=0.5836  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 4.993e+00 (batch 30)
  ... step 32/59  loss=0.2066  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 2.273e+00 (batch 32)
  ... step 34/59  loss=0.2596  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 2.965e+00 (batch 34)
  ... step 36/59  loss=0.1675  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 2.505e+00 (batch 36)
  ... step 38/59  loss=0.2094  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 2.509e+00 (batch 38)
  ... step 40/59  loss=0.4877  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 4.726e+00 (batch 40)
  ... step 42/59  loss=0.2675  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 2.513e+00 (batch 42)
  ... step 44/59  loss=0.4028  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 3.962e+00 (batch 44)
  ... step 46/59  loss=0.5212  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 6.666e+00 (batch 46)
  ... step 48/59  loss=0.2335  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 1.990e+00 (batch 48)
  ... step 50/59  loss=0.5180  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 5.289e+00 (batch 50)
  ... step 52/59  loss=0.2469  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 3.604e+00 (batch 52)
  ... step 54/59  loss=0.5792  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 4.555e+00 (batch 54)
  ... step 56/59  loss=0.4585  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 3.962e+00 (batch 56)
  ... step 58/59  loss=0.4506  (1.3s since last print)
  â†˜ grad L2 norm â‰ˆ 3.857e+00 (batch 58)
âœ… epoch 17 forward/backward done in 66.5s
  ðŸ”Ž val step 0: batch (8, 64, 2, 324, 1, 16) loss=0.4574
[17] train=0.3465  val=0.3807  RMSE(std)=[Qi:0.614, Qe:0.630, Î“:0.606]  RMSE(phys)=[Qi:49.895, Qe:65.851, Î“:29.979]  (4.2s)
âœ… Saved unified NN â†’ ./mnt/data/bin.cgyro.nn
ðŸŸ¦ Starting epoch 18/20 (train steps â‰ˆ 59)
  ... step 0/59  loss=0.2102  (0.3s since last print)
  â†˜ grad L2 norm â‰ˆ 2.033e+00 (batch 0)
  ... step 2/59  loss=0.6064  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 3.834e+00 (batch 2)
  ... step 4/59  loss=0.2650  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 2.919e+00 (batch 4)
  ... step 6/59  loss=0.3421  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 3.903e+00 (batch 6)
  ... step 8/59  loss=0.2027  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 2.432e+00 (batch 8)
  ... step 10/59  loss=0.2177  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 2.168e+00 (batch 10)
  ... step 12/59  loss=0.2586  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 3.092e+00 (batch 12)
  ... step 14/59  loss=0.3092  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 2.981e+00 (batch 14)
  ... step 16/59  loss=0.3448  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 3.272e+00 (batch 16)
  ... step 18/59  loss=0.2125  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 2.419e+00 (batch 18)
  ... step 20/59  loss=0.2480  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 2.871e+00 (batch 20)
  ... step 22/59  loss=0.1900  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 2.032e+00 (batch 22)
  ... step 24/59  loss=0.3198  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 3.703e+00 (batch 24)
  ... step 26/59  loss=0.5246  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 4.171e+00 (batch 26)
  ... step 28/59  loss=0.4190  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 3.358e+00 (batch 28)
  ... step 30/59  loss=0.3264  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 3.829e+00 (batch 30)
  ... step 32/59  loss=0.2339  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 3.050e+00 (batch 32)
  ... step 34/59  loss=0.1689  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 2.325e+00 (batch 34)
  ... step 36/59  loss=0.2460  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 2.776e+00 (batch 36)
  ... step 38/59  loss=0.1786  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 2.632e+00 (batch 38)
  ... step 40/59  loss=0.2076  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 2.255e+00 (batch 40)
  ... step 42/59  loss=0.1942  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 2.628e+00 (batch 42)
  ... step 44/59  loss=0.4994  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 5.476e+00 (batch 44)
  ... step 46/59  loss=0.3339  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 3.028e+00 (batch 46)
  ... step 48/59  loss=0.2621  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 2.947e+00 (batch 48)
  ... step 50/59  loss=0.2815  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 3.399e+00 (batch 50)
  ... step 52/59  loss=0.1958  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 2.380e+00 (batch 52)
  ... step 54/59  loss=0.3700  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 3.836e+00 (batch 54)
  ... step 56/59  loss=0.1670  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 3.637e+00 (batch 56)
  ... step 58/59  loss=0.5532  (1.3s since last print)
  â†˜ grad L2 norm â‰ˆ 7.692e+00 (batch 58)
âœ… epoch 18 forward/backward done in 66.5s
  ðŸ”Ž val step 0: batch (8, 64, 2, 324, 1, 16) loss=2.7948
[18] train=0.2891  val=2.3091  RMSE(std)=[Qi:1.532, Qe:1.493, Î“:1.533]  RMSE(phys)=[Qi:124.390, Qe:155.999, Î“:75.860]  (4.2s)
âœ… Saved unified NN â†’ ./mnt/data/bin.cgyro.nn
ðŸŸ¦ Starting epoch 19/20 (train steps â‰ˆ 59)
  ... step 0/59  loss=0.3843  (0.3s since last print)
  â†˜ grad L2 norm â‰ˆ 4.135e+00 (batch 0)
  ... step 2/59  loss=0.1989  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 2.311e+00 (batch 2)
  ... step 4/59  loss=0.3261  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 3.064e+00 (batch 4)
  ... step 6/59  loss=0.4896  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 4.142e+00 (batch 6)
  ... step 8/59  loss=0.3353  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 3.063e+00 (batch 8)
  ... step 10/59  loss=0.3436  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 3.385e+00 (batch 10)
  ... step 12/59  loss=0.3224  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 5.115e+00 (batch 12)
  ... step 14/59  loss=0.3531  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 4.245e+00 (batch 14)
  ... step 16/59  loss=0.6101  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 5.005e+00 (batch 16)
  ... step 18/59  loss=0.3183  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 2.822e+00 (batch 18)
  ... step 20/59  loss=0.1995  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 2.071e+00 (batch 20)
  ... step 22/59  loss=0.2151  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 2.092e+00 (batch 22)
  ... step 24/59  loss=0.2499  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 2.888e+00 (batch 24)
  ... step 26/59  loss=0.1942  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 2.095e+00 (batch 26)
  ... step 28/59  loss=0.2512  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 2.799e+00 (batch 28)
  ... step 30/59  loss=0.3697  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 3.637e+00 (batch 30)
  ... step 32/59  loss=0.3669  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 2.863e+00 (batch 32)
  ... step 34/59  loss=0.4455  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 3.174e+00 (batch 34)
  ... step 36/59  loss=0.2069  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 1.902e+00 (batch 36)
  ... step 38/59  loss=0.4473  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 3.732e+00 (batch 38)
  ... step 40/59  loss=0.2116  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 2.576e+00 (batch 40)
  ... step 42/59  loss=0.2414  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 2.134e+00 (batch 42)
  ... step 44/59  loss=0.3553  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 3.123e+00 (batch 44)
  ... step 46/59  loss=0.3302  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 3.136e+00 (batch 46)
  ... step 48/59  loss=0.1149  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 1.635e+00 (batch 48)
  ... step 50/59  loss=0.3148  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 2.590e+00 (batch 50)
  ... step 52/59  loss=0.1745  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 1.985e+00 (batch 52)
  ... step 54/59  loss=0.3031  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 2.537e+00 (batch 54)
  ... step 56/59  loss=0.4355  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 5.013e+00 (batch 56)
  ... step 58/59  loss=0.3424  (1.3s since last print)
  â†˜ grad L2 norm â‰ˆ 4.856e+00 (batch 58)
âœ… epoch 19 forward/backward done in 66.5s
  ðŸ”Ž val step 0: batch (8, 64, 2, 324, 1, 16) loss=0.5555
[19] train=0.3079  val=0.5199  RMSE(std)=[Qi:0.719, Qe:0.734, Î“:0.710]  RMSE(phys)=[Qi:58.413, Qe:76.637, Î“:35.132]  (4.2s)
âœ… Saved unified NN â†’ ./mnt/data/bin.cgyro.nn
ðŸŸ¦ Starting epoch 20/20 (train steps â‰ˆ 59)
  ... step 0/59  loss=0.2836  (0.3s since last print)
  â†˜ grad L2 norm â‰ˆ 3.080e+00 (batch 0)
  ... step 2/59  loss=0.2536  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 2.693e+00 (batch 2)
  ... step 4/59  loss=0.2211  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 2.693e+00 (batch 4)
  ... step 6/59  loss=0.2200  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 2.317e+00 (batch 6)
  ... step 8/59  loss=0.3121  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 2.581e+00 (batch 8)
  ... step 10/59  loss=0.3833  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 4.750e+00 (batch 10)
  ... step 12/59  loss=0.2196  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 2.425e+00 (batch 12)
  ... step 14/59  loss=0.2357  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 2.638e+00 (batch 14)
  ... step 16/59  loss=0.3182  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 3.486e+00 (batch 16)
  ... step 18/59  loss=0.2213  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 2.347e+00 (batch 18)
  ... step 20/59  loss=0.2290  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 2.976e+00 (batch 20)
  ... step 22/59  loss=0.5997  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 9.786e+00 (batch 22)
  ... step 24/59  loss=0.4548  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 5.315e+00 (batch 24)
  ... step 26/59  loss=0.2780  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 4.310e+00 (batch 26)
  ... step 28/59  loss=0.5235  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 4.757e+00 (batch 28)
  ... step 30/59  loss=0.3319  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 3.839e+00 (batch 30)
  ... step 32/59  loss=0.0983  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 1.647e+00 (batch 32)
  ... step 34/59  loss=0.3464  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 3.432e+00 (batch 34)
  ... step 36/59  loss=0.1318  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 2.832e+00 (batch 36)
  ... step 38/59  loss=0.2168  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 2.227e+00 (batch 38)
  ... step 40/59  loss=0.5088  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 5.334e+00 (batch 40)
  ... step 42/59  loss=0.4196  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 3.548e+00 (batch 42)
  ... step 44/59  loss=0.1771  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 1.721e+00 (batch 44)
  ... step 46/59  loss=0.1981  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 2.579e+00 (batch 46)
  ... step 48/59  loss=0.2834  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 2.075e+00 (batch 48)
  ... step 50/59  loss=0.5380  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 5.111e+00 (batch 50)
  ... step 52/59  loss=0.4562  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 3.337e+00 (batch 52)
  ... step 54/59  loss=0.2540  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 3.518e+00 (batch 54)
  ... step 56/59  loss=0.4963  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 4.259e+00 (batch 56)
  ... step 58/59  loss=0.4539  (1.3s since last print)
  â†˜ grad L2 norm â‰ˆ 3.484e+00 (batch 58)
âœ… epoch 20 forward/backward done in 66.5s
  ðŸ”Ž val step 0: batch (8, 64, 2, 324, 1, 16) loss=0.2661
[20] train=0.3030  val=0.2528  RMSE(std)=[Qi:0.501, Qe:0.515, Î“:0.491]  RMSE(phys)=[Qi:40.688, Qe:53.835, Î“:24.320]  (4.2s)
âœ… Saved unified NN â†’ ./mnt/data/bin.cgyro.nn
Saved metrics â†’ ./mnt/data/myrun_logs_deep_debug/metrics.csv
âœ… Final unified NN â†’ ./mnt/data/bin.cgyro.nn
âœ… Training complete. Artifacts in: ./mnt/data/myrun_logs_deep_debug
