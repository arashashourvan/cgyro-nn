[build_datasets] windows: total=815  train=489  val=163  test=163

[train] dataset:
  y_mean: [[[134.60855 203.21703  80.05728]]]
  y_std : [[[ 85.10512 110.49066  51.77117]]]
  sample Y: min=-1.763e+00, max=2.779e+00, mean=1.555e-02, std=1.035e+00

[val] dataset:
  y_mean: [[[134.60855 203.21703  80.05728]]]
  y_std : [[[ 85.10512 110.49066  51.77117]]]
  sample Y: min=-1.756e+00, max=2.662e+00, mean=-1.294e-01, std=9.179e-01

[test] dataset:
  y_mean: [[[134.60855 203.21703  80.05728]]]
  y_std : [[[ 85.10512 110.49066  51.77117]]]
  sample Y: min=-1.765e+00, max=2.763e+00, mean=2.595e-02, std=1.020e+00
âœ… Saved flux histograms in ./mnt/data/myrun_logs_deep_debug
ğŸŸ¦ Starting epoch 1/20 (train steps â‰ˆ 31)
[1484608] Î¦2FluxDeep forward: input (16, 32, 2, 324, 1, 16)
  ... step 0/31  loss=1.2694  (3.2s since last print)
  â†˜ grad L2 norm â‰ˆ 1.007e+01 (batch 0)
  ... step 2/31  loss=0.7737  (1.5s since last print)
  â†˜ grad L2 norm â‰ˆ 5.903e+00 (batch 2)
  ... step 4/31  loss=0.9800  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 5.871e+00 (batch 4)
  ... step 6/31  loss=1.0962  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 4.816e+00 (batch 6)
  ... step 8/31  loss=1.0668  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 5.507e+00 (batch 8)
  ... step 10/31  loss=0.7413  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 3.441e+00 (batch 10)
  ... step 12/31  loss=0.7281  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 3.900e+00 (batch 12)
  ... step 14/31  loss=0.8757  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 5.663e+00 (batch 14)
  ... step 16/31  loss=0.5193  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 3.576e+00 (batch 16)
  ... step 18/31  loss=0.6257  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 3.479e+00 (batch 18)
  ... step 20/31  loss=0.7861  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 4.957e+00 (batch 20)
  ... step 22/31  loss=0.7470  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 4.602e+00 (batch 22)
  ... step 24/31  loss=1.1078  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 7.678e+00 (batch 24)
  ... step 26/31  loss=0.5254  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 4.022e+00 (batch 26)
  ... step 28/31  loss=0.8104  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 4.794e+00 (batch 28)
  ... step 30/31  loss=1.4392  (1.3s since last print)
  â†˜ grad L2 norm â‰ˆ 5.533e+00 (batch 30)
âœ… epoch 1 forward/backward done in 36.8s
  ğŸ” val step 0: batch (16, 32, 2, 324, 1, 16) loss=1.2262
[01] train=0.8370  val=2.0433  RMSE(std)=[Qi:1.438, Qe:1.478, Î“:1.370]  RMSE(phys)=[Qi:122.374, Qe:163.314, Î“:70.938]  (2.2s)
âœ… Saved unified NN â†’ ./mnt/data/bin.cgyro.nn
ğŸŸ¦ Starting epoch 2/20 (train steps â‰ˆ 31)
  ... step 0/31  loss=0.5581  (0.3s since last print)
  â†˜ grad L2 norm â‰ˆ 3.199e+00 (batch 0)
  ... step 2/31  loss=0.5152  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 3.126e+00 (batch 2)
  ... step 4/31  loss=0.7994  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 2.904e+00 (batch 4)
  ... step 6/31  loss=0.4171  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 1.898e+00 (batch 6)
  ... step 8/31  loss=0.8773  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 3.201e+00 (batch 8)
  ... step 10/31  loss=0.7077  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 2.555e+00 (batch 10)
  ... step 12/31  loss=0.3651  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 1.877e+00 (batch 12)
  ... step 14/31  loss=0.6172  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 2.528e+00 (batch 14)
  ... step 16/31  loss=0.7808  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 2.558e+00 (batch 16)
  ... step 18/31  loss=0.8515  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 2.514e+00 (batch 18)
  ... step 20/31  loss=0.4640  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 1.708e+00 (batch 20)
  ... step 22/31  loss=0.9810  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 2.522e+00 (batch 22)
  ... step 24/31  loss=0.7555  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 1.831e+00 (batch 24)
  ... step 26/31  loss=0.5014  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 2.032e+00 (batch 26)
  ... step 28/31  loss=0.6869  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 1.776e+00 (batch 28)
  ... step 30/31  loss=0.6363  (1.3s since last print)
  â†˜ grad L2 norm â‰ˆ 2.242e+00 (batch 30)
âœ… epoch 2 forward/backward done in 34.7s
  ğŸ” val step 0: batch (16, 32, 2, 324, 1, 16) loss=65.6810
[02] train=0.6399  val=62.6757  RMSE(std)=[Qi:7.007, Qe:8.833, Î“:7.804]  RMSE(phys)=[Qi:596.345, Qe:975.949, Î“:404.039]  (2.2s)
âœ… Saved unified NN â†’ ./mnt/data/bin.cgyro.nn
ğŸŸ¦ Starting epoch 3/20 (train steps â‰ˆ 31)
  ... step 0/31  loss=0.4349  (0.3s since last print)
  â†˜ grad L2 norm â‰ˆ 1.377e+00 (batch 0)
  ... step 2/31  loss=0.7417  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 2.896e+00 (batch 2)
  ... step 4/31  loss=0.4935  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 1.365e+00 (batch 4)
  ... step 6/31  loss=0.8742  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 2.535e+00 (batch 6)
  ... step 8/31  loss=0.4535  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 1.360e+00 (batch 8)
  ... step 10/31  loss=0.7692  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 2.583e+00 (batch 10)
  ... step 12/31  loss=0.4687  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 2.419e+00 (batch 12)
  ... step 14/31  loss=0.5603  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 2.663e+00 (batch 14)
  ... step 16/31  loss=0.6387  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 2.287e+00 (batch 16)
  ... step 18/31  loss=0.2847  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 9.999e-01 (batch 18)
  ... step 20/31  loss=0.6151  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 1.879e+00 (batch 20)
  ... step 22/31  loss=0.7006  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 2.702e+00 (batch 22)
  ... step 24/31  loss=0.5106  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 1.914e+00 (batch 24)
  ... step 26/31  loss=0.3437  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 1.246e+00 (batch 26)
  ... step 28/31  loss=0.5661  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 1.579e+00 (batch 28)
  ... step 30/31  loss=0.6378  (1.3s since last print)
  â†˜ grad L2 norm â‰ˆ 2.539e+00 (batch 30)
âœ… epoch 3 forward/backward done in 34.7s
  ğŸ” val step 0: batch (16, 32, 2, 324, 1, 16) loss=10.2122
[03] train=0.5539  val=9.0985  RMSE(std)=[Qi:2.959, Qe:3.079, Î“:3.011]  RMSE(phys)=[Qi:251.808, Qe:340.148, Î“:155.863]  (2.2s)
âœ… Saved unified NN â†’ ./mnt/data/bin.cgyro.nn
ğŸŸ¦ Starting epoch 4/20 (train steps â‰ˆ 31)
  ... step 0/31  loss=0.7572  (0.3s since last print)
  â†˜ grad L2 norm â‰ˆ 2.433e+00 (batch 0)
  ... step 2/31  loss=0.2758  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 1.087e+00 (batch 2)
  ... step 4/31  loss=0.5152  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 1.730e+00 (batch 4)
  ... step 6/31  loss=0.2367  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 1.352e+00 (batch 6)
  ... step 8/31  loss=0.2158  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 1.078e+00 (batch 8)
  ... step 10/31  loss=0.6184  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 2.508e+00 (batch 10)
  ... step 12/31  loss=0.3978  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 1.714e+00 (batch 12)
  ... step 14/31  loss=0.6633  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 2.845e+00 (batch 14)
  ... step 16/31  loss=0.6083  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 1.998e+00 (batch 16)
  ... step 18/31  loss=0.4830  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 1.765e+00 (batch 18)
  ... step 20/31  loss=0.6674  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 2.587e+00 (batch 20)
  ... step 22/31  loss=0.3741  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 2.258e+00 (batch 22)
  ... step 24/31  loss=0.2854  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 1.135e+00 (batch 24)
  ... step 26/31  loss=0.5291  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 2.067e+00 (batch 26)
  ... step 28/31  loss=0.4266  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 1.198e+00 (batch 28)
  ... step 30/31  loss=0.3785  (1.3s since last print)
  â†˜ grad L2 norm â‰ˆ 1.597e+00 (batch 30)
âœ… epoch 4 forward/backward done in 34.7s
  ğŸ” val step 0: batch (16, 32, 2, 324, 1, 16) loss=27.4750
[04] train=0.5236  val=25.6146  RMSE(std)=[Qi:4.577, Qe:5.357, Î“:5.215]  RMSE(phys)=[Qi:389.557, Qe:591.866, Î“:269.992]  (2.2s)
âœ… Saved unified NN â†’ ./mnt/data/bin.cgyro.nn
ğŸŸ¦ Starting epoch 5/20 (train steps â‰ˆ 31)
  ... step 0/31  loss=0.4719  (0.3s since last print)
  â†˜ grad L2 norm â‰ˆ 1.444e+00 (batch 0)
  ... step 2/31  loss=0.4869  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 1.748e+00 (batch 2)
  ... step 4/31  loss=0.4047  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 1.758e+00 (batch 4)
  ... step 6/31  loss=0.8508  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 2.417e+00 (batch 6)
  ... step 8/31  loss=0.5183  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 2.121e+00 (batch 8)
  ... step 10/31  loss=0.6846  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 2.152e+00 (batch 10)
  ... step 12/31  loss=0.6839  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 1.849e+00 (batch 12)
  ... step 14/31  loss=0.4123  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 1.233e+00 (batch 14)
  ... step 16/31  loss=0.6643  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 1.475e+00 (batch 16)
  ... step 18/31  loss=0.6866  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 1.535e+00 (batch 18)
  ... step 20/31  loss=0.4486  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 1.217e+00 (batch 20)
  ... step 22/31  loss=0.1953  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 7.787e-01 (batch 22)
  ... step 24/31  loss=0.3605  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 1.197e+00 (batch 24)
  ... step 26/31  loss=0.5341  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 1.851e+00 (batch 26)
  ... step 28/31  loss=0.5296  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 1.930e+00 (batch 28)
  ... step 30/31  loss=0.7769  (1.3s since last print)
  â†˜ grad L2 norm â‰ˆ 2.400e+00 (batch 30)
âœ… epoch 5 forward/backward done in 34.7s
  ğŸ” val step 0: batch (16, 32, 2, 324, 1, 16) loss=10.5272
[05] train=0.5101  val=9.3196  RMSE(std)=[Qi:2.864, Qe:3.233, Î“:3.049]  RMSE(phys)=[Qi:243.780, Qe:357.266, Î“:157.867]  (2.2s)
âœ… Saved unified NN â†’ ./mnt/data/bin.cgyro.nn
ğŸŸ¦ Starting epoch 6/20 (train steps â‰ˆ 31)
  ... step 0/31  loss=0.2449  (0.3s since last print)
  â†˜ grad L2 norm â‰ˆ 9.969e-01 (batch 0)
  ... step 2/31  loss=0.5047  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 2.034e+00 (batch 2)
  ... step 4/31  loss=0.6242  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 2.594e+00 (batch 4)
  ... step 6/31  loss=0.4056  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 1.883e+00 (batch 6)
  ... step 8/31  loss=0.6423  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 1.839e+00 (batch 8)
  ... step 10/31  loss=0.3239  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 1.262e+00 (batch 10)
  ... step 12/31  loss=0.5946  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 1.670e+00 (batch 12)
  ... step 14/31  loss=0.4166  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 1.304e+00 (batch 14)
  ... step 16/31  loss=0.5209  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 1.419e+00 (batch 16)
  ... step 18/31  loss=0.5384  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 1.402e+00 (batch 18)
  ... step 20/31  loss=0.6986  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 1.456e+00 (batch 20)
  ... step 22/31  loss=0.2529  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 9.905e-01 (batch 22)
  ... step 24/31  loss=0.6328  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 1.786e+00 (batch 24)
  ... step 26/31  loss=0.4167  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 1.428e+00 (batch 26)
  ... step 28/31  loss=0.3950  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 1.917e+00 (batch 28)
  ... step 30/31  loss=0.7738  (1.3s since last print)
  â†˜ grad L2 norm â‰ˆ 2.523e+00 (batch 30)
âœ… epoch 6 forward/backward done in 34.7s
  ğŸ” val step 0: batch (16, 32, 2, 324, 1, 16) loss=16.0830
[06] train=0.4889  val=14.7412  RMSE(std)=[Qi:3.890, Qe:3.840, Î“:3.787]  RMSE(phys)=[Qi:331.042, Qe:424.324, Î“:196.080]  (2.2s)
âœ… Saved unified NN â†’ ./mnt/data/bin.cgyro.nn
ğŸŸ¦ Starting epoch 7/20 (train steps â‰ˆ 31)
  ... step 0/31  loss=0.3584  (0.3s since last print)
  â†˜ grad L2 norm â‰ˆ 1.057e+00 (batch 0)
  ... step 2/31  loss=0.3756  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 1.351e+00 (batch 2)
  ... step 4/31  loss=0.5448  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 1.404e+00 (batch 4)
  ... step 6/31  loss=0.3140  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 1.646e+00 (batch 6)
  ... step 8/31  loss=0.8517  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 2.794e+00 (batch 8)
  ... step 10/31  loss=0.4353  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 1.597e+00 (batch 10)
  ... step 12/31  loss=0.3682  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 1.128e+00 (batch 12)
  ... step 14/31  loss=0.4901  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 1.592e+00 (batch 14)
  ... step 16/31  loss=0.3842  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 1.060e+00 (batch 16)
  ... step 18/31  loss=0.4759  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 1.437e+00 (batch 18)
  ... step 20/31  loss=0.5753  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 1.287e+00 (batch 20)
  ... step 22/31  loss=0.5294  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 1.642e+00 (batch 22)
  ... step 24/31  loss=0.9681  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 2.586e+00 (batch 24)
  ... step 26/31  loss=0.4121  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 1.311e+00 (batch 26)
  ... step 28/31  loss=0.5362  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 1.533e+00 (batch 28)
  ... step 30/31  loss=0.5522  (1.3s since last print)
  â†˜ grad L2 norm â‰ˆ 3.177e+00 (batch 30)
âœ… epoch 7 forward/backward done in 34.8s
  ğŸ” val step 0: batch (16, 32, 2, 324, 1, 16) loss=20.0196
[07] train=0.4977  val=18.6612  RMSE(std)=[Qi:4.502, Qe:4.243, Î“:4.208]  RMSE(phys)=[Qi:383.130, Qe:468.849, Î“:217.876]  (2.2s)
âœ… Saved unified NN â†’ ./mnt/data/bin.cgyro.nn
ğŸŸ¦ Starting epoch 8/20 (train steps â‰ˆ 31)
  ... step 0/31  loss=0.4843  (0.3s since last print)
  â†˜ grad L2 norm â‰ˆ 1.740e+00 (batch 0)
  ... step 2/31  loss=0.6022  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 2.464e+00 (batch 2)
  ... step 4/31  loss=0.5271  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 1.171e+00 (batch 4)
  ... step 6/31  loss=0.4302  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 1.017e+00 (batch 6)
  ... step 8/31  loss=0.6649  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 1.374e+00 (batch 8)
  ... step 10/31  loss=0.8277  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 2.398e+00 (batch 10)
  ... step 12/31  loss=0.4594  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 1.192e+00 (batch 12)
  ... step 14/31  loss=0.5342  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 1.169e+00 (batch 14)
  ... step 16/31  loss=0.3247  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 8.095e-01 (batch 16)
  ... step 18/31  loss=0.6372  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 1.835e+00 (batch 18)
  ... step 20/31  loss=0.5942  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 1.373e+00 (batch 20)
  ... step 22/31  loss=0.3801  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 1.044e+00 (batch 22)
  ... step 24/31  loss=0.6515  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 1.638e+00 (batch 24)
  ... step 26/31  loss=0.4589  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 1.254e+00 (batch 26)
  ... step 28/31  loss=0.3076  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 1.210e+00 (batch 28)
  ... step 30/31  loss=0.7219  (1.3s since last print)
  â†˜ grad L2 norm â‰ˆ 2.476e+00 (batch 30)
âœ… epoch 8 forward/backward done in 34.7s
  ğŸ” val step 0: batch (16, 32, 2, 324, 1, 16) loss=11.4416
[08] train=0.5039  val=10.2746  RMSE(std)=[Qi:3.190, Qe:3.194, Î“:3.233]  RMSE(phys)=[Qi:271.464, Qe:352.856, Î“:167.363]  (2.2s)
âœ… Saved unified NN â†’ ./mnt/data/bin.cgyro.nn
ğŸŸ¦ Starting epoch 9/20 (train steps â‰ˆ 31)
  ... step 0/31  loss=0.4981  (0.3s since last print)
  â†˜ grad L2 norm â‰ˆ 1.200e+00 (batch 0)
  ... step 2/31  loss=0.3546  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 1.303e+00 (batch 2)
  ... step 4/31  loss=0.5370  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 1.841e+00 (batch 4)
  ... step 6/31  loss=0.4384  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 9.439e-01 (batch 6)
  ... step 8/31  loss=0.4009  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 7.362e-01 (batch 8)
  ... step 10/31  loss=0.4559  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 1.218e+00 (batch 10)
  ... step 12/31  loss=0.4745  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 1.254e+00 (batch 12)
  ... step 14/31  loss=0.2421  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 8.568e-01 (batch 14)
  ... step 16/31  loss=0.4650  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 1.895e+00 (batch 16)
  ... step 18/31  loss=0.5298  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 1.565e+00 (batch 18)
  ... step 20/31  loss=0.5282  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 1.328e+00 (batch 20)
  ... step 22/31  loss=0.2884  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 9.205e-01 (batch 22)
  ... step 24/31  loss=0.5451  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 2.915e+00 (batch 24)
  ... step 26/31  loss=0.4839  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 1.368e+00 (batch 26)
  ... step 28/31  loss=0.3296  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 9.758e-01 (batch 28)
  ... step 30/31  loss=0.4545  (1.3s since last print)
  â†˜ grad L2 norm â‰ˆ 1.989e+00 (batch 30)
âœ… epoch 9 forward/backward done in 34.7s
  ğŸ” val step 0: batch (16, 32, 2, 324, 1, 16) loss=4.9187
[09] train=0.4499  val=4.4632  RMSE(std)=[Qi:2.165, Qe:2.227, Î“:1.935]  RMSE(phys)=[Qi:184.235, Qe:246.089, Î“:100.158]  (2.2s)
âœ… Saved unified NN â†’ ./mnt/data/bin.cgyro.nn
ğŸŸ¦ Starting epoch 10/20 (train steps â‰ˆ 31)
  ... step 0/31  loss=0.4173  (0.3s since last print)
  â†˜ grad L2 norm â‰ˆ 1.994e+00 (batch 0)
  ... step 2/31  loss=0.4636  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 1.306e+00 (batch 2)
  ... step 4/31  loss=0.2625  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 8.429e-01 (batch 4)
  ... step 6/31  loss=0.4065  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 1.547e+00 (batch 6)
  ... step 8/31  loss=0.4267  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 1.189e+00 (batch 8)
  ... step 10/31  loss=0.4735  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 1.604e+00 (batch 10)
  ... step 12/31  loss=0.5049  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 1.343e+00 (batch 12)
  ... step 14/31  loss=0.4613  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 1.937e+00 (batch 14)
  ... step 16/31  loss=0.3810  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 1.193e+00 (batch 16)
  ... step 18/31  loss=0.4935  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 1.679e+00 (batch 18)
  ... step 20/31  loss=0.6345  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 1.267e+00 (batch 20)
  ... step 22/31  loss=0.4765  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 1.608e+00 (batch 22)
  ... step 24/31  loss=0.4847  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 1.236e+00 (batch 24)
  ... step 26/31  loss=0.5624  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 2.386e+00 (batch 26)
  ... step 28/31  loss=0.4189  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 1.050e+00 (batch 28)
  ... step 30/31  loss=0.4949  (1.3s since last print)
  â†˜ grad L2 norm â‰ˆ 1.886e+00 (batch 30)
âœ… epoch 10 forward/backward done in 34.7s
  ğŸ” val step 0: batch (16, 32, 2, 324, 1, 16) loss=8.3331
[10] train=0.4335  val=7.8063  RMSE(std)=[Qi:2.697, Qe:2.899, Î“:2.782]  RMSE(phys)=[Qi:229.536, Qe:320.339, Î“:144.024]  (2.2s)
âœ… Saved unified NN â†’ ./mnt/data/bin.cgyro.nn
ğŸŸ¦ Starting epoch 11/20 (train steps â‰ˆ 31)
  ... step 0/31  loss=0.5810  (0.3s since last print)
  â†˜ grad L2 norm â‰ˆ 1.101e+00 (batch 0)
  ... step 2/31  loss=0.3077  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 1.123e+00 (batch 2)
  ... step 4/31  loss=0.3431  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 1.216e+00 (batch 4)
  ... step 6/31  loss=0.2208  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 8.624e-01 (batch 6)
  ... step 8/31  loss=0.5136  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 1.235e+00 (batch 8)
  ... step 10/31  loss=0.4749  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 1.639e+00 (batch 10)
  ... step 12/31  loss=0.5913  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 1.521e+00 (batch 12)
  ... step 14/31  loss=0.3529  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 1.442e+00 (batch 14)
  ... step 16/31  loss=0.3710  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 9.771e-01 (batch 16)
  ... step 18/31  loss=0.5020  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 1.692e+00 (batch 18)
  ... step 20/31  loss=0.2787  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 8.316e-01 (batch 20)
  ... step 22/31  loss=0.4360  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 1.119e+00 (batch 22)
  ... step 24/31  loss=0.2756  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 1.046e+00 (batch 24)
  ... step 26/31  loss=0.3978  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 7.533e-01 (batch 26)
  ... step 28/31  loss=0.3857  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 1.271e+00 (batch 28)
  ... step 30/31  loss=0.6973  (1.3s since last print)
  â†˜ grad L2 norm â‰ˆ 2.505e+00 (batch 30)
âœ… epoch 11 forward/backward done in 34.7s
  ğŸ” val step 0: batch (16, 32, 2, 324, 1, 16) loss=6.0058
[11] train=0.4409  val=5.5278  RMSE(std)=[Qi:2.400, Qe:2.346, Î“:2.307]  RMSE(phys)=[Qi:204.272, Qe:259.161, Î“:119.420]  (2.2s)
âœ… Saved unified NN â†’ ./mnt/data/bin.cgyro.nn
â¹ Early stopping after 11 epochs (no val improvement).
Saved metrics â†’ ./mnt/data/myrun_logs_deep_debug/metrics.csv
âœ… Final unified NN â†’ ./mnt/data/bin.cgyro.nn
âœ… Training complete. Artifacts in: ./mnt/data/myrun_logs_deep_debug
