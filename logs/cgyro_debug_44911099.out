[build_datasets] windows: total=615  train=369  val=123  test=123

[train] dataset:
  y_mean: [[[149.46204 223.82538  88.89333]]]
  y_std : [[[72.62504 92.54556 44.15767]]]
  sample Y: min=-1.324e+00, max=2.054e+00, mean=-2.283e-01, std=7.447e-01

[val] dataset:
  y_mean: [[[149.46204 223.82538  88.89333]]]
  y_std : [[[72.62504 92.54556 44.15767]]]
  sample Y: min=-1.976e+00, max=2.718e+00, mean=-3.365e-01, std=1.145e+00

[test] dataset:
  y_mean: [[[149.46204 223.82538  88.89333]]]
  y_std : [[[72.62504 92.54556 44.15767]]]
  sample Y: min=-1.871e+00, max=3.058e+00, mean=-1.987e-02, std=1.562e+00
âœ… Saved flux histograms in ./mnt/data/myrun_logs_deep_debug_ordered_t
ðŸŸ¦ Starting epoch 1/20 (train steps â‰ˆ 47)
[475269] Î¦2FluxDeep forward: input (8, 32, 2, 324, 1, 16)
  ... step 0/47  loss=0.7751  (3.1s since last print)
  â†˜ grad L2 norm â‰ˆ 1.505e+01 (batch 0)
  ... step 2/47  loss=1.3318  (0.8s since last print)
  â†˜ grad L2 norm â‰ˆ 1.680e+01 (batch 2)
  ... step 4/47  loss=0.9421  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 1.412e+01 (batch 4)
  ... step 6/47  loss=0.9539  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 1.373e+01 (batch 6)
  ... step 8/47  loss=0.7839  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 1.141e+01 (batch 8)
  ... step 10/47  loss=0.7790  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 1.193e+01 (batch 10)
  ... step 12/47  loss=1.2803  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 1.812e+01 (batch 12)
  ... step 14/47  loss=0.9088  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 1.370e+01 (batch 14)
  ... step 16/47  loss=1.2065  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 1.413e+01 (batch 16)
  ... step 18/47  loss=0.9328  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 1.140e+01 (batch 18)
  ... step 20/47  loss=0.6763  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 1.141e+01 (batch 20)
  ... step 22/47  loss=1.1380  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 1.451e+01 (batch 22)
  ... step 24/47  loss=1.0937  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 1.255e+01 (batch 24)
  ... step 26/47  loss=0.8572  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 1.301e+01 (batch 26)
  ... step 28/47  loss=0.5507  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 9.379e+00 (batch 28)
  ... step 30/47  loss=0.9329  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 1.198e+01 (batch 30)
  ... step 32/47  loss=0.8702  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 1.091e+01 (batch 32)
  ... step 34/47  loss=1.2092  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 1.444e+01 (batch 34)
  ... step 36/47  loss=0.9180  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 1.046e+01 (batch 36)
  ... step 38/47  loss=0.8229  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 1.093e+01 (batch 38)
  ... step 40/47  loss=1.0541  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 1.385e+01 (batch 40)
  ... step 42/47  loss=1.3697  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 1.481e+01 (batch 42)
  ... step 44/47  loss=0.9136  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 1.120e+01 (batch 44)
  ... step 46/47  loss=2.0013  (0.6s since last print)
  â†˜ grad L2 norm â‰ˆ 3.868e+01 (batch 46)
âœ… epoch 1 forward/backward done in 28.1s
  ðŸ”Ž val step 0: batch (8, 32, 2, 324, 1, 16) loss=1.1912
[01] train=1.0490  val=1.3907  RMSE(std)=[Qi:1.163, Qe:1.216, Î“:1.158]  RMSE(phys)=[Qi:84.496, Qe:112.491, Î“:51.137]  (1.5s)
âœ… Saved unified NN â†’ ./mnt/data/bin.cgyro.nn
ðŸŸ¦ Starting epoch 2/20 (train steps â‰ˆ 47)
  ... step 0/47  loss=0.7095  (0.1s since last print)
  â†˜ grad L2 norm â‰ˆ 8.656e+00 (batch 0)
  ... step 2/47  loss=1.6600  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 1.764e+01 (batch 2)
  ... step 4/47  loss=1.0480  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 1.400e+01 (batch 4)
  ... step 6/47  loss=1.0088  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 1.157e+01 (batch 6)
  ... step 8/47  loss=0.8671  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 1.199e+01 (batch 8)
  ... step 10/47  loss=1.3149  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 1.354e+01 (batch 10)
  ... step 12/47  loss=0.7765  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 1.131e+01 (batch 12)
  ... step 14/47  loss=0.3430  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 6.916e+00 (batch 14)
  ... step 16/47  loss=1.0720  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 1.270e+01 (batch 16)
  ... step 18/47  loss=0.7861  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 1.030e+01 (batch 18)
  ... step 20/47  loss=0.6424  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 8.689e+00 (batch 20)
  ... step 22/47  loss=1.4254  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 1.219e+01 (batch 22)
  ... step 24/47  loss=0.7057  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 9.808e+00 (batch 24)
  ... step 26/47  loss=1.7221  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 1.528e+01 (batch 26)
  ... step 28/47  loss=0.7559  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 8.939e+00 (batch 28)
  ... step 30/47  loss=0.8883  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 1.088e+01 (batch 30)
  ... step 32/47  loss=0.9402  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 1.245e+01 (batch 32)
  ... step 34/47  loss=1.1170  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 1.167e+01 (batch 34)
  ... step 36/47  loss=1.6304  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 1.558e+01 (batch 36)
  ... step 38/47  loss=1.1097  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 1.133e+01 (batch 38)
  ... step 40/47  loss=0.5527  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 7.264e+00 (batch 40)
  ... step 42/47  loss=0.9038  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 1.005e+01 (batch 42)
  ... step 44/47  loss=1.1883  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 1.126e+01 (batch 44)
  ... step 46/47  loss=1.8835  (0.6s since last print)
  â†˜ grad L2 norm â‰ˆ 4.101e+01 (batch 46)
âœ… epoch 2 forward/backward done in 25.4s
  ðŸ”Ž val step 0: batch (8, 32, 2, 324, 1, 16) loss=1.1573
[02] train=1.0108  val=1.3523  RMSE(std)=[Qi:1.137, Qe:1.202, Î“:1.148]  RMSE(phys)=[Qi:82.592, Qe:111.257, Î“:50.703]  (1.5s)
âœ… Saved unified NN â†’ ./mnt/data/bin.cgyro.nn
ðŸŸ¦ Starting epoch 3/20 (train steps â‰ˆ 47)
  ... step 0/47  loss=0.8823  (0.1s since last print)
  â†˜ grad L2 norm â‰ˆ 9.820e+00 (batch 0)
  ... step 2/47  loss=0.9600  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 1.099e+01 (batch 2)
  ... step 4/47  loss=1.5193  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 1.348e+01 (batch 4)
  ... step 6/47  loss=1.1665  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 1.168e+01 (batch 6)
  ... step 8/47  loss=0.4156  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 6.684e+00 (batch 8)
  ... step 10/47  loss=0.5910  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 6.514e+00 (batch 10)
  ... step 12/47  loss=0.7635  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 8.001e+00 (batch 12)
  ... step 14/47  loss=1.0238  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 1.208e+01 (batch 14)
  ... step 16/47  loss=1.2791  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 1.311e+01 (batch 16)
  ... step 18/47  loss=0.5293  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 7.545e+00 (batch 18)
  ... step 20/47  loss=1.0006  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 9.449e+00 (batch 20)
  ... step 22/47  loss=1.6584  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 1.143e+01 (batch 22)
  ... step 24/47  loss=1.5368  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 1.427e+01 (batch 24)
  ... step 26/47  loss=0.2792  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 5.732e+00 (batch 26)
  ... step 28/47  loss=1.4755  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 1.209e+01 (batch 28)
  ... step 30/47  loss=0.6532  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 9.799e+00 (batch 30)
  ... step 32/47  loss=1.7407  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 1.489e+01 (batch 32)
  ... step 34/47  loss=1.0660  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 1.136e+01 (batch 34)
  ... step 36/47  loss=1.2929  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 1.154e+01 (batch 36)
  ... step 38/47  loss=0.9026  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 9.389e+00 (batch 38)
  ... step 40/47  loss=0.9029  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 9.869e+00 (batch 40)
  ... step 42/47  loss=1.1504  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 1.002e+01 (batch 42)
  ... step 44/47  loss=0.6743  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 8.803e+00 (batch 44)
  ... step 46/47  loss=2.3398  (0.6s since last print)
  â†˜ grad L2 norm â‰ˆ 3.229e+01 (batch 46)
âœ… epoch 3 forward/backward done in 25.4s
  ðŸ”Ž val step 0: batch (8, 32, 2, 324, 1, 16) loss=1.3316
[03] train=0.9749  val=1.3156  RMSE(std)=[Qi:1.131, Qe:1.181, Î“:1.128]  RMSE(phys)=[Qi:82.166, Qe:109.281, Î“:49.812]  (1.5s)
âœ… Saved unified NN â†’ ./mnt/data/bin.cgyro.nn
ðŸŸ¦ Starting epoch 4/20 (train steps â‰ˆ 47)
  ... step 0/47  loss=0.5297  (0.1s since last print)
  â†˜ grad L2 norm â‰ˆ 5.711e+00 (batch 0)
  ... step 2/47  loss=1.2987  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 1.381e+01 (batch 2)
  ... step 4/47  loss=1.0375  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 1.086e+01 (batch 4)
  ... step 6/47  loss=1.2372  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 9.871e+00 (batch 6)
  ... step 8/47  loss=0.8721  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 9.411e+00 (batch 8)
  ... step 10/47  loss=0.5856  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 9.860e+00 (batch 10)
  ... step 12/47  loss=0.9560  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 1.092e+01 (batch 12)
  ... step 14/47  loss=0.7431  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 9.555e+00 (batch 14)
  ... step 16/47  loss=1.4432  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 1.411e+01 (batch 16)
  ... step 18/47  loss=1.1219  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 1.057e+01 (batch 18)
  ... step 20/47  loss=1.4012  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 1.276e+01 (batch 20)
  ... step 22/47  loss=0.8743  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 1.101e+01 (batch 22)
  ... step 24/47  loss=1.2298  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 1.176e+01 (batch 24)
  ... step 26/47  loss=0.8319  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 1.006e+01 (batch 26)
  ... step 28/47  loss=0.6215  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 8.768e+00 (batch 28)
  ... step 30/47  loss=0.6624  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 8.540e+00 (batch 30)
  ... step 32/47  loss=0.4745  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 5.716e+00 (batch 32)
  ... step 34/47  loss=1.3629  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 1.322e+01 (batch 34)
  ... step 36/47  loss=0.9346  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 9.277e+00 (batch 36)
  ... step 38/47  loss=0.5304  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 8.129e+00 (batch 38)
  ... step 40/47  loss=0.6643  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 1.155e+01 (batch 40)
  ... step 42/47  loss=0.9126  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 1.033e+01 (batch 42)
  ... step 44/47  loss=0.7064  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 9.231e+00 (batch 44)
  ... step 46/47  loss=0.8508  (0.6s since last print)
  â†˜ grad L2 norm â‰ˆ 3.494e+01 (batch 46)
âœ… epoch 4 forward/backward done in 25.4s
  ðŸ”Ž val step 0: batch (8, 32, 2, 324, 1, 16) loss=1.5954
[04] train=0.9002  val=1.1166  RMSE(std)=[Qi:1.027, Qe:1.094, Î“:1.048]  RMSE(phys)=[Qi:74.606, Qe:101.239, Î“:46.266]  (1.5s)
âœ… Saved unified NN â†’ ./mnt/data/bin.cgyro.nn
ðŸŸ¦ Starting epoch 5/20 (train steps â‰ˆ 47)
  ... step 0/47  loss=0.7171  (0.1s since last print)
  â†˜ grad L2 norm â‰ˆ 1.243e+01 (batch 0)
  ... step 2/47  loss=1.3425  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 1.069e+01 (batch 2)
  ... step 4/47  loss=0.4956  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 9.467e+00 (batch 4)
  ... step 6/47  loss=0.6514  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 7.874e+00 (batch 6)
  ... step 8/47  loss=1.0097  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 1.133e+01 (batch 8)
  ... step 10/47  loss=0.5521  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 9.801e+00 (batch 10)
  ... step 12/47  loss=0.5259  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 8.147e+00 (batch 12)
  ... step 14/47  loss=0.4823  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 7.028e+00 (batch 14)
  ... step 16/47  loss=0.9093  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 1.070e+01 (batch 16)
  ... step 18/47  loss=0.9410  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 1.131e+01 (batch 18)
  ... step 20/47  loss=0.7059  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 8.470e+00 (batch 20)
  ... step 22/47  loss=0.7199  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 9.830e+00 (batch 22)
  ... step 24/47  loss=1.2469  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 1.354e+01 (batch 24)
  ... step 26/47  loss=1.0923  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 1.177e+01 (batch 26)
  ... step 28/47  loss=0.3058  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 8.309e+00 (batch 28)
  ... step 30/47  loss=0.8063  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 7.211e+00 (batch 30)
  ... step 32/47  loss=0.7762  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 1.165e+01 (batch 32)
  ... step 34/47  loss=0.9050  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 1.199e+01 (batch 34)
  ... step 36/47  loss=0.5958  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 1.078e+01 (batch 36)
  ... step 38/47  loss=0.9123  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 8.957e+00 (batch 38)
  ... step 40/47  loss=0.7229  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 1.211e+01 (batch 40)
  ... step 42/47  loss=0.4264  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 6.494e+00 (batch 42)
  ... step 44/47  loss=0.8082  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 1.364e+01 (batch 44)
  ... step 46/47  loss=2.3350  (0.6s since last print)
  â†˜ grad L2 norm â‰ˆ 6.355e+01 (batch 46)
âœ… epoch 5 forward/backward done in 25.4s
  ðŸ”Ž val step 0: batch (8, 32, 2, 324, 1, 16) loss=15.0106
[05] train=0.7700  val=10.2862  RMSE(std)=[Qi:3.142, Qe:2.998, Î“:3.465]  RMSE(phys)=[Qi:228.152, Qe:277.411, Î“:152.993]  (1.5s)
âœ… Saved unified NN â†’ ./mnt/data/bin.cgyro.nn
ðŸŸ¦ Starting epoch 6/20 (train steps â‰ˆ 47)
  ... step 0/47  loss=0.5710  (0.1s since last print)
  â†˜ grad L2 norm â‰ˆ 1.200e+01 (batch 0)
  ... step 2/47  loss=0.5078  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 1.196e+01 (batch 2)
  ... step 4/47  loss=0.9087  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 1.190e+01 (batch 4)
  ... step 6/47  loss=1.1500  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 1.306e+01 (batch 6)
  ... step 8/47  loss=0.8261  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 1.336e+01 (batch 8)
  ... step 10/47  loss=0.6353  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 8.556e+00 (batch 10)
  ... step 12/47  loss=0.4953  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 1.058e+01 (batch 12)
  ... step 14/47  loss=0.7372  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 1.091e+01 (batch 14)
  ... step 16/47  loss=1.1150  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 1.608e+01 (batch 16)
  ... step 18/47  loss=0.7559  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 1.714e+01 (batch 18)
  ... step 20/47  loss=0.8664  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 1.184e+01 (batch 20)
  ... step 22/47  loss=0.8869  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 1.338e+01 (batch 22)
  ... step 24/47  loss=0.7825  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 1.106e+01 (batch 24)
  ... step 26/47  loss=0.4070  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 6.405e+00 (batch 26)
  ... step 28/47  loss=0.3965  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 6.844e+00 (batch 28)
  ... step 30/47  loss=1.5470  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 1.550e+01 (batch 30)
  ... step 32/47  loss=0.6675  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 9.644e+00 (batch 32)
  ... step 34/47  loss=0.8519  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 1.348e+01 (batch 34)
  ... step 36/47  loss=0.4010  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 4.559e+00 (batch 36)
  ... step 38/47  loss=1.6491  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 1.591e+01 (batch 38)
  ... step 40/47  loss=0.6117  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 1.018e+01 (batch 40)
  ... step 42/47  loss=0.4934  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 9.237e+00 (batch 42)
  ... step 44/47  loss=0.6941  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 8.221e+00 (batch 44)
  ... step 46/47  loss=0.5418  (0.6s since last print)
  â†˜ grad L2 norm â‰ˆ 1.688e+01 (batch 46)
âœ… epoch 6 forward/backward done in 25.4s
  ðŸ”Ž val step 0: batch (8, 32, 2, 324, 1, 16) loss=41.3323
[06] train=0.7582  val=38.7540  RMSE(std)=[Qi:6.704, Qe:5.633, Î“:6.292]  RMSE(phys)=[Qi:486.854, Qe:521.329, Î“:277.842]  (1.5s)
âœ… Saved unified NN â†’ ./mnt/data/bin.cgyro.nn
ðŸŸ¦ Starting epoch 7/20 (train steps â‰ˆ 47)
  ... step 0/47  loss=0.4640  (0.1s since last print)
  â†˜ grad L2 norm â‰ˆ 8.132e+00 (batch 0)
  ... step 2/47  loss=0.8134  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 1.084e+01 (batch 2)
  ... step 4/47  loss=0.5534  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 8.580e+00 (batch 4)
  ... step 6/47  loss=0.7282  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 1.291e+01 (batch 6)
  ... step 8/47  loss=0.7286  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 1.145e+01 (batch 8)
  ... step 10/47  loss=0.7197  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 8.215e+00 (batch 10)
  ... step 12/47  loss=0.7082  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 9.275e+00 (batch 12)
  ... step 14/47  loss=1.4833  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 1.222e+01 (batch 14)
  ... step 16/47  loss=0.4948  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 6.567e+00 (batch 16)
  ... step 18/47  loss=0.4388  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 6.420e+00 (batch 18)
  ... step 20/47  loss=0.6928  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 8.155e+00 (batch 20)
  ... step 22/47  loss=0.6439  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 8.153e+00 (batch 22)
  ... step 24/47  loss=0.7813  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 9.382e+00 (batch 24)
  ... step 26/47  loss=0.7635  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 1.100e+01 (batch 26)
  ... step 28/47  loss=0.6678  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 8.878e+00 (batch 28)
  ... step 30/47  loss=0.4872  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 6.441e+00 (batch 30)
  ... step 32/47  loss=0.6137  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 7.958e+00 (batch 32)
  ... step 34/47  loss=0.4741  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 6.361e+00 (batch 34)
  ... step 36/47  loss=0.9009  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 9.486e+00 (batch 36)
  ... step 38/47  loss=0.2344  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 4.048e+00 (batch 38)
  ... step 40/47  loss=0.8731  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 7.397e+00 (batch 40)
  ... step 42/47  loss=0.7081  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 9.069e+00 (batch 42)
  ... step 44/47  loss=0.4962  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 6.196e+00 (batch 44)
  ... step 46/47  loss=1.3679  (0.6s since last print)
  â†˜ grad L2 norm â‰ˆ 2.960e+01 (batch 46)
âœ… epoch 7 forward/backward done in 25.4s
  ðŸ”Ž val step 0: batch (8, 32, 2, 324, 1, 16) loss=58.9829
[07] train=0.6860  val=58.4418  RMSE(std)=[Qi:7.833, Qe:7.201, Î“:7.881]  RMSE(phys)=[Qi:568.838, Qe:666.461, Î“:348.023]  (1.5s)
âœ… Saved unified NN â†’ ./mnt/data/bin.cgyro.nn
ðŸŸ¦ Starting epoch 8/20 (train steps â‰ˆ 47)
  ... step 0/47  loss=1.1049  (0.1s since last print)
  â†˜ grad L2 norm â‰ˆ 1.086e+01 (batch 0)
  ... step 2/47  loss=0.5959  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 9.715e+00 (batch 2)
  ... step 4/47  loss=0.6305  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 8.462e+00 (batch 4)
  ... step 6/47  loss=0.4883  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 6.029e+00 (batch 6)
  ... step 8/47  loss=0.6208  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 7.647e+00 (batch 8)
  ... step 10/47  loss=0.6423  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 5.173e+00 (batch 10)
  ... step 12/47  loss=0.4756  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 6.542e+00 (batch 12)
  ... step 14/47  loss=0.6065  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 7.433e+00 (batch 14)
  ... step 16/47  loss=0.4797  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 6.267e+00 (batch 16)
  ... step 18/47  loss=0.6321  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 7.532e+00 (batch 18)
  ... step 20/47  loss=0.5862  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 7.098e+00 (batch 20)
  ... step 22/47  loss=0.8611  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 1.003e+01 (batch 22)
  ... step 24/47  loss=0.5849  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 8.649e+00 (batch 24)
  ... step 26/47  loss=0.3801  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 6.767e+00 (batch 26)
  ... step 28/47  loss=1.1524  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 1.486e+01 (batch 28)
  ... step 30/47  loss=1.1100  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 1.052e+01 (batch 30)
  ... step 32/47  loss=0.7885  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 8.392e+00 (batch 32)
  ... step 34/47  loss=0.6924  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 1.158e+01 (batch 34)
  ... step 36/47  loss=0.6406  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 7.943e+00 (batch 36)
  ... step 38/47  loss=0.6380  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 8.177e+00 (batch 38)
  ... step 40/47  loss=0.8187  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 1.005e+01 (batch 40)
  ... step 42/47  loss=0.6813  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 7.937e+00 (batch 42)
  ... step 44/47  loss=0.6424  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 7.360e+00 (batch 44)
  ... step 46/47  loss=0.1492  (0.6s since last print)
  â†˜ grad L2 norm â‰ˆ 1.297e+01 (batch 46)
âœ… epoch 8 forward/backward done in 25.4s
  ðŸ”Ž val step 0: batch (8, 32, 2, 324, 1, 16) loss=65.1002
[08] train=0.6287  val=64.4094  RMSE(std)=[Qi:8.728, Qe:7.682, Î“:7.618]  RMSE(phys)=[Qi:633.883, Qe:710.969, Î“:336.377]  (1.5s)
âœ… Saved unified NN â†’ ./mnt/data/bin.cgyro.nn
ðŸŸ¦ Starting epoch 9/20 (train steps â‰ˆ 47)
  ... step 0/47  loss=0.6304  (0.1s since last print)
  â†˜ grad L2 norm â‰ˆ 8.214e+00 (batch 0)
  ... step 2/47  loss=0.2318  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 4.413e+00 (batch 2)
  ... step 4/47  loss=0.3296  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 4.907e+00 (batch 4)
  ... step 6/47  loss=0.7205  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 8.119e+00 (batch 6)
  ... step 8/47  loss=0.5703  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 7.992e+00 (batch 8)
  ... step 10/47  loss=0.7578  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 9.888e+00 (batch 10)
  ... step 12/47  loss=0.6711  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 7.307e+00 (batch 12)
  ... step 14/47  loss=0.6514  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 7.639e+00 (batch 14)
  ... step 16/47  loss=0.6191  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 9.126e+00 (batch 16)
  ... step 18/47  loss=0.5594  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 6.418e+00 (batch 18)
  ... step 20/47  loss=0.7044  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 9.363e+00 (batch 20)
  ... step 22/47  loss=0.8710  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 1.039e+01 (batch 22)
  ... step 24/47  loss=0.7833  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 9.349e+00 (batch 24)
  ... step 26/47  loss=0.9776  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 1.326e+01 (batch 26)
  ... step 28/47  loss=0.4392  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 7.538e+00 (batch 28)
  ... step 30/47  loss=0.2664  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 4.522e+00 (batch 30)
  ... step 32/47  loss=0.6034  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 8.214e+00 (batch 32)
  ... step 34/47  loss=0.9528  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 1.057e+01 (batch 34)
  ... step 36/47  loss=0.4943  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 7.038e+00 (batch 36)
  ... step 38/47  loss=0.6605  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 9.948e+00 (batch 38)
  ... step 40/47  loss=0.4862  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 1.009e+01 (batch 40)
  ... step 42/47  loss=0.6626  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 8.036e+00 (batch 42)
  ... step 44/47  loss=0.4269  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 8.673e+00 (batch 44)
  ... step 46/47  loss=0.1719  (0.6s since last print)
  â†˜ grad L2 norm â‰ˆ 1.085e+01 (batch 46)
âœ… epoch 9 forward/backward done in 25.4s
  ðŸ”Ž val step 0: batch (8, 32, 2, 324, 1, 16) loss=7.1526
[09] train=0.6053  val=3.5917  RMSE(std)=[Qi:1.898, Qe:1.851, Î“:1.935]  RMSE(phys)=[Qi:137.877, Qe:171.338, Î“:85.433]  (1.5s)
âœ… Saved unified NN â†’ ./mnt/data/bin.cgyro.nn
ðŸŸ¦ Starting epoch 10/20 (train steps â‰ˆ 47)
  ... step 0/47  loss=0.2613  (0.1s since last print)
  â†˜ grad L2 norm â‰ˆ 4.965e+00 (batch 0)
  ... step 2/47  loss=0.4552  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 5.956e+00 (batch 2)
  ... step 4/47  loss=0.8186  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 1.071e+01 (batch 4)
  ... step 6/47  loss=0.4684  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 7.015e+00 (batch 6)
  ... step 8/47  loss=0.8808  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 8.341e+00 (batch 8)
  ... step 10/47  loss=0.8796  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 8.102e+00 (batch 10)
  ... step 12/47  loss=0.7931  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 8.840e+00 (batch 12)
  ... step 14/47  loss=0.8398  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 9.775e+00 (batch 14)
  ... step 16/47  loss=0.3688  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 6.200e+00 (batch 16)
  ... step 18/47  loss=0.3163  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 6.341e+00 (batch 18)
  ... step 20/47  loss=0.2949  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 4.330e+00 (batch 20)
  ... step 22/47  loss=0.5183  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 6.796e+00 (batch 22)
  ... step 24/47  loss=0.3194  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 5.555e+00 (batch 24)
  ... step 26/47  loss=0.6142  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 8.916e+00 (batch 26)
  ... step 28/47  loss=0.8126  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 8.240e+00 (batch 28)
  ... step 30/47  loss=1.0773  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 1.011e+01 (batch 30)
  ... step 32/47  loss=0.5412  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 7.111e+00 (batch 32)
  ... step 34/47  loss=0.3644  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 6.582e+00 (batch 34)
  ... step 36/47  loss=0.2550  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 4.596e+00 (batch 36)
  ... step 38/47  loss=0.7737  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 9.362e+00 (batch 38)
  ... step 40/47  loss=0.5202  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 7.603e+00 (batch 40)
  ... step 42/47  loss=0.6114  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 7.243e+00 (batch 42)
  ... step 44/47  loss=0.6871  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 7.944e+00 (batch 44)
  ... step 46/47  loss=0.1255  (0.6s since last print)
  â†˜ grad L2 norm â‰ˆ 1.798e+01 (batch 46)
âœ… epoch 10 forward/backward done in 25.4s
  ðŸ”Ž val step 0: batch (8, 32, 2, 324, 1, 16) loss=7.8542
[10] train=0.5936  val=3.4948  RMSE(std)=[Qi:1.855, Qe:1.859, Î“:1.895]  RMSE(phys)=[Qi:134.688, Qe:172.044, Î“:83.657]  (1.5s)
âœ… Saved unified NN â†’ ./mnt/data/bin.cgyro.nn
ðŸŸ¦ Starting epoch 11/20 (train steps â‰ˆ 47)
  ... step 0/47  loss=0.4597  (0.1s since last print)
  â†˜ grad L2 norm â‰ˆ 6.200e+00 (batch 0)
  ... step 2/47  loss=0.8219  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 1.136e+01 (batch 2)
  ... step 4/47  loss=0.4259  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 6.630e+00 (batch 4)
  ... step 6/47  loss=0.6955  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 1.315e+01 (batch 6)
  ... step 8/47  loss=0.7274  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 1.101e+01 (batch 8)
  ... step 10/47  loss=0.6365  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 8.501e+00 (batch 10)
  ... step 12/47  loss=0.5462  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 9.053e+00 (batch 12)
  ... step 14/47  loss=0.9693  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 1.149e+01 (batch 14)
  ... step 16/47  loss=0.8311  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 9.807e+00 (batch 16)
  ... step 18/47  loss=0.7156  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 8.931e+00 (batch 18)
  ... step 20/47  loss=0.4223  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 5.330e+00 (batch 20)
  ... step 22/47  loss=0.2956  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 6.648e+00 (batch 22)
  ... step 24/47  loss=0.8598  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 8.348e+00 (batch 24)
  ... step 26/47  loss=0.5715  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 7.539e+00 (batch 26)
  ... step 28/47  loss=0.6200  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 7.965e+00 (batch 28)
  ... step 30/47  loss=0.7624  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 7.632e+00 (batch 30)
  ... step 32/47  loss=0.6536  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 9.243e+00 (batch 32)
  ... step 34/47  loss=0.7411  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 7.836e+00 (batch 34)
  ... step 36/47  loss=0.9143  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 8.940e+00 (batch 36)
  ... step 38/47  loss=0.8835  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 1.118e+01 (batch 38)
  ... step 40/47  loss=0.3211  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 5.388e+00 (batch 40)
  ... step 42/47  loss=0.5902  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 7.706e+00 (batch 42)
  ... step 44/47  loss=0.8046  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 9.788e+00 (batch 44)
  ... step 46/47  loss=2.1745  (0.6s since last print)
  â†˜ grad L2 norm â‰ˆ 6.343e+01 (batch 46)
âœ… epoch 11 forward/backward done in 25.4s
  ðŸ”Ž val step 0: batch (8, 32, 2, 324, 1, 16) loss=4.6246
[11] train=0.6049  val=1.6378  RMSE(std)=[Qi:1.288, Qe:1.292, Î“:1.259]  RMSE(phys)=[Qi:93.538, Qe:119.568, Î“:55.601]  (1.5s)
âœ… Saved unified NN â†’ ./mnt/data/bin.cgyro.nn
ðŸŸ¦ Starting epoch 12/20 (train steps â‰ˆ 47)
  ... step 0/47  loss=0.4846  (0.1s since last print)
  â†˜ grad L2 norm â‰ˆ 8.738e+00 (batch 0)
  ... step 2/47  loss=0.6697  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 8.424e+00 (batch 2)
  ... step 4/47  loss=0.7469  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 9.887e+00 (batch 4)
  ... step 6/47  loss=0.4586  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 8.355e+00 (batch 6)
  ... step 8/47  loss=0.4393  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 5.366e+00 (batch 8)
  ... step 10/47  loss=0.6109  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 1.175e+01 (batch 10)
  ... step 12/47  loss=0.4283  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 6.681e+00 (batch 12)
  ... step 14/47  loss=0.6574  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 8.516e+00 (batch 14)
  ... step 16/47  loss=0.7922  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 8.140e+00 (batch 16)
  ... step 18/47  loss=0.3614  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 5.368e+00 (batch 18)
  ... step 20/47  loss=0.6947  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 8.188e+00 (batch 20)
  ... step 22/47  loss=1.2681  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 1.213e+01 (batch 22)
  ... step 24/47  loss=0.5206  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 6.320e+00 (batch 24)
  ... step 26/47  loss=0.8268  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 1.158e+01 (batch 26)
  ... step 28/47  loss=0.3211  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 4.909e+00 (batch 28)
  ... step 30/47  loss=0.4773  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 7.395e+00 (batch 30)
  ... step 32/47  loss=0.5964  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 8.176e+00 (batch 32)
  ... step 34/47  loss=0.2891  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 4.543e+00 (batch 34)
  ... step 36/47  loss=0.3167  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 4.863e+00 (batch 36)
  ... step 38/47  loss=0.4978  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 5.773e+00 (batch 38)
  ... step 40/47  loss=0.5627  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 9.972e+00 (batch 40)
  ... step 42/47  loss=0.4119  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 4.855e+00 (batch 42)
  ... step 44/47  loss=0.9388  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 1.048e+01 (batch 44)
  ... step 46/47  loss=0.3053  (0.6s since last print)
  â†˜ grad L2 norm â‰ˆ 1.654e+01 (batch 46)
âœ… epoch 12 forward/backward done in 25.4s
  ðŸ”Ž val step 0: batch (8, 32, 2, 324, 1, 16) loss=7.3556
[12] train=0.5835  val=2.5995  RMSE(std)=[Qi:1.589, Qe:1.602, Î“:1.645]  RMSE(phys)=[Qi:115.417, Qe:148.227, Î“:72.658]  (1.5s)
âœ… Saved unified NN â†’ ./mnt/data/bin.cgyro.nn
ðŸŸ¦ Starting epoch 13/20 (train steps â‰ˆ 47)
  ... step 0/47  loss=0.2899  (0.1s since last print)
  â†˜ grad L2 norm â‰ˆ 6.553e+00 (batch 0)
  ... step 2/47  loss=0.6808  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 9.004e+00 (batch 2)
  ... step 4/47  loss=0.3382  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 5.389e+00 (batch 4)
  ... step 6/47  loss=0.4267  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 8.511e+00 (batch 6)
  ... step 8/47  loss=0.7782  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 8.256e+00 (batch 8)
  ... step 10/47  loss=0.8798  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 1.264e+01 (batch 10)
  ... step 12/47  loss=0.4985  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 6.534e+00 (batch 12)
  ... step 14/47  loss=0.6057  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 7.231e+00 (batch 14)
  ... step 16/47  loss=0.5184  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 8.470e+00 (batch 16)
  ... step 18/47  loss=0.6895  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 1.079e+01 (batch 18)
  ... step 20/47  loss=0.3815  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 6.741e+00 (batch 20)
  ... step 22/47  loss=0.4380  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 6.152e+00 (batch 22)
  ... step 24/47  loss=0.4839  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 6.729e+00 (batch 24)
  ... step 26/47  loss=0.6663  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 8.595e+00 (batch 26)
  ... step 28/47  loss=0.6883  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 8.952e+00 (batch 28)
  ... step 30/47  loss=0.2459  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 6.072e+00 (batch 30)
  ... step 32/47  loss=0.3510  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 4.434e+00 (batch 32)
  ... step 34/47  loss=0.4220  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 8.152e+00 (batch 34)
  ... step 36/47  loss=0.5294  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 7.562e+00 (batch 36)
  ... step 38/47  loss=0.4418  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 6.861e+00 (batch 38)
  ... step 40/47  loss=0.5878  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 6.298e+00 (batch 40)
  ... step 42/47  loss=0.5465  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 6.313e+00 (batch 42)
  ... step 44/47  loss=0.2193  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 4.474e+00 (batch 44)
  ... step 46/47  loss=0.3093  (0.6s since last print)
  â†˜ grad L2 norm â‰ˆ 1.311e+01 (batch 46)
âœ… epoch 13 forward/backward done in 25.4s
  ðŸ”Ž val step 0: batch (8, 32, 2, 324, 1, 16) loss=1.8531
[13] train=0.5405  val=0.7797  RMSE(std)=[Qi:0.874, Qe:0.920, Î“:0.854]  RMSE(phys)=[Qi:63.493, Qe:85.118, Î“:37.697]  (1.5s)
âœ… Saved unified NN â†’ ./mnt/data/bin.cgyro.nn
ðŸŸ¦ Starting epoch 14/20 (train steps â‰ˆ 47)
  ... step 0/47  loss=0.4403  (0.1s since last print)
  â†˜ grad L2 norm â‰ˆ 9.357e+00 (batch 0)
  ... step 2/47  loss=0.6976  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 7.126e+00 (batch 2)
  ... step 4/47  loss=0.4891  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 6.680e+00 (batch 4)
  ... step 6/47  loss=0.5001  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 8.432e+00 (batch 6)
  ... step 8/47  loss=0.8145  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 1.211e+01 (batch 8)
  ... step 10/47  loss=0.5176  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 7.424e+00 (batch 10)
  ... step 12/47  loss=0.5585  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 9.974e+00 (batch 12)
  ... step 14/47  loss=0.2656  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 4.405e+00 (batch 14)
  ... step 16/47  loss=0.5932  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 7.770e+00 (batch 16)
  ... step 18/47  loss=0.5142  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 5.999e+00 (batch 18)
  ... step 20/47  loss=0.6274  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 8.601e+00 (batch 20)
  ... step 22/47  loss=0.4333  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 7.575e+00 (batch 22)
  ... step 24/47  loss=0.3127  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 6.249e+00 (batch 24)
  ... step 26/47  loss=0.5154  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 7.396e+00 (batch 26)
  ... step 28/47  loss=0.8866  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 8.836e+00 (batch 28)
  ... step 30/47  loss=0.5100  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 9.979e+00 (batch 30)
  ... step 32/47  loss=0.3663  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 5.601e+00 (batch 32)
  ... step 34/47  loss=0.5961  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 1.213e+01 (batch 34)
  ... step 36/47  loss=0.3157  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 4.441e+00 (batch 36)
  ... step 38/47  loss=0.3023  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 4.737e+00 (batch 38)
  ... step 40/47  loss=0.3424  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 4.364e+00 (batch 40)
  ... step 42/47  loss=0.6477  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 8.185e+00 (batch 42)
  ... step 44/47  loss=0.4234  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 5.065e+00 (batch 44)
  ... step 46/47  loss=1.8581  (0.6s since last print)
  â†˜ grad L2 norm â‰ˆ 5.306e+01 (batch 46)
âœ… epoch 14 forward/backward done in 25.4s
  ðŸ”Ž val step 0: batch (8, 32, 2, 324, 1, 16) loss=2.4382
[14] train=0.5522  val=0.9003  RMSE(std)=[Qi:0.936, Qe:0.980, Î“:0.930]  RMSE(phys)=[Qi:67.979, Qe:90.705, Î“:41.050]  (1.5s)
âœ… Saved unified NN â†’ ./mnt/data/bin.cgyro.nn
ðŸŸ¦ Starting epoch 15/20 (train steps â‰ˆ 47)
  ... step 0/47  loss=0.5081  (0.1s since last print)
  â†˜ grad L2 norm â‰ˆ 7.483e+00 (batch 0)
  ... step 2/47  loss=0.3502  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 6.886e+00 (batch 2)
  ... step 4/47  loss=0.2335  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 4.638e+00 (batch 4)
  ... step 6/47  loss=0.5282  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 6.603e+00 (batch 6)
  ... step 8/47  loss=0.7007  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 8.884e+00 (batch 8)
  ... step 10/47  loss=0.4676  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 6.794e+00 (batch 10)
  ... step 12/47  loss=0.2592  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 3.864e+00 (batch 12)
  ... step 14/47  loss=0.3921  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 4.764e+00 (batch 14)
  ... step 16/47  loss=0.3489  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 4.953e+00 (batch 16)
  ... step 18/47  loss=0.4269  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 6.577e+00 (batch 18)
  ... step 20/47  loss=0.5411  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 6.583e+00 (batch 20)
  ... step 22/47  loss=0.9996  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 1.085e+01 (batch 22)
  ... step 24/47  loss=0.9107  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 9.093e+00 (batch 24)
  ... step 26/47  loss=0.6427  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 7.042e+00 (batch 26)
  ... step 28/47  loss=0.5706  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 7.522e+00 (batch 28)
  ... step 30/47  loss=0.7467  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 9.114e+00 (batch 30)
  ... step 32/47  loss=0.6818  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 9.159e+00 (batch 32)
  ... step 34/47  loss=0.5728  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 6.776e+00 (batch 34)
  ... step 36/47  loss=0.6963  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 8.490e+00 (batch 36)
  ... step 38/47  loss=0.3696  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 5.104e+00 (batch 38)
  ... step 40/47  loss=0.6505  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 7.468e+00 (batch 40)
  ... step 42/47  loss=0.3302  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 7.292e+00 (batch 42)
  ... step 44/47  loss=0.4210  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 6.973e+00 (batch 44)
  ... step 46/47  loss=0.2753  (0.6s since last print)
  â†˜ grad L2 norm â‰ˆ 1.375e+01 (batch 46)
âœ… epoch 15 forward/backward done in 25.4s
  ðŸ”Ž val step 0: batch (8, 32, 2, 324, 1, 16) loss=1.8398
[15] train=0.5451  val=0.8585  RMSE(std)=[Qi:0.914, Qe:0.966, Î“:0.898]  RMSE(phys)=[Qi:66.386, Qe:89.388, Î“:39.668]  (1.5s)
âœ… Saved unified NN â†’ ./mnt/data/bin.cgyro.nn
ðŸŸ¦ Starting epoch 16/20 (train steps â‰ˆ 47)
  ... step 0/47  loss=0.2200  (0.1s since last print)
  â†˜ grad L2 norm â‰ˆ 3.040e+00 (batch 0)
  ... step 2/47  loss=0.5777  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 8.107e+00 (batch 2)
  ... step 4/47  loss=0.4146  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 5.890e+00 (batch 4)
  ... step 6/47  loss=0.5381  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 6.947e+00 (batch 6)
  ... step 8/47  loss=0.2691  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 6.909e+00 (batch 8)
  ... step 10/47  loss=0.4211  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 6.679e+00 (batch 10)
  ... step 12/47  loss=0.3775  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 6.498e+00 (batch 12)
  ... step 14/47  loss=0.7687  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 1.035e+01 (batch 14)
  ... step 16/47  loss=0.6276  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 1.156e+01 (batch 16)
  ... step 18/47  loss=0.4055  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 8.130e+00 (batch 18)
  ... step 20/47  loss=0.2644  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 6.715e+00 (batch 20)
  ... step 22/47  loss=0.5140  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 1.011e+01 (batch 22)
  ... step 24/47  loss=0.6005  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 8.989e+00 (batch 24)
  ... step 26/47  loss=0.5702  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 8.693e+00 (batch 26)
  ... step 28/47  loss=0.5485  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 7.524e+00 (batch 28)
  ... step 30/47  loss=0.7943  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 1.174e+01 (batch 30)
  ... step 32/47  loss=0.3631  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 7.334e+00 (batch 32)
  ... step 34/47  loss=0.4327  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 5.244e+00 (batch 34)
  ... step 36/47  loss=0.5208  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 7.374e+00 (batch 36)
  ... step 38/47  loss=0.3207  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 6.644e+00 (batch 38)
  ... step 40/47  loss=0.2886  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 5.808e+00 (batch 40)
  ... step 42/47  loss=0.7498  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 1.021e+01 (batch 42)
  ... step 44/47  loss=0.8387  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 1.128e+01 (batch 44)
  ... step 46/47  loss=1.0537  (0.6s since last print)
  â†˜ grad L2 norm â‰ˆ 3.300e+01 (batch 46)
âœ… epoch 16 forward/backward done in 25.4s
  ðŸ”Ž val step 0: batch (8, 32, 2, 324, 1, 16) loss=3.5316
[16] train=0.5129  val=1.1104  RMSE(std)=[Qi:1.044, Qe:1.078, Î“:1.039]  RMSE(phys)=[Qi:75.837, Qe:99.743, Î“:45.872]  (1.5s)
âœ… Saved unified NN â†’ ./mnt/data/bin.cgyro.nn
ðŸŸ¦ Starting epoch 17/20 (train steps â‰ˆ 47)
  ... step 0/47  loss=0.7259  (0.1s since last print)
  â†˜ grad L2 norm â‰ˆ 9.346e+00 (batch 0)
  ... step 2/47  loss=0.1919  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 3.373e+00 (batch 2)
  ... step 4/47  loss=0.4915  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 9.518e+00 (batch 4)
  ... step 6/47  loss=0.4324  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 7.320e+00 (batch 6)
  ... step 8/47  loss=0.7874  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 9.840e+00 (batch 8)
  ... step 10/47  loss=0.6624  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 7.910e+00 (batch 10)
  ... step 12/47  loss=0.3486  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 6.474e+00 (batch 12)
  ... step 14/47  loss=0.3884  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 5.524e+00 (batch 14)
  ... step 16/47  loss=0.5718  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 5.946e+00 (batch 16)
  ... step 18/47  loss=0.4446  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 6.567e+00 (batch 18)
  ... step 20/47  loss=0.3531  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 6.739e+00 (batch 20)
  ... step 22/47  loss=0.6148  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 7.484e+00 (batch 22)
  ... step 24/47  loss=0.4966  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 6.732e+00 (batch 24)
  ... step 26/47  loss=0.7074  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 9.763e+00 (batch 26)
  ... step 28/47  loss=0.7412  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 9.553e+00 (batch 28)
  ... step 30/47  loss=0.2461  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 6.310e+00 (batch 30)
  ... step 32/47  loss=0.1903  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 5.344e+00 (batch 32)
  ... step 34/47  loss=0.3962  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 6.116e+00 (batch 34)
  ... step 36/47  loss=0.5141  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 6.474e+00 (batch 36)
  ... step 38/47  loss=0.3397  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 5.211e+00 (batch 38)
  ... step 40/47  loss=0.6098  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 8.379e+00 (batch 40)
  ... step 42/47  loss=0.3060  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 4.842e+00 (batch 42)
  ... step 44/47  loss=0.2382  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 4.062e+00 (batch 44)
  ... step 46/47  loss=1.1255  (0.6s since last print)
  â†˜ grad L2 norm â‰ˆ 4.101e+01 (batch 46)
âœ… epoch 17 forward/backward done in 25.4s
  ðŸ”Ž val step 0: batch (8, 32, 2, 324, 1, 16) loss=2.8136
[17] train=0.4663  val=0.9112  RMSE(std)=[Qi:0.951, Qe:0.978, Î“:0.934]  RMSE(phys)=[Qi:69.066, Qe:90.494, Î“:41.257]  (1.5s)
âœ… Saved unified NN â†’ ./mnt/data/bin.cgyro.nn
ðŸŸ¦ Starting epoch 18/20 (train steps â‰ˆ 47)
  ... step 0/47  loss=0.4645  (0.1s since last print)
  â†˜ grad L2 norm â‰ˆ 7.230e+00 (batch 0)
  ... step 2/47  loss=0.7186  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 9.677e+00 (batch 2)
  ... step 4/47  loss=0.5596  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 9.277e+00 (batch 4)
  ... step 6/47  loss=0.7635  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 1.473e+01 (batch 6)
  ... step 8/47  loss=0.4821  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 1.184e+01 (batch 8)
  ... step 10/47  loss=0.2505  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 4.712e+00 (batch 10)
  ... step 12/47  loss=0.5702  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 8.476e+00 (batch 12)
  ... step 14/47  loss=0.7035  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 1.127e+01 (batch 14)
  ... step 16/47  loss=0.4835  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 6.927e+00 (batch 16)
  ... step 18/47  loss=0.4167  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 8.021e+00 (batch 18)
  ... step 20/47  loss=0.3860  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 7.358e+00 (batch 20)
  ... step 22/47  loss=0.3140  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 9.618e+00 (batch 22)
  ... step 24/47  loss=0.5066  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 8.037e+00 (batch 24)
  ... step 26/47  loss=0.3899  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 7.746e+00 (batch 26)
  ... step 28/47  loss=0.3858  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 5.955e+00 (batch 28)
  ... step 30/47  loss=0.3309  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 6.208e+00 (batch 30)
  ... step 32/47  loss=0.3914  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 5.256e+00 (batch 32)
  ... step 34/47  loss=0.5319  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 8.300e+00 (batch 34)
  ... step 36/47  loss=0.5384  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 5.316e+00 (batch 36)
  ... step 38/47  loss=0.4380  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 8.320e+00 (batch 38)
  ... step 40/47  loss=0.2082  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 4.411e+00 (batch 40)
  ... step 42/47  loss=0.3677  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 6.984e+00 (batch 42)
  ... step 44/47  loss=0.3076  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 6.021e+00 (batch 44)
  ... step 46/47  loss=0.2543  (0.6s since last print)
  â†˜ grad L2 norm â‰ˆ 2.078e+01 (batch 46)
âœ… epoch 18 forward/backward done in 25.4s
  ðŸ”Ž val step 0: batch (8, 32, 2, 324, 1, 16) loss=4.0850
[18] train=0.4628  val=1.3446  RMSE(std)=[Qi:1.159, Qe:1.182, Î“:1.137]  RMSE(phys)=[Qi:84.172, Qe:109.433, Î“:50.200]  (1.5s)
âœ… Saved unified NN â†’ ./mnt/data/bin.cgyro.nn
ðŸŸ¦ Starting epoch 19/20 (train steps â‰ˆ 47)
  ... step 0/47  loss=0.4721  (0.1s since last print)
  â†˜ grad L2 norm â‰ˆ 8.906e+00 (batch 0)
  ... step 2/47  loss=0.8982  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 1.438e+01 (batch 2)
  ... step 4/47  loss=0.4164  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 8.330e+00 (batch 4)
  ... step 6/47  loss=0.4524  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 8.040e+00 (batch 6)
  ... step 8/47  loss=0.2203  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 4.295e+00 (batch 8)
  ... step 10/47  loss=0.3126  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 8.532e+00 (batch 10)
  ... step 12/47  loss=0.4185  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 7.037e+00 (batch 12)
  ... step 14/47  loss=0.3587  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 7.641e+00 (batch 14)
  ... step 16/47  loss=0.3365  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 4.798e+00 (batch 16)
  ... step 18/47  loss=0.3573  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 5.192e+00 (batch 18)
  ... step 20/47  loss=0.7000  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 9.282e+00 (batch 20)
  ... step 22/47  loss=0.5356  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 9.606e+00 (batch 22)
  ... step 24/47  loss=0.4845  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 6.611e+00 (batch 24)
  ... step 26/47  loss=0.2519  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 4.314e+00 (batch 26)
  ... step 28/47  loss=0.3897  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 8.774e+00 (batch 28)
  ... step 30/47  loss=0.2757  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 4.597e+00 (batch 30)
  ... step 32/47  loss=0.5041  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 6.778e+00 (batch 32)
  ... step 34/47  loss=0.3192  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 6.060e+00 (batch 34)
  ... step 36/47  loss=0.7843  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 9.643e+00 (batch 36)
  ... step 38/47  loss=0.2134  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 3.750e+00 (batch 38)
  ... step 40/47  loss=0.4199  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 6.026e+00 (batch 40)
  ... step 42/47  loss=0.2652  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 5.516e+00 (batch 42)
  ... step 44/47  loss=0.4336  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 8.168e+00 (batch 44)
  ... step 46/47  loss=0.7379  (0.6s since last print)
  â†˜ grad L2 norm â‰ˆ 1.878e+01 (batch 46)
âœ… epoch 19 forward/backward done in 25.4s
  ðŸ”Ž val step 0: batch (8, 32, 2, 324, 1, 16) loss=3.3046
[19] train=0.4477  val=1.0455  RMSE(std)=[Qi:1.025, Qe:1.042, Î“:1.000]  RMSE(phys)=[Qi:74.409, Qe:96.471, Î“:44.158]  (1.5s)
âœ… Saved unified NN â†’ ./mnt/data/bin.cgyro.nn
ðŸŸ¦ Starting epoch 20/20 (train steps â‰ˆ 47)
  ... step 0/47  loss=0.4624  (0.1s since last print)
  â†˜ grad L2 norm â‰ˆ 8.349e+00 (batch 0)
  ... step 2/47  loss=0.3734  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 5.302e+00 (batch 2)
  ... step 4/47  loss=0.2336  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 4.233e+00 (batch 4)
  ... step 6/47  loss=0.7591  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 1.145e+01 (batch 6)
  ... step 8/47  loss=0.3189  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 5.945e+00 (batch 8)
  ... step 10/47  loss=0.2857  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 3.808e+00 (batch 10)
  ... step 12/47  loss=0.6172  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 1.051e+01 (batch 12)
  ... step 14/47  loss=0.6129  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 8.606e+00 (batch 14)
  ... step 16/47  loss=0.4315  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 4.775e+00 (batch 16)
  ... step 18/47  loss=0.6920  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 8.173e+00 (batch 18)
  ... step 20/47  loss=0.3132  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 5.518e+00 (batch 20)
  ... step 22/47  loss=0.5507  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 6.464e+00 (batch 22)
  ... step 24/47  loss=0.2147  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 2.808e+00 (batch 24)
  ... step 26/47  loss=0.4597  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 8.260e+00 (batch 26)
  ... step 28/47  loss=0.3004  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 6.208e+00 (batch 28)
  ... step 30/47  loss=0.3203  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 4.172e+00 (batch 30)
  ... step 32/47  loss=0.3620  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 6.816e+00 (batch 32)
  ... step 34/47  loss=0.4534  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 7.557e+00 (batch 34)
  ... step 36/47  loss=0.1962  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 3.868e+00 (batch 36)
  ... step 38/47  loss=0.2956  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 7.490e+00 (batch 38)
  ... step 40/47  loss=0.1841  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 4.425e+00 (batch 40)
  ... step 42/47  loss=0.4309  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 7.070e+00 (batch 42)
  ... step 44/47  loss=0.2041  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 6.334e+00 (batch 44)
  ... step 46/47  loss=0.2952  (0.6s since last print)
  â†˜ grad L2 norm â‰ˆ 3.105e+01 (batch 46)
âœ… epoch 20 forward/backward done in 25.4s
  ðŸ”Ž val step 0: batch (8, 32, 2, 324, 1, 16) loss=1.5941
[20] train=0.4348  val=0.7302  RMSE(std)=[Qi:0.848, Qe:0.891, Î“:0.824]  RMSE(phys)=[Qi:61.555, Qe:82.442, Î“:36.376]  (1.5s)
âœ… Saved unified NN â†’ ./mnt/data/bin.cgyro.nn
Saved metrics â†’ ./mnt/data/myrun_logs_deep_debug_ordered_t/metrics.csv
âœ… Final unified NN â†’ ./mnt/data/bin.cgyro.nn
âœ… Training complete. Artifacts in: ./mnt/data/myrun_logs_deep_debug_ordered_t
