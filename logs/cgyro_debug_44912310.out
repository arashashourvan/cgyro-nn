[build_datasets] windows: total=583  train=349  val=116  test=118

[train] dataset:
  y_mean: [[[151.75755 226.04332  90.37167]]]
  y_std : [[[74.70836 95.86813 45.35161]]]
  sample Y: min=-1.322e+00, max=1.959e+00, mean=-1.599e-01, std=7.659e-01

[val] dataset:
  y_mean: [[[151.75755 226.04332  90.37167]]]
  y_std : [[[74.70836 95.86813 45.35161]]]
  sample Y: min=-1.931e+00, max=2.661e+00, mean=-2.372e-01, std=1.144e+00

[test] dataset:
  y_mean: [[[151.75755 226.04332  90.37167]]]
  y_std : [[[74.70836 95.86813 45.35161]]]
  sample Y: min=-1.829e+00, max=2.945e+00, mean=-8.542e-02, std=1.517e+00
âœ… Saved flux histograms in ./mnt/data/myrun_logs_deep_debug_ordered_t
ğŸŸ¦ Starting epoch 1/30 (train steps â‰ˆ 44)
[2153668] Î¦2FluxDeep forward: input (8, 64, 2, 324, 1, 16)
  ... step 0/44  loss=0.3880  (9.8s since last print)
  â†˜ grad L2 norm â‰ˆ 7.835e+00 (batch 0)
  ... step 2/44  loss=0.8191  (1.7s since last print)
  â†˜ grad L2 norm â‰ˆ 1.106e+01 (batch 2)
  ... step 4/44  loss=0.8022  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 9.014e+00 (batch 4)
  ... step 6/44  loss=1.0127  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 1.094e+01 (batch 6)
  ... step 8/44  loss=0.5298  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 7.850e+00 (batch 8)
  ... step 10/44  loss=0.4338  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 6.250e+00 (batch 10)
  ... step 12/44  loss=0.7933  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 1.046e+01 (batch 12)
  ... step 14/44  loss=1.3803  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 1.278e+01 (batch 14)
  ... step 16/44  loss=1.2653  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 1.243e+01 (batch 16)
  ... step 18/44  loss=1.1329  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 1.066e+01 (batch 18)
  ... step 20/44  loss=1.3613  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 1.246e+01 (batch 20)
  ... step 22/44  loss=0.6494  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 7.488e+00 (batch 22)
  ... step 24/44  loss=0.8118  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 1.057e+01 (batch 24)
  ... step 26/44  loss=1.5213  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 1.297e+01 (batch 26)
  ... step 28/44  loss=1.0761  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 9.821e+00 (batch 28)
  ... step 30/44  loss=1.2546  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 1.269e+01 (batch 30)
  ... step 32/44  loss=1.3647  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 1.140e+01 (batch 32)
  ... step 34/44  loss=0.8598  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 9.383e+00 (batch 34)
  ... step 36/44  loss=1.0964  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 1.001e+01 (batch 36)
  ... step 38/44  loss=0.5817  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 9.044e+00 (batch 38)
  ... step 40/44  loss=1.7433  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 1.331e+01 (batch 40)
  ... step 42/44  loss=1.3105  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 1.125e+01 (batch 42)
âœ… epoch 1 forward/backward done in 58.5s
  ğŸ” val step 0: batch (8, 64, 2, 324, 1, 16) loss=2.9652
[01] train=1.0353  val=1.3371  RMSE(std)=[Qi:1.148, Qe:1.184, Î“:1.136]  RMSE(phys)=[Qi:85.793, Qe:113.527, Î“:51.513]  (3.9s)
âœ… Saved unified NN â†’ ./mnt/data/bin.cgyro.nn
ğŸŸ¦ Starting epoch 2/30 (train steps â‰ˆ 44)
  ... step 0/44  loss=0.8864  (0.3s since last print)
  â†˜ grad L2 norm â‰ˆ 8.971e+00 (batch 0)
  ... step 2/44  loss=0.8524  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 9.797e+00 (batch 2)
  ... step 4/44  loss=0.5214  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 6.965e+00 (batch 4)
  ... step 6/44  loss=0.7216  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 8.639e+00 (batch 6)
  ... step 8/44  loss=1.2558  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 1.013e+01 (batch 8)
  ... step 10/44  loss=0.7231  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 8.742e+00 (batch 10)
  ... step 12/44  loss=0.7878  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 7.457e+00 (batch 12)
  ... step 14/44  loss=1.2110  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 1.017e+01 (batch 14)
  ... step 16/44  loss=0.8118  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 6.877e+00 (batch 16)
  ... step 18/44  loss=0.9531  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 1.069e+01 (batch 18)
  ... step 20/44  loss=0.9909  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 9.153e+00 (batch 20)
  ... step 22/44  loss=0.5643  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 6.658e+00 (batch 22)
  ... step 24/44  loss=0.3467  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 5.629e+00 (batch 24)
  ... step 26/44  loss=0.4313  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 7.242e+00 (batch 26)
  ... step 28/44  loss=1.7029  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 1.151e+01 (batch 28)
  ... step 30/44  loss=1.1086  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 9.876e+00 (batch 30)
  ... step 32/44  loss=1.1608  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 1.177e+01 (batch 32)
  ... step 34/44  loss=0.7846  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 8.305e+00 (batch 34)
  ... step 36/44  loss=1.1525  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 8.412e+00 (batch 36)
  ... step 38/44  loss=1.1965  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 1.017e+01 (batch 38)
  ... step 40/44  loss=1.3440  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 9.161e+00 (batch 40)
  ... step 42/44  loss=1.1292  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 8.782e+00 (batch 42)
âœ… epoch 2 forward/backward done in 49.6s
  ğŸ” val step 0: batch (8, 64, 2, 324, 1, 16) loss=2.2412
[02] train=0.9733  val=1.3178  RMSE(std)=[Qi:1.132, Qe:1.177, Î“:1.134]  RMSE(phys)=[Qi:84.595, Qe:112.860, Î“:51.416]  (3.9s)
âœ… Saved unified NN â†’ ./mnt/data/bin.cgyro.nn
ğŸŸ¦ Starting epoch 3/30 (train steps â‰ˆ 44)
  ... step 0/44  loss=0.9786  (0.3s since last print)
  â†˜ grad L2 norm â‰ˆ 9.397e+00 (batch 0)
  ... step 2/44  loss=0.7799  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 9.125e+00 (batch 2)
  ... step 4/44  loss=0.8208  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 8.881e+00 (batch 4)
  ... step 6/44  loss=0.7366  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 6.999e+00 (batch 6)
  ... step 8/44  loss=1.0236  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 1.054e+01 (batch 8)
  ... step 10/44  loss=0.7199  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 6.980e+00 (batch 10)
  ... step 12/44  loss=1.0641  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 1.029e+01 (batch 12)
  ... step 14/44  loss=1.1895  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 1.066e+01 (batch 14)
  ... step 16/44  loss=0.7671  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 7.347e+00 (batch 16)
  ... step 18/44  loss=1.4551  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 1.095e+01 (batch 18)
  ... step 20/44  loss=0.5450  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 7.252e+00 (batch 20)
  ... step 22/44  loss=1.1314  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 9.205e+00 (batch 22)
  ... step 24/44  loss=1.0088  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 8.841e+00 (batch 24)
  ... step 26/44  loss=0.7039  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 7.990e+00 (batch 26)
  ... step 28/44  loss=0.5361  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 8.180e+00 (batch 28)
  ... step 30/44  loss=0.8706  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 8.290e+00 (batch 30)
  ... step 32/44  loss=0.9336  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 1.187e+01 (batch 32)
  ... step 34/44  loss=0.8441  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 1.173e+01 (batch 34)
  ... step 36/44  loss=0.7415  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 7.984e+00 (batch 36)
  ... step 38/44  loss=0.6303  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 7.935e+00 (batch 38)
  ... step 40/44  loss=1.0953  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 9.725e+00 (batch 40)
  ... step 42/44  loss=0.8002  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 9.568e+00 (batch 42)
âœ… epoch 3 forward/backward done in 49.6s
  ğŸ” val step 0: batch (8, 64, 2, 324, 1, 16) loss=11.1849
[03] train=0.8804  val=5.5062  RMSE(std)=[Qi:2.334, Qe:2.599, Î“:2.077]  RMSE(phys)=[Qi:174.402, Qe:249.159, Î“:94.199]  (3.9s)
âœ… Saved unified NN â†’ ./mnt/data/bin.cgyro.nn
ğŸŸ¦ Starting epoch 4/30 (train steps â‰ˆ 44)
  ... step 0/44  loss=0.7181  (0.3s since last print)
  â†˜ grad L2 norm â‰ˆ 9.060e+00 (batch 0)
  ... step 2/44  loss=0.7721  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 9.515e+00 (batch 2)
  ... step 4/44  loss=0.3614  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 6.781e+00 (batch 4)
  ... step 6/44  loss=1.4483  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 1.253e+01 (batch 6)
  ... step 8/44  loss=1.1746  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 1.314e+01 (batch 8)
  ... step 10/44  loss=0.5174  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 5.991e+00 (batch 10)
  ... step 12/44  loss=0.8619  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 9.817e+00 (batch 12)
  ... step 14/44  loss=0.7971  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 9.264e+00 (batch 14)
  ... step 16/44  loss=0.5482  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 8.201e+00 (batch 16)
  ... step 18/44  loss=0.7096  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 9.707e+00 (batch 18)
  ... step 20/44  loss=0.8601  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 1.033e+01 (batch 20)
  ... step 22/44  loss=1.1753  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 1.440e+01 (batch 22)
  ... step 24/44  loss=1.2523  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 1.271e+01 (batch 24)
  ... step 26/44  loss=0.6150  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 7.702e+00 (batch 26)
  ... step 28/44  loss=0.3637  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 5.749e+00 (batch 28)
  ... step 30/44  loss=0.6473  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 9.299e+00 (batch 30)
  ... step 32/44  loss=0.7624  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 8.575e+00 (batch 32)
  ... step 34/44  loss=0.9849  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 1.144e+01 (batch 34)
  ... step 36/44  loss=0.4359  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 7.792e+00 (batch 36)
  ... step 38/44  loss=1.0638  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 1.498e+01 (batch 38)
  ... step 40/44  loss=0.8843  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 1.377e+01 (batch 40)
  ... step 42/44  loss=0.5363  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 7.506e+00 (batch 42)
âœ… epoch 4 forward/backward done in 49.6s
  ğŸ” val step 0: batch (8, 64, 2, 324, 1, 16) loss=16.9324
[04] train=0.7602  val=8.8000  RMSE(std)=[Qi:3.028, Qe:2.987, Î“:2.883]  RMSE(phys)=[Qi:226.223, Qe:286.325, Î“:130.740]  (3.9s)
âœ… Saved unified NN â†’ ./mnt/data/bin.cgyro.nn
ğŸŸ¦ Starting epoch 5/30 (train steps â‰ˆ 44)
  ... step 0/44  loss=0.3531  (0.3s since last print)
  â†˜ grad L2 norm â‰ˆ 5.424e+00 (batch 0)
  ... step 2/44  loss=1.1332  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 1.225e+01 (batch 2)
  ... step 4/44  loss=0.6009  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 9.615e+00 (batch 4)
  ... step 6/44  loss=0.8445  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 1.534e+01 (batch 6)
  ... step 8/44  loss=0.6273  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 7.898e+00 (batch 8)
  ... step 10/44  loss=0.9853  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 1.694e+01 (batch 10)
  ... step 12/44  loss=0.7698  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 1.139e+01 (batch 12)
  ... step 14/44  loss=0.5753  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 1.025e+01 (batch 14)
  ... step 16/44  loss=1.0063  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 1.412e+01 (batch 16)
  ... step 18/44  loss=0.9169  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 1.032e+01 (batch 18)
  ... step 20/44  loss=0.4379  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 9.219e+00 (batch 20)
  ... step 22/44  loss=0.5188  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 1.280e+01 (batch 22)
  ... step 24/44  loss=1.0959  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 1.612e+01 (batch 24)
  ... step 26/44  loss=0.2289  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 4.175e+00 (batch 26)
  ... step 28/44  loss=0.8422  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 1.917e+01 (batch 28)
  ... step 30/44  loss=0.6288  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 1.029e+01 (batch 30)
  ... step 32/44  loss=0.8182  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 1.071e+01 (batch 32)
  ... step 34/44  loss=0.5107  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 7.550e+00 (batch 34)
  ... step 36/44  loss=0.5652  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 8.359e+00 (batch 36)
  ... step 38/44  loss=0.6791  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 8.093e+00 (batch 38)
  ... step 40/44  loss=0.5213  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 7.308e+00 (batch 40)
  ... step 42/44  loss=1.0798  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 1.194e+01 (batch 42)
âœ… epoch 5 forward/backward done in 49.6s
  ğŸ” val step 0: batch (8, 64, 2, 324, 1, 16) loss=19.1636
[05] train=0.7056  val=10.4557  RMSE(std)=[Qi:3.518, Qe:3.056, Î“:3.107]  RMSE(phys)=[Qi:262.824, Qe:292.992, Î“:140.886]  (3.9s)
âœ… Saved unified NN â†’ ./mnt/data/bin.cgyro.nn
ğŸŸ¦ Starting epoch 6/30 (train steps â‰ˆ 44)
  ... step 0/44  loss=0.6053  (0.3s since last print)
  â†˜ grad L2 norm â‰ˆ 1.113e+01 (batch 0)
  ... step 2/44  loss=0.3603  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 5.037e+00 (batch 2)
  ... step 4/44  loss=0.6579  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 7.454e+00 (batch 4)
  ... step 6/44  loss=0.6558  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 9.644e+00 (batch 6)
  ... step 8/44  loss=0.4601  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 7.301e+00 (batch 8)
  ... step 10/44  loss=1.3220  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 1.218e+01 (batch 10)
  ... step 12/44  loss=0.7662  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 1.025e+01 (batch 12)
  ... step 14/44  loss=0.5889  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 8.060e+00 (batch 14)
  ... step 16/44  loss=0.7576  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 7.522e+00 (batch 16)
  ... step 18/44  loss=0.3453  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 5.903e+00 (batch 18)
  ... step 20/44  loss=0.3706  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 5.983e+00 (batch 20)
  ... step 22/44  loss=1.2922  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 1.298e+01 (batch 22)
  ... step 24/44  loss=0.2860  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 4.274e+00 (batch 24)
  ... step 26/44  loss=0.8189  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 1.010e+01 (batch 26)
  ... step 28/44  loss=0.4191  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 6.273e+00 (batch 28)
  ... step 30/44  loss=0.7972  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 1.251e+01 (batch 30)
  ... step 32/44  loss=0.6389  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 8.587e+00 (batch 32)
  ... step 34/44  loss=0.6624  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 9.313e+00 (batch 34)
  ... step 36/44  loss=0.3968  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 6.124e+00 (batch 36)
  ... step 38/44  loss=0.8170  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 9.588e+00 (batch 38)
  ... step 40/44  loss=0.3446  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 5.819e+00 (batch 40)
  ... step 42/44  loss=0.5429  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 7.517e+00 (batch 42)
âœ… epoch 6 forward/backward done in 49.6s
  ğŸ” val step 0: batch (8, 64, 2, 324, 1, 16) loss=29.7417
[06] train=0.6393  val=18.5040  RMSE(std)=[Qi:4.566, Qe:4.218, Î“:4.108]  RMSE(phys)=[Qi:341.096, Qe:404.382, Î“:186.295]  (3.9s)
âœ… Saved unified NN â†’ ./mnt/data/bin.cgyro.nn
ğŸŸ¦ Starting epoch 7/30 (train steps â‰ˆ 44)
  ... step 0/44  loss=0.7121  (0.3s since last print)
  â†˜ grad L2 norm â‰ˆ 9.986e+00 (batch 0)
  ... step 2/44  loss=0.5884  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 9.077e+00 (batch 2)
  ... step 4/44  loss=0.6921  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 8.932e+00 (batch 4)
  ... step 6/44  loss=0.4320  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 6.332e+00 (batch 6)
  ... step 8/44  loss=0.2723  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 5.603e+00 (batch 8)
  ... step 10/44  loss=0.9721  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 8.898e+00 (batch 10)
  ... step 12/44  loss=0.5372  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 6.219e+00 (batch 12)
  ... step 14/44  loss=0.5443  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 6.755e+00 (batch 14)
  ... step 16/44  loss=0.7883  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 1.005e+01 (batch 16)
  ... step 18/44  loss=0.4855  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 8.999e+00 (batch 18)
  ... step 20/44  loss=0.6442  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 7.550e+00 (batch 20)
  ... step 22/44  loss=0.5789  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 6.866e+00 (batch 22)
  ... step 24/44  loss=0.3584  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 6.147e+00 (batch 24)
  ... step 26/44  loss=0.6358  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 7.109e+00 (batch 26)
  ... step 28/44  loss=0.7483  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 8.292e+00 (batch 28)
  ... step 30/44  loss=0.3906  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 5.646e+00 (batch 30)
  ... step 32/44  loss=0.3055  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 5.555e+00 (batch 32)
  ... step 34/44  loss=0.5584  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 6.248e+00 (batch 34)
  ... step 36/44  loss=0.5648  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 5.814e+00 (batch 36)
  ... step 38/44  loss=0.3859  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 5.296e+00 (batch 38)
  ... step 40/44  loss=0.5730  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 7.514e+00 (batch 40)
  ... step 42/44  loss=0.3469  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 4.497e+00 (batch 42)
âœ… epoch 7 forward/backward done in 49.5s
  ğŸ” val step 0: batch (8, 64, 2, 324, 1, 16) loss=38.0647
[07] train=0.5983  val=25.6385  RMSE(std)=[Qi:5.214, Qe:5.183, Î“:4.783]  RMSE(phys)=[Qi:389.496, Qe:496.846, Î“:216.908]  (3.9s)
âœ… Saved unified NN â†’ ./mnt/data/bin.cgyro.nn
ğŸŸ¦ Starting epoch 8/30 (train steps â‰ˆ 44)
  ... step 0/44  loss=0.6346  (0.3s since last print)
  â†˜ grad L2 norm â‰ˆ 8.050e+00 (batch 0)
  ... step 2/44  loss=0.7369  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 8.619e+00 (batch 2)
  ... step 4/44  loss=0.3420  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 6.013e+00 (batch 4)
  ... step 6/44  loss=0.5838  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 7.550e+00 (batch 6)
  ... step 8/44  loss=0.5088  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 8.091e+00 (batch 8)
  ... step 10/44  loss=0.9188  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 1.098e+01 (batch 10)
  ... step 12/44  loss=0.5582  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 9.841e+00 (batch 12)
  ... step 14/44  loss=0.6677  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 1.098e+01 (batch 14)
  ... step 16/44  loss=1.1166  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 1.560e+01 (batch 16)
  ... step 18/44  loss=0.4691  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 6.135e+00 (batch 18)
  ... step 20/44  loss=0.3828  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 6.337e+00 (batch 20)
  ... step 22/44  loss=0.5108  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 1.086e+01 (batch 22)
  ... step 24/44  loss=0.6954  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 1.297e+01 (batch 24)
  ... step 26/44  loss=0.7607  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 9.746e+00 (batch 26)
  ... step 28/44  loss=0.5128  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 8.886e+00 (batch 28)
  ... step 30/44  loss=0.8919  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 9.379e+00 (batch 30)
  ... step 32/44  loss=0.2594  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 5.522e+00 (batch 32)
  ... step 34/44  loss=0.7973  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 1.120e+01 (batch 34)
  ... step 36/44  loss=0.5373  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 8.782e+00 (batch 36)
  ... step 38/44  loss=0.5136  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 8.510e+00 (batch 38)
  ... step 40/44  loss=0.3993  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 6.450e+00 (batch 40)
  ... step 42/44  loss=0.6566  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 9.220e+00 (batch 42)
âœ… epoch 8 forward/backward done in 49.6s
  ğŸ” val step 0: batch (8, 64, 2, 324, 1, 16) loss=29.5134
[08] train=0.5932  val=19.6049  RMSE(std)=[Qi:4.502, Qe:4.624, Î“:4.143]  RMSE(phys)=[Qi:336.331, Qe:443.300, Î“:187.898]  (3.9s)
âœ… Saved unified NN â†’ ./mnt/data/bin.cgyro.nn
ğŸŸ¦ Starting epoch 9/30 (train steps â‰ˆ 44)
  ... step 0/44  loss=0.7670  (0.3s since last print)
  â†˜ grad L2 norm â‰ˆ 1.102e+01 (batch 0)
  ... step 2/44  loss=0.3709  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 6.147e+00 (batch 2)
  ... step 4/44  loss=0.6220  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 7.491e+00 (batch 4)
  ... step 6/44  loss=0.5095  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 1.306e+01 (batch 6)
  ... step 8/44  loss=0.7051  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 9.758e+00 (batch 8)
  ... step 10/44  loss=0.2189  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 4.624e+00 (batch 10)
  ... step 12/44  loss=0.7658  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 1.443e+01 (batch 12)
  ... step 14/44  loss=0.6904  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 7.437e+00 (batch 14)
  ... step 16/44  loss=0.5948  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 9.300e+00 (batch 16)
  ... step 18/44  loss=1.0394  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 1.248e+01 (batch 18)
  ... step 20/44  loss=0.3281  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 6.784e+00 (batch 20)
  ... step 22/44  loss=0.2706  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 4.798e+00 (batch 22)
  ... step 24/44  loss=0.8108  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 1.265e+01 (batch 24)
  ... step 26/44  loss=0.3058  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 5.487e+00 (batch 26)
  ... step 28/44  loss=0.3882  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 5.771e+00 (batch 28)
  ... step 30/44  loss=0.3760  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 7.394e+00 (batch 30)
  ... step 32/44  loss=0.4887  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 7.354e+00 (batch 32)
  ... step 34/44  loss=0.5030  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 6.509e+00 (batch 34)
  ... step 36/44  loss=0.7299  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 8.968e+00 (batch 36)
  ... step 38/44  loss=0.5052  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 9.322e+00 (batch 38)
  ... step 40/44  loss=0.5724  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 7.085e+00 (batch 40)
  ... step 42/44  loss=0.6981  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 9.593e+00 (batch 42)
âœ… epoch 9 forward/backward done in 49.5s
  ğŸ” val step 0: batch (8, 64, 2, 324, 1, 16) loss=37.0820
[09] train=0.5487  val=23.9672  RMSE(std)=[Qi:5.243, Qe:4.999, Î“:4.408]  RMSE(phys)=[Qi:391.689, Qe:479.220, Î“:199.888]  (3.9s)
âœ… Saved unified NN â†’ ./mnt/data/bin.cgyro.nn
ğŸŸ¦ Starting epoch 10/30 (train steps â‰ˆ 44)
  ... step 0/44  loss=1.0286  (0.3s since last print)
  â†˜ grad L2 norm â‰ˆ 1.350e+01 (batch 0)
  ... step 2/44  loss=0.4245  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 6.907e+00 (batch 2)
  ... step 4/44  loss=0.7810  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 1.034e+01 (batch 4)
  ... step 6/44  loss=0.5341  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 6.926e+00 (batch 6)
  ... step 8/44  loss=0.5383  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 7.900e+00 (batch 8)
  ... step 10/44  loss=0.6892  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 1.014e+01 (batch 10)
  ... step 12/44  loss=0.5181  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 6.586e+00 (batch 12)
  ... step 14/44  loss=0.3652  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 6.540e+00 (batch 14)
  ... step 16/44  loss=0.4192  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 7.072e+00 (batch 16)
  ... step 18/44  loss=0.3635  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 6.522e+00 (batch 18)
  ... step 20/44  loss=0.5223  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 7.501e+00 (batch 20)
  ... step 22/44  loss=0.4952  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 7.953e+00 (batch 22)
  ... step 24/44  loss=0.7224  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 9.601e+00 (batch 24)
  ... step 26/44  loss=0.4770  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 8.467e+00 (batch 26)
  ... step 28/44  loss=0.2457  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 4.126e+00 (batch 28)
  ... step 30/44  loss=0.3015  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 8.512e+00 (batch 30)
  ... step 32/44  loss=0.5140  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 6.818e+00 (batch 32)
  ... step 34/44  loss=0.5505  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 6.955e+00 (batch 34)
  ... step 36/44  loss=0.5539  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 6.272e+00 (batch 36)
  ... step 38/44  loss=0.6449  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 6.717e+00 (batch 38)
  ... step 40/44  loss=0.2282  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 5.888e+00 (batch 40)
  ... step 42/44  loss=0.5831  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 8.008e+00 (batch 42)
âœ… epoch 10 forward/backward done in 49.6s
  ğŸ” val step 0: batch (8, 64, 2, 324, 1, 16) loss=17.9305
[10] train=0.5484  val=10.0517  RMSE(std)=[Qi:3.318, Qe:3.136, Î“:3.051]  RMSE(phys)=[Qi:247.914, Qe:300.661, Î“:138.359]  (3.9s)
âœ… Saved unified NN â†’ ./mnt/data/bin.cgyro.nn
ğŸŸ¦ Starting epoch 11/30 (train steps â‰ˆ 44)
  ... step 0/44  loss=0.5900  (0.3s since last print)
  â†˜ grad L2 norm â‰ˆ 7.250e+00 (batch 0)
  ... step 2/44  loss=1.0234  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 1.285e+01 (batch 2)
  ... step 4/44  loss=0.5275  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 6.420e+00 (batch 4)
  ... step 6/44  loss=0.4117  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 5.391e+00 (batch 6)
  ... step 8/44  loss=0.3579  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 6.399e+00 (batch 8)
  ... step 10/44  loss=0.6976  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 9.053e+00 (batch 10)
  ... step 12/44  loss=0.5253  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 6.810e+00 (batch 12)
  ... step 14/44  loss=0.3518  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 6.043e+00 (batch 14)
  ... step 16/44  loss=0.5643  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 9.407e+00 (batch 16)
  ... step 18/44  loss=0.5010  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 8.664e+00 (batch 18)
  ... step 20/44  loss=0.4418  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 7.674e+00 (batch 20)
  ... step 22/44  loss=0.7611  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 8.151e+00 (batch 22)
  ... step 24/44  loss=0.4857  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 6.644e+00 (batch 24)
  ... step 26/44  loss=0.4952  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 5.575e+00 (batch 26)
  ... step 28/44  loss=0.2617  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 3.959e+00 (batch 28)
  ... step 30/44  loss=0.5877  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 6.634e+00 (batch 30)
  ... step 32/44  loss=0.5703  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 7.974e+00 (batch 32)
  ... step 34/44  loss=0.7641  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 1.591e+01 (batch 34)
  ... step 36/44  loss=0.1929  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 3.602e+00 (batch 36)
  ... step 38/44  loss=0.5897  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 6.318e+00 (batch 38)
  ... step 40/44  loss=0.3956  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 6.872e+00 (batch 40)
  ... step 42/44  loss=0.3591  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 6.311e+00 (batch 42)
âœ… epoch 11 forward/backward done in 49.6s
  ğŸ” val step 0: batch (8, 64, 2, 324, 1, 16) loss=6.2846
[11] train=0.5119  val=2.7679  RMSE(std)=[Qi:1.651, Qe:1.681, Î“:1.658]  RMSE(phys)=[Qi:123.361, Qe:161.195, Î“:75.207]  (3.9s)
âœ… Saved unified NN â†’ ./mnt/data/bin.cgyro.nn
ğŸŸ¦ Starting epoch 12/30 (train steps â‰ˆ 44)
  ... step 0/44  loss=1.0279  (0.3s since last print)
  â†˜ grad L2 norm â‰ˆ 9.880e+00 (batch 0)
  ... step 2/44  loss=0.5324  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 7.778e+00 (batch 2)
  ... step 4/44  loss=0.2561  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 4.777e+00 (batch 4)
  ... step 6/44  loss=0.3491  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 7.027e+00 (batch 6)
  ... step 8/44  loss=0.3656  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 6.805e+00 (batch 8)
  ... step 10/44  loss=0.7125  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 1.188e+01 (batch 10)
  ... step 12/44  loss=0.7813  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 1.146e+01 (batch 12)
  ... step 14/44  loss=0.4306  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 5.038e+00 (batch 14)
  ... step 16/44  loss=0.4305  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 6.051e+00 (batch 16)
  ... step 18/44  loss=0.2801  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 6.751e+00 (batch 18)
  ... step 20/44  loss=0.5027  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 5.626e+00 (batch 20)
  ... step 22/44  loss=0.4000  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 7.064e+00 (batch 22)
  ... step 24/44  loss=0.6159  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 1.025e+01 (batch 24)
  ... step 26/44  loss=0.8949  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 8.932e+00 (batch 26)
  ... step 28/44  loss=0.3757  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 6.795e+00 (batch 28)
  ... step 30/44  loss=0.5958  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 8.578e+00 (batch 30)
  ... step 32/44  loss=0.5310  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 7.613e+00 (batch 32)
  ... step 34/44  loss=0.5767  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 9.083e+00 (batch 34)
  ... step 36/44  loss=0.6439  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 4.936e+00 (batch 36)
  ... step 38/44  loss=0.5470  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 6.542e+00 (batch 38)
  ... step 40/44  loss=0.5403  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 7.137e+00 (batch 40)
  ... step 42/44  loss=0.2656  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 4.484e+00 (batch 42)
âœ… epoch 12 forward/backward done in 49.6s
  ğŸ” val step 0: batch (8, 64, 2, 324, 1, 16) loss=24.8875
[12] train=0.5021  val=14.1994  RMSE(std)=[Qi:3.868, Qe:3.930, Î“:3.492]  RMSE(phys)=[Qi:288.950, Qe:376.756, Î“:158.371]  (3.9s)
âœ… Saved unified NN â†’ ./mnt/data/bin.cgyro.nn
â¹ Early stopping after 12 epochs (no val improvement).
Saved metrics â†’ ./mnt/data/myrun_logs_deep_debug_ordered_t/metrics.csv
âœ… Final unified NN â†’ ./mnt/data/bin.cgyro.nn
âœ… Training complete. Artifacts in: ./mnt/data/myrun_logs_deep_debug_ordered_t
