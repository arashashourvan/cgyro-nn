[build_datasets] windows: total=783  train=469  val=156  test=158

[train] dataset:
  y_mean: [[[136.79208 208.24574  81.35384]]]
  y_std : [[[65.85536 84.52039 40.15286]]]
  sample Y: min=-2.064e+00, max=1.791e+00, mean=-3.870e-01, std=9.346e-01

[val] dataset:
  y_mean: [[[136.79208 208.24574  81.35384]]]
  y_std : [[[65.85536 84.52039 40.15286]]]
  sample Y: min=-1.979e+00, max=3.160e+00, mean=-7.862e-02, std=1.538e+00

[test] dataset:
  y_mean: [[[136.79208 208.24574  81.35384]]]
  y_std : [[[65.85536 84.52039 40.15286]]]
  sample Y: min=-1.864e+00, max=3.557e+00, mean=1.330e-01, std=1.536e+00
âœ… Saved flux histograms in ./mnt/data/myrun_logs_deep_debug_ordered_t
ðŸŸ¦ Starting epoch 1/20 (train steps â‰ˆ 59)
[31150] Î¦2FluxDeep forward: input (8, 64, 2, 324, 1, 16)
  ... step 0/59  loss=1.4363  (7.7s since last print)
  â†˜ grad L2 norm â‰ˆ 1.827e+01 (batch 0)
  ... step 2/59  loss=0.6477  (1.6s since last print)
  â†˜ grad L2 norm â‰ˆ 8.387e+00 (batch 2)
  ... step 4/59  loss=1.0019  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 1.331e+01 (batch 4)
  ... step 6/59  loss=0.9240  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 1.200e+01 (batch 6)
  ... step 8/59  loss=1.2620  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 1.460e+01 (batch 8)
  ... step 10/59  loss=0.8850  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 1.009e+01 (batch 10)
  ... step 12/59  loss=0.9655  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 1.035e+01 (batch 12)
  ... step 14/59  loss=1.0555  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 8.238e+00 (batch 14)
  ... step 16/59  loss=0.9215  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 9.657e+00 (batch 16)
  ... step 18/59  loss=1.1480  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 1.035e+01 (batch 18)
  ... step 20/59  loss=1.6589  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 1.288e+01 (batch 20)
  ... step 22/59  loss=0.6812  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 8.579e+00 (batch 22)
  ... step 24/59  loss=1.1204  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 1.062e+01 (batch 24)
  ... step 26/59  loss=1.0614  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 9.297e+00 (batch 26)
  ... step 28/59  loss=0.6786  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 7.583e+00 (batch 28)
  ... step 30/59  loss=1.1353  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 1.022e+01 (batch 30)
  ... step 32/59  loss=1.1520  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 1.024e+01 (batch 32)
  ... step 34/59  loss=0.9032  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 1.128e+01 (batch 34)
  ... step 36/59  loss=0.7974  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 8.358e+00 (batch 36)
  ... step 38/59  loss=1.2480  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 9.020e+00 (batch 38)
  ... step 40/59  loss=1.0589  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 1.019e+01 (batch 40)
  ... step 42/59  loss=0.6808  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 6.621e+00 (batch 42)
  ... step 44/59  loss=0.2690  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 4.098e+00 (batch 44)
  ... step 46/59  loss=0.6345  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 6.551e+00 (batch 46)
  ... step 48/59  loss=0.7015  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 8.808e+00 (batch 48)
  ... step 50/59  loss=0.9847  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 8.414e+00 (batch 50)
  ... step 52/59  loss=0.9569  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 7.349e+00 (batch 52)
  ... step 54/59  loss=0.9944  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 6.832e+00 (batch 54)
  ... step 56/59  loss=0.6878  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 4.982e+00 (batch 56)
  ... step 58/59  loss=0.5319  (1.3s since last print)
  â†˜ grad L2 norm â‰ˆ 7.702e+00 (batch 58)
âœ… epoch 1 forward/backward done in 70.8s
  ðŸ”Ž val step 0: batch (8, 64, 2, 324, 1, 16) loss=2.4106
[01] train=0.9702  val=3.1607  RMSE(std)=[Qi:1.800, Qe:1.848, Î“:1.681]  RMSE(phys)=[Qi:118.536, Qe:156.208, Î“:67.507]  (3.9s)
âœ… Saved unified NN â†’ ./mnt/data/bin.cgyro.nn
ðŸŸ¦ Starting epoch 2/20 (train steps â‰ˆ 59)
  ... step 0/59  loss=0.9603  (0.3s since last print)
  â†˜ grad L2 norm â‰ˆ 5.775e+00 (batch 0)
  ... step 2/59  loss=0.5885  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 5.282e+00 (batch 2)
  ... step 4/59  loss=0.6508  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 6.125e+00 (batch 4)
  ... step 6/59  loss=0.4735  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 5.125e+00 (batch 6)
  ... step 8/59  loss=0.6402  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 5.535e+00 (batch 8)
  ... step 10/59  loss=0.8163  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 6.562e+00 (batch 10)
  ... step 12/59  loss=1.1002  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 6.800e+00 (batch 12)
  ... step 14/59  loss=0.7145  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 5.594e+00 (batch 14)
  ... step 16/59  loss=0.7698  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 6.737e+00 (batch 16)
  ... step 18/59  loss=0.5842  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 5.564e+00 (batch 18)
  ... step 20/59  loss=0.4235  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 4.457e+00 (batch 20)
  ... step 22/59  loss=1.2625  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 7.769e+00 (batch 22)
  ... step 24/59  loss=1.1644  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 8.497e+00 (batch 24)
  ... step 26/59  loss=0.5790  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 4.014e+00 (batch 26)
  ... step 28/59  loss=0.9189  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 7.835e+00 (batch 28)
  ... step 30/59  loss=0.6067  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 6.028e+00 (batch 30)
  ... step 32/59  loss=0.9822  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 1.040e+01 (batch 32)
  ... step 34/59  loss=0.6885  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 7.085e+00 (batch 34)
  ... step 36/59  loss=1.0192  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 6.405e+00 (batch 36)
  ... step 38/59  loss=0.9404  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 8.824e+00 (batch 38)
  ... step 40/59  loss=0.7423  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 5.792e+00 (batch 40)
  ... step 42/59  loss=1.1524  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 8.484e+00 (batch 42)
  ... step 44/59  loss=0.8109  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 7.573e+00 (batch 44)
  ... step 46/59  loss=0.9032  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 1.152e+01 (batch 46)
  ... step 48/59  loss=1.2418  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 8.747e+00 (batch 48)
  ... step 50/59  loss=0.4275  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 6.091e+00 (batch 50)
  ... step 52/59  loss=0.4091  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 4.592e+00 (batch 52)
  ... step 54/59  loss=0.6003  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 7.557e+00 (batch 54)
  ... step 56/59  loss=0.7055  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 7.511e+00 (batch 56)
  ... step 58/59  loss=1.0984  (1.3s since last print)
  â†˜ grad L2 norm â‰ˆ 1.162e+01 (batch 58)
âœ… epoch 2 forward/backward done in 63.8s
  ðŸ”Ž val step 0: batch (8, 64, 2, 324, 1, 16) loss=7.2069
[02] train=0.7919  val=11.0118  RMSE(std)=[Qi:2.809, Qe:3.525, Î“:3.566]  RMSE(phys)=[Qi:185.007, Qe:297.915, Î“:143.202]  (3.9s)
âœ… Saved unified NN â†’ ./mnt/data/bin.cgyro.nn
ðŸŸ¦ Starting epoch 3/20 (train steps â‰ˆ 59)
  ... step 0/59  loss=0.4450  (0.3s since last print)
  â†˜ grad L2 norm â‰ˆ 5.976e+00 (batch 0)
  ... step 2/59  loss=0.4703  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 4.734e+00 (batch 2)
  ... step 4/59  loss=0.4419  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 5.196e+00 (batch 4)
  ... step 6/59  loss=0.5094  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 8.151e+00 (batch 6)
  ... step 8/59  loss=0.6157  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 9.287e+00 (batch 8)
  ... step 10/59  loss=0.6694  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 7.923e+00 (batch 10)
  ... step 12/59  loss=0.9781  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 9.860e+00 (batch 12)
  ... step 14/59  loss=0.4925  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 5.238e+00 (batch 14)
  ... step 16/59  loss=0.9266  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 6.731e+00 (batch 16)
  ... step 18/59  loss=0.8197  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 6.751e+00 (batch 18)
  ... step 20/59  loss=0.8328  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 5.665e+00 (batch 20)
  ... step 22/59  loss=0.6876  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 5.821e+00 (batch 22)
  ... step 24/59  loss=0.6147  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 5.497e+00 (batch 24)
  ... step 26/59  loss=1.0173  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 7.634e+00 (batch 26)
  ... step 28/59  loss=0.8973  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 8.225e+00 (batch 28)
  ... step 30/59  loss=0.6531  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 5.851e+00 (batch 30)
  ... step 32/59  loss=0.6089  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 5.450e+00 (batch 32)
  ... step 34/59  loss=0.4287  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 4.777e+00 (batch 34)
  ... step 36/59  loss=0.7084  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 5.748e+00 (batch 36)
  ... step 38/59  loss=0.5393  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 4.691e+00 (batch 38)
  ... step 40/59  loss=0.6450  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 5.165e+00 (batch 40)
  ... step 42/59  loss=0.9054  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 6.838e+00 (batch 42)
  ... step 44/59  loss=0.4806  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 4.884e+00 (batch 44)
  ... step 46/59  loss=0.5542  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 4.510e+00 (batch 46)
  ... step 48/59  loss=1.2168  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 6.340e+00 (batch 48)
  ... step 50/59  loss=0.4177  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 3.984e+00 (batch 50)
  ... step 52/59  loss=0.3859  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 3.852e+00 (batch 52)
  ... step 54/59  loss=0.9591  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 5.934e+00 (batch 54)
  ... step 56/59  loss=0.6149  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 3.339e+00 (batch 56)
  ... step 58/59  loss=0.7694  (1.3s since last print)
  â†˜ grad L2 norm â‰ˆ 7.359e+00 (batch 58)
âœ… epoch 3 forward/backward done in 63.8s
  ðŸ”Ž val step 0: batch (8, 64, 2, 324, 1, 16) loss=2.6715
[03] train=0.6969  val=5.3839  RMSE(std)=[Qi:2.126, Qe:2.322, Î“:2.498]  RMSE(phys)=[Qi:140.015, Qe:196.217, Î“:100.317]  (3.9s)
âœ… Saved unified NN â†’ ./mnt/data/bin.cgyro.nn
ðŸŸ¦ Starting epoch 4/20 (train steps â‰ˆ 59)
  ... step 0/59  loss=0.7326  (0.3s since last print)
  â†˜ grad L2 norm â‰ˆ 4.629e+00 (batch 0)
  ... step 2/59  loss=0.6748  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 4.638e+00 (batch 2)
  ... step 4/59  loss=0.7958  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 5.313e+00 (batch 4)
  ... step 6/59  loss=0.7127  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 4.508e+00 (batch 6)
  ... step 8/59  loss=0.2660  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 3.265e+00 (batch 8)
  ... step 10/59  loss=0.5119  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 4.056e+00 (batch 10)
  ... step 12/59  loss=0.5246  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 5.928e+00 (batch 12)
  ... step 14/59  loss=0.7068  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 4.516e+00 (batch 14)
  ... step 16/59  loss=0.5520  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 4.187e+00 (batch 16)
  ... step 18/59  loss=0.8303  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 6.348e+00 (batch 18)
  ... step 20/59  loss=0.5812  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 4.902e+00 (batch 20)
  ... step 22/59  loss=0.4938  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 4.971e+00 (batch 22)
  ... step 24/59  loss=0.7147  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 5.195e+00 (batch 24)
  ... step 26/59  loss=1.0315  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 6.873e+00 (batch 26)
  ... step 28/59  loss=0.5352  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 3.820e+00 (batch 28)
  ... step 30/59  loss=0.4732  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 3.343e+00 (batch 30)
  ... step 32/59  loss=0.7530  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 4.933e+00 (batch 32)
  ... step 34/59  loss=0.5706  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 4.084e+00 (batch 34)
  ... step 36/59  loss=0.3579  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 3.923e+00 (batch 36)
  ... step 38/59  loss=0.3956  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 3.899e+00 (batch 38)
  ... step 40/59  loss=0.3337  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 2.545e+00 (batch 40)
  ... step 42/59  loss=0.6859  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 4.843e+00 (batch 42)
  ... step 44/59  loss=0.2292  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 2.482e+00 (batch 44)
  ... step 46/59  loss=0.3913  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 3.464e+00 (batch 46)
  ... step 48/59  loss=0.2627  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 2.668e+00 (batch 48)
  ... step 50/59  loss=0.6543  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 5.356e+00 (batch 50)
  ... step 52/59  loss=0.6755  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 4.156e+00 (batch 52)
  ... step 54/59  loss=1.0280  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 5.132e+00 (batch 54)
  ... step 56/59  loss=0.3775  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 2.242e+00 (batch 56)
  ... step 58/59  loss=0.5054  (1.3s since last print)
  â†˜ grad L2 norm â‰ˆ 4.598e+00 (batch 58)
âœ… epoch 4 forward/backward done in 63.8s
  ðŸ”Ž val step 0: batch (8, 64, 2, 324, 1, 16) loss=15.3571
[04] train=0.6176  val=19.5390  RMSE(std)=[Qi:4.392, Qe:4.348, Î“:4.519]  RMSE(phys)=[Qi:289.221, Qe:367.510, Î“:181.457]  (3.9s)
âœ… Saved unified NN â†’ ./mnt/data/bin.cgyro.nn
ðŸŸ¦ Starting epoch 5/20 (train steps â‰ˆ 59)
  ... step 0/59  loss=0.3332  (0.3s since last print)
  â†˜ grad L2 norm â‰ˆ 3.402e+00 (batch 0)
  ... step 2/59  loss=1.1215  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 4.824e+00 (batch 2)
  ... step 4/59  loss=0.5120  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 3.893e+00 (batch 4)
  ... step 6/59  loss=0.5647  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 4.750e+00 (batch 6)
  ... step 8/59  loss=0.5271  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 4.597e+00 (batch 8)
  ... step 10/59  loss=0.4276  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 3.283e+00 (batch 10)
  ... step 12/59  loss=0.6555  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 4.376e+00 (batch 12)
  ... step 14/59  loss=1.0850  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 5.469e+00 (batch 14)
  ... step 16/59  loss=0.4082  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 3.106e+00 (batch 16)
  ... step 18/59  loss=1.4129  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 6.395e+00 (batch 18)
  ... step 20/59  loss=0.3754  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 3.308e+00 (batch 20)
  ... step 22/59  loss=0.6366  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 3.088e+00 (batch 22)
  ... step 24/59  loss=0.3390  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 3.174e+00 (batch 24)
  ... step 26/59  loss=0.4198  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 3.316e+00 (batch 26)
  ... step 28/59  loss=0.4383  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 2.835e+00 (batch 28)
  ... step 30/59  loss=1.1383  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 4.544e+00 (batch 30)
  ... step 32/59  loss=0.4789  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 2.672e+00 (batch 32)
  ... step 34/59  loss=0.6307  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 3.994e+00 (batch 34)
  ... step 36/59  loss=0.3541  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 2.423e+00 (batch 36)
  ... step 38/59  loss=0.2194  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 1.769e+00 (batch 38)
  ... step 40/59  loss=0.7745  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 3.053e+00 (batch 40)
  ... step 42/59  loss=0.9971  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 4.527e+00 (batch 42)
  ... step 44/59  loss=0.5262  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 3.477e+00 (batch 44)
  ... step 46/59  loss=0.5827  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 5.285e+00 (batch 46)
  ... step 48/59  loss=0.6174  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 4.066e+00 (batch 48)
  ... step 50/59  loss=0.5201  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 4.491e+00 (batch 50)
  ... step 52/59  loss=0.7145  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 5.051e+00 (batch 52)
  ... step 54/59  loss=0.9794  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 6.280e+00 (batch 54)
  ... step 56/59  loss=0.8193  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 4.746e+00 (batch 56)
  ... step 58/59  loss=0.8445  (1.3s since last print)
  â†˜ grad L2 norm â‰ˆ 6.997e+00 (batch 58)
âœ… epoch 5 forward/backward done in 63.8s
  ðŸ”Ž val step 0: batch (8, 64, 2, 324, 1, 16) loss=7.4441
[05] train=0.6083  val=7.4096  RMSE(std)=[Qi:2.640, Qe:2.838, Î“:2.684]  RMSE(phys)=[Qi:173.832, Qe:239.904, Î“:107.776]  (3.9s)
âœ… Saved unified NN â†’ ./mnt/data/bin.cgyro.nn
ðŸŸ¦ Starting epoch 6/20 (train steps â‰ˆ 59)
  ... step 0/59  loss=0.8148  (0.3s since last print)
  â†˜ grad L2 norm â‰ˆ 3.797e+00 (batch 0)
  ... step 2/59  loss=0.8703  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 5.662e+00 (batch 2)
  ... step 4/59  loss=0.3808  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 3.671e+00 (batch 4)
  ... step 6/59  loss=0.8374  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 6.438e+00 (batch 6)
  ... step 8/59  loss=1.0204  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 4.826e+00 (batch 8)
  ... step 10/59  loss=0.4464  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 3.496e+00 (batch 10)
  ... step 12/59  loss=0.4494  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 2.911e+00 (batch 12)
  ... step 14/59  loss=1.2137  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 4.139e+00 (batch 14)
  ... step 16/59  loss=0.3457  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 2.159e+00 (batch 16)
  ... step 18/59  loss=0.4182  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 2.953e+00 (batch 18)
  ... step 20/59  loss=0.8397  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 5.341e+00 (batch 20)
  ... step 22/59  loss=0.4819  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 3.909e+00 (batch 22)
  ... step 24/59  loss=0.1579  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 1.438e+00 (batch 24)
  ... step 26/59  loss=0.5188  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 4.168e+00 (batch 26)
  ... step 28/59  loss=0.5609  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 3.292e+00 (batch 28)
  ... step 30/59  loss=0.7547  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 4.072e+00 (batch 30)
  ... step 32/59  loss=0.2927  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 2.404e+00 (batch 32)
  ... step 34/59  loss=0.4881  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 2.728e+00 (batch 34)
  ... step 36/59  loss=0.3164  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 3.452e+00 (batch 36)
  ... step 38/59  loss=0.9350  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 3.437e+00 (batch 38)
  ... step 40/59  loss=0.8246  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 5.471e+00 (batch 40)
  ... step 42/59  loss=0.5522  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 4.073e+00 (batch 42)
  ... step 44/59  loss=0.3284  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 2.382e+00 (batch 44)
  ... step 46/59  loss=0.8821  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 4.238e+00 (batch 46)
  ... step 48/59  loss=0.5669  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 3.096e+00 (batch 48)
  ... step 50/59  loss=0.2162  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 1.175e+00 (batch 50)
  ... step 52/59  loss=0.5342  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 4.940e+00 (batch 52)
  ... step 54/59  loss=0.4189  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 2.843e+00 (batch 54)
  ... step 56/59  loss=0.3676  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 2.669e+00 (batch 56)
  ... step 58/59  loss=0.4289  (1.3s since last print)
  â†˜ grad L2 norm â‰ˆ 2.597e+00 (batch 58)
âœ… epoch 6 forward/backward done in 63.9s
  ðŸ”Ž val step 0: batch (8, 64, 2, 324, 1, 16) loss=1.0262
[06] train=0.5897  val=1.8146  RMSE(std)=[Qi:1.327, Qe:1.384, Î“:1.329]  RMSE(phys)=[Qi:87.417, Qe:116.952, Î“:53.377]  (3.9s)
âœ… Saved unified NN â†’ ./mnt/data/bin.cgyro.nn
ðŸŸ¦ Starting epoch 7/20 (train steps â‰ˆ 59)
  ... step 0/59  loss=0.3268  (0.3s since last print)
  â†˜ grad L2 norm â‰ˆ 2.750e+00 (batch 0)
  ... step 2/59  loss=0.2264  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 1.753e+00 (batch 2)
  ... step 4/59  loss=0.3142  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 2.403e+00 (batch 4)
  ... step 6/59  loss=0.4069  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 2.632e+00 (batch 6)
  ... step 8/59  loss=0.8268  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 3.173e+00 (batch 8)
  ... step 10/59  loss=0.4783  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 3.674e+00 (batch 10)
  ... step 12/59  loss=0.7451  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 4.140e+00 (batch 12)
  ... step 14/59  loss=0.4887  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 3.674e+00 (batch 14)
  ... step 16/59  loss=0.6501  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 3.575e+00 (batch 16)
  ... step 18/59  loss=0.6865  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 4.800e+00 (batch 18)
  ... step 20/59  loss=0.4744  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 4.157e+00 (batch 20)
  ... step 22/59  loss=0.7887  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 6.455e+00 (batch 22)
  ... step 24/59  loss=0.6652  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 4.706e+00 (batch 24)
  ... step 26/59  loss=0.8154  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 4.794e+00 (batch 26)
  ... step 28/59  loss=0.6517  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 3.467e+00 (batch 28)
  ... step 30/59  loss=0.5463  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 2.627e+00 (batch 30)
  ... step 32/59  loss=0.6656  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 5.044e+00 (batch 32)
  ... step 34/59  loss=0.4193  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 2.024e+00 (batch 34)
  ... step 36/59  loss=1.0273  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 6.231e+00 (batch 36)
  ... step 38/59  loss=0.3667  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 2.624e+00 (batch 38)
  ... step 40/59  loss=0.4327  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 2.742e+00 (batch 40)
  ... step 42/59  loss=0.6414  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 4.021e+00 (batch 42)
  ... step 44/59  loss=0.4988  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 3.719e+00 (batch 44)
  ... step 46/59  loss=0.8361  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 4.409e+00 (batch 46)
  ... step 48/59  loss=0.3884  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 2.342e+00 (batch 48)
  ... step 50/59  loss=0.4377  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 3.220e+00 (batch 50)
  ... step 52/59  loss=0.6115  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 2.126e+00 (batch 52)
  ... step 54/59  loss=0.3283  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 2.532e+00 (batch 54)
  ... step 56/59  loss=0.9833  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 3.733e+00 (batch 56)
  ... step 58/59  loss=1.0777  (1.3s since last print)
  â†˜ grad L2 norm â‰ˆ 4.977e+00 (batch 58)
âœ… epoch 7 forward/backward done in 63.8s
  ðŸ”Ž val step 0: batch (8, 64, 2, 324, 1, 16) loss=0.9998
[07] train=0.5844  val=1.7910  RMSE(std)=[Qi:1.316, Qe:1.371, Î“:1.327]  RMSE(phys)=[Qi:86.681, Qe:115.840, Î“:53.302]  (3.9s)
âœ… Saved unified NN â†’ ./mnt/data/bin.cgyro.nn
ðŸŸ¦ Starting epoch 8/20 (train steps â‰ˆ 59)
  ... step 0/59  loss=0.6196  (0.3s since last print)
  â†˜ grad L2 norm â‰ˆ 3.410e+00 (batch 0)
  ... step 2/59  loss=0.3049  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 2.024e+00 (batch 2)
  ... step 4/59  loss=0.5643  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 2.796e+00 (batch 4)
  ... step 6/59  loss=0.4643  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 2.699e+00 (batch 6)
  ... step 8/59  loss=0.6183  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 4.757e+00 (batch 8)
  ... step 10/59  loss=0.5645  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 3.740e+00 (batch 10)
  ... step 12/59  loss=0.6975  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 4.481e+00 (batch 12)
  ... step 14/59  loss=0.6039  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 4.042e+00 (batch 14)
  ... step 16/59  loss=0.6327  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 3.277e+00 (batch 16)
  ... step 18/59  loss=0.1985  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 1.692e+00 (batch 18)
  ... step 20/59  loss=0.9394  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 8.143e+00 (batch 20)
  ... step 22/59  loss=0.1894  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 1.796e+00 (batch 22)
  ... step 24/59  loss=0.4491  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 4.118e+00 (batch 24)
  ... step 26/59  loss=0.2962  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 2.549e+00 (batch 26)
  ... step 28/59  loss=0.2527  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 2.058e+00 (batch 28)
  ... step 30/59  loss=0.4924  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 2.639e+00 (batch 30)
  ... step 32/59  loss=0.3591  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 2.283e+00 (batch 32)
  ... step 34/59  loss=0.4867  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 4.587e+00 (batch 34)
  ... step 36/59  loss=0.4925  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 3.359e+00 (batch 36)
  ... step 38/59  loss=0.4966  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 3.972e+00 (batch 38)
  ... step 40/59  loss=0.4989  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 3.204e+00 (batch 40)
  ... step 42/59  loss=0.6248  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 4.119e+00 (batch 42)
  ... step 44/59  loss=0.7874  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 4.572e+00 (batch 44)
  ... step 46/59  loss=0.7908  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 4.422e+00 (batch 46)
  ... step 48/59  loss=0.6826  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 4.108e+00 (batch 48)
  ... step 50/59  loss=0.3109  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 2.328e+00 (batch 50)
  ... step 52/59  loss=0.5203  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 3.162e+00 (batch 52)
  ... step 54/59  loss=0.7925  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 3.095e+00 (batch 54)
  ... step 56/59  loss=0.3584  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 2.606e+00 (batch 56)
  ... step 58/59  loss=0.2458  (1.3s since last print)
  â†˜ grad L2 norm â‰ˆ 2.680e+00 (batch 58)
âœ… epoch 8 forward/backward done in 63.9s
  ðŸ”Ž val step 0: batch (8, 64, 2, 324, 1, 16) loss=0.9571
[08] train=0.5253  val=1.7547  RMSE(std)=[Qi:1.305, Qe:1.361, Î“:1.307]  RMSE(phys)=[Qi:85.940, Qe:115.031, Î“:52.490]  (3.9s)
âœ… Saved unified NN â†’ ./mnt/data/bin.cgyro.nn
ðŸŸ¦ Starting epoch 9/20 (train steps â‰ˆ 59)
  ... step 0/59  loss=0.3944  (0.3s since last print)
  â†˜ grad L2 norm â‰ˆ 3.609e+00 (batch 0)
  ... step 2/59  loss=0.4892  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 3.527e+00 (batch 2)
  ... step 4/59  loss=0.4490  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 3.032e+00 (batch 4)
  ... step 6/59  loss=0.5127  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 4.933e+00 (batch 6)
  ... step 8/59  loss=0.3936  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 3.650e+00 (batch 8)
  ... step 10/59  loss=0.2327  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 3.790e+00 (batch 10)
  ... step 12/59  loss=0.3554  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 4.115e+00 (batch 12)
  ... step 14/59  loss=0.2257  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 1.166e+01 (batch 14)
  ... step 16/59  loss=1.0910  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 2.076e+01 (batch 16)
  ... step 18/59  loss=0.3765  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 3.464e+00 (batch 18)
  ... step 20/59  loss=1.1764  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 6.566e+00 (batch 20)
  ... step 22/59  loss=0.2646  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 1.943e+00 (batch 22)
  ... step 24/59  loss=0.4254  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 3.034e+00 (batch 24)
  ... step 26/59  loss=0.6105  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 3.308e+00 (batch 26)
  ... step 28/59  loss=0.4800  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 2.892e+00 (batch 28)
  ... step 30/59  loss=0.5489  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 3.322e+00 (batch 30)
  ... step 32/59  loss=0.4201  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 2.464e+00 (batch 32)
  ... step 34/59  loss=0.7208  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 4.332e+00 (batch 34)
  ... step 36/59  loss=0.2964  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 2.515e+00 (batch 36)
  ... step 38/59  loss=0.3349  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 2.275e+00 (batch 38)
  ... step 40/59  loss=0.5614  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 4.158e+00 (batch 40)
  ... step 42/59  loss=0.7599  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 5.610e+00 (batch 42)
  ... step 44/59  loss=0.5432  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 3.344e+00 (batch 44)
  ... step 46/59  loss=0.3626  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 2.925e+00 (batch 46)
  ... step 48/59  loss=0.6115  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 4.264e+00 (batch 48)
  ... step 50/59  loss=0.4275  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 3.207e+00 (batch 50)
  ... step 52/59  loss=0.8019  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 4.438e+00 (batch 52)
  ... step 54/59  loss=0.6990  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 4.324e+00 (batch 54)
  ... step 56/59  loss=0.4298  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 3.230e+00 (batch 56)
  ... step 58/59  loss=0.7560  (1.3s since last print)
  â†˜ grad L2 norm â‰ˆ 6.465e+00 (batch 58)
âœ… epoch 9 forward/backward done in 63.8s
  ðŸ”Ž val step 0: batch (8, 64, 2, 324, 1, 16) loss=1.0526
[09] train=0.5252  val=1.7929  RMSE(std)=[Qi:1.322, Qe:1.367, Î“:1.327]  RMSE(phys)=[Qi:87.089, Qe:115.569, Î“:53.272]  (3.9s)
âœ… Saved unified NN â†’ ./mnt/data/bin.cgyro.nn
ðŸŸ¦ Starting epoch 10/20 (train steps â‰ˆ 59)
  ... step 0/59  loss=0.7378  (0.3s since last print)
  â†˜ grad L2 norm â‰ˆ 5.406e+00 (batch 0)
  ... step 2/59  loss=0.5324  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 4.247e+00 (batch 2)
  ... step 4/59  loss=0.8543  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 4.238e+00 (batch 4)
  ... step 6/59  loss=0.7812  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 3.981e+00 (batch 6)
  ... step 8/59  loss=0.3803  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 2.833e+00 (batch 8)
  ... step 10/59  loss=0.4696  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 2.349e+00 (batch 10)
  ... step 12/59  loss=0.7342  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 4.979e+00 (batch 12)
  ... step 14/59  loss=0.4034  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 2.379e+00 (batch 14)
  ... step 16/59  loss=0.3882  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 3.465e+00 (batch 16)
  ... step 18/59  loss=0.4023  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 3.208e+00 (batch 18)
  ... step 20/59  loss=0.4167  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 2.719e+00 (batch 20)
  ... step 22/59  loss=0.7565  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 2.902e+00 (batch 22)
  ... step 24/59  loss=0.5150  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 3.004e+00 (batch 24)
  ... step 26/59  loss=0.5240  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 3.689e+00 (batch 26)
  ... step 28/59  loss=0.3470  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 3.114e+00 (batch 28)
  ... step 30/59  loss=0.3733  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 3.854e+00 (batch 30)
  ... step 32/59  loss=0.3896  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 2.655e+00 (batch 32)
  ... step 34/59  loss=0.7691  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 4.872e+00 (batch 34)
  ... step 36/59  loss=0.3739  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 2.714e+00 (batch 36)
  ... step 38/59  loss=0.7063  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 4.488e+00 (batch 38)
  ... step 40/59  loss=0.3491  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 2.546e+00 (batch 40)
  ... step 42/59  loss=0.2754  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 2.707e+00 (batch 42)
  ... step 44/59  loss=0.5126  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 3.807e+00 (batch 44)
  ... step 46/59  loss=0.4937  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 4.421e+00 (batch 46)
  ... step 48/59  loss=0.3899  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 4.268e+00 (batch 48)
  ... step 50/59  loss=0.2291  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 2.430e+00 (batch 50)
  ... step 52/59  loss=0.3674  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 3.111e+00 (batch 52)
  ... step 54/59  loss=0.4937  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 4.743e+00 (batch 54)
  ... step 56/59  loss=1.0139  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 6.313e+00 (batch 56)
  ... step 58/59  loss=0.3856  (1.3s since last print)
  â†˜ grad L2 norm â‰ˆ 4.239e+00 (batch 58)
âœ… epoch 10 forward/backward done in 63.9s
  ðŸ”Ž val step 0: batch (8, 64, 2, 324, 1, 16) loss=1.0076
[10] train=0.5188  val=2.0711  RMSE(std)=[Qi:1.430, Qe:1.476, Î“:1.411]  RMSE(phys)=[Qi:94.144, Qe:124.790, Î“:56.640]  (3.9s)
âœ… Saved unified NN â†’ ./mnt/data/bin.cgyro.nn
ðŸŸ¦ Starting epoch 11/20 (train steps â‰ˆ 59)
  ... step 0/59  loss=0.6181  (0.3s since last print)
  â†˜ grad L2 norm â‰ˆ 5.336e+00 (batch 0)
  ... step 2/59  loss=0.6246  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 4.527e+00 (batch 2)
  ... step 4/59  loss=0.4554  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 4.002e+00 (batch 4)
  ... step 6/59  loss=0.4456  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 3.311e+00 (batch 6)
  ... step 8/59  loss=0.6503  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 4.237e+00 (batch 8)
  ... step 10/59  loss=0.4268  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 2.468e+00 (batch 10)
  ... step 12/59  loss=0.8948  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 4.527e+00 (batch 12)
  ... step 14/59  loss=0.4647  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 2.887e+00 (batch 14)
  ... step 16/59  loss=0.5669  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 3.083e+00 (batch 16)
  ... step 18/59  loss=0.4787  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 2.403e+00 (batch 18)
  ... step 20/59  loss=0.2692  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 2.441e+00 (batch 20)
  ... step 22/59  loss=0.2817  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 2.356e+00 (batch 22)
  ... step 24/59  loss=0.3830  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 2.497e+00 (batch 24)
  ... step 26/59  loss=0.3800  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 3.163e+00 (batch 26)
  ... step 28/59  loss=0.6151  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 3.397e+00 (batch 28)
  ... step 30/59  loss=1.3184  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 5.832e+00 (batch 30)
  ... step 32/59  loss=0.4301  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 2.028e+00 (batch 32)
  ... step 34/59  loss=0.2947  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 2.631e+00 (batch 34)
  ... step 36/59  loss=0.6224  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 3.723e+00 (batch 36)
  ... step 38/59  loss=0.4354  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 4.753e+00 (batch 38)
  ... step 40/59  loss=0.2997  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 2.680e+00 (batch 40)
  ... step 42/59  loss=0.5751  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 4.052e+00 (batch 42)
  ... step 44/59  loss=0.3424  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 3.226e+00 (batch 44)
  ... step 46/59  loss=0.5507  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 4.570e+00 (batch 46)
  ... step 48/59  loss=0.2944  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 2.922e+00 (batch 48)
  ... step 50/59  loss=0.2156  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 2.194e+00 (batch 50)
  ... step 52/59  loss=1.1585  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 5.874e+00 (batch 52)
  ... step 54/59  loss=0.6272  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 4.562e+00 (batch 54)
  ... step 56/59  loss=0.7396  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 5.150e+00 (batch 56)
  ... step 58/59  loss=0.5484  (1.3s since last print)
  â†˜ grad L2 norm â‰ˆ 4.377e+00 (batch 58)
âœ… epoch 11 forward/backward done in 63.8s
  ðŸ”Ž val step 0: batch (8, 64, 2, 324, 1, 16) loss=1.7098
[11] train=0.5202  val=2.3870  RMSE(std)=[Qi:1.538, Qe:1.574, Î“:1.522]  RMSE(phys)=[Qi:101.318, Qe:133.006, Î“:61.127]  (3.9s)
âœ… Saved unified NN â†’ ./mnt/data/bin.cgyro.nn
ðŸŸ¦ Starting epoch 12/20 (train steps â‰ˆ 59)
  ... step 0/59  loss=0.1801  (0.3s since last print)
  â†˜ grad L2 norm â‰ˆ 2.297e+00 (batch 0)
  ... step 2/59  loss=0.6302  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 3.601e+00 (batch 2)
  ... step 4/59  loss=0.8797  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 5.484e+00 (batch 4)
  ... step 6/59  loss=0.5036  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 4.495e+00 (batch 6)
  ... step 8/59  loss=0.6625  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 4.525e+00 (batch 8)
  ... step 10/59  loss=0.3176  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 4.140e+00 (batch 10)
  ... step 12/59  loss=0.3290  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 2.822e+00 (batch 12)
  ... step 14/59  loss=0.8250  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 5.632e+00 (batch 14)
  ... step 16/59  loss=0.2806  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 2.494e+00 (batch 16)
  ... step 18/59  loss=0.4494  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 3.841e+00 (batch 18)
  ... step 20/59  loss=0.5729  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 4.741e+00 (batch 20)
  ... step 22/59  loss=0.4851  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 3.489e+00 (batch 22)
  ... step 24/59  loss=0.6128  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 4.522e+00 (batch 24)
  ... step 26/59  loss=0.4021  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 5.346e+00 (batch 26)
  ... step 28/59  loss=0.2721  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 3.408e+00 (batch 28)
  ... step 30/59  loss=0.3099  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 3.561e+00 (batch 30)
  ... step 32/59  loss=0.3528  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 2.883e+00 (batch 32)
  ... step 34/59  loss=0.9638  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 6.094e+00 (batch 34)
  ... step 36/59  loss=0.4109  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 2.484e+00 (batch 36)
  ... step 38/59  loss=0.4125  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 6.388e+00 (batch 38)
  ... step 40/59  loss=0.4095  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 4.116e+00 (batch 40)
  ... step 42/59  loss=0.4191  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 4.074e+00 (batch 42)
  ... step 44/59  loss=0.3551  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 3.512e+00 (batch 44)
  ... step 46/59  loss=0.3243  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 2.152e+00 (batch 46)
  ... step 48/59  loss=0.3351  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 3.227e+00 (batch 48)
  ... step 50/59  loss=0.3625  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 3.309e+00 (batch 50)
  ... step 52/59  loss=0.3807  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 4.591e+00 (batch 52)
  ... step 54/59  loss=0.2779  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 4.044e+00 (batch 54)
  ... step 56/59  loss=0.4700  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 4.272e+00 (batch 56)
  ... step 58/59  loss=0.1108  (1.3s since last print)
  â†˜ grad L2 norm â‰ˆ 2.816e+00 (batch 58)
âœ… epoch 12 forward/backward done in 63.8s
  ðŸ”Ž val step 0: batch (8, 64, 2, 324, 1, 16) loss=1.2042
[12] train=0.4482  val=2.5022  RMSE(std)=[Qi:1.572, Qe:1.616, Î“:1.556]  RMSE(phys)=[Qi:103.551, Qe:136.621, Î“:62.480]  (3.9s)
âœ… Saved unified NN â†’ ./mnt/data/bin.cgyro.nn
ðŸŸ¦ Starting epoch 13/20 (train steps â‰ˆ 59)
  ... step 0/59  loss=0.7363  (0.3s since last print)
  â†˜ grad L2 norm â‰ˆ 2.665e+01 (batch 0)
  ... step 2/59  loss=0.4849  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 4.869e+00 (batch 2)
  ... step 4/59  loss=0.5306  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 3.743e+00 (batch 4)
  ... step 6/59  loss=0.3782  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 3.360e+00 (batch 6)
  ... step 8/59  loss=0.6684  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 3.864e+00 (batch 8)
  ... step 10/59  loss=0.3262  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 2.378e+00 (batch 10)
  ... step 12/59  loss=0.8310  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 4.576e+00 (batch 12)
  ... step 14/59  loss=0.3973  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 2.657e+00 (batch 14)
  ... step 16/59  loss=0.8030  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 4.074e+00 (batch 16)
  ... step 18/59  loss=0.3242  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 2.361e+00 (batch 18)
  ... step 20/59  loss=0.6120  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 3.930e+00 (batch 20)
  ... step 22/59  loss=0.2031  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 1.235e+00 (batch 22)
  ... step 24/59  loss=0.4530  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 2.816e+00 (batch 24)
  ... step 26/59  loss=0.3857  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 2.421e+00 (batch 26)
  ... step 28/59  loss=0.3181  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 5.882e+00 (batch 28)
  ... step 30/59  loss=0.2073  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 2.442e+00 (batch 30)
  ... step 32/59  loss=0.3116  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 4.835e+00 (batch 32)
  ... step 34/59  loss=1.2998  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 1.132e+01 (batch 34)
  ... step 36/59  loss=0.7277  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 5.938e+00 (batch 36)
  ... step 38/59  loss=0.4348  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 3.558e+00 (batch 38)
  ... step 40/59  loss=0.6872  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 4.757e+00 (batch 40)
  ... step 42/59  loss=1.0541  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 6.961e+00 (batch 42)
  ... step 44/59  loss=0.5573  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 3.660e+00 (batch 44)
  ... step 46/59  loss=0.3933  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 3.638e+00 (batch 46)
  ... step 48/59  loss=0.4187  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 2.670e+00 (batch 48)
  ... step 50/59  loss=0.7880  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 4.223e+00 (batch 50)
  ... step 52/59  loss=0.5616  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 2.697e+00 (batch 52)
  ... step 54/59  loss=0.8153  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 3.966e+00 (batch 54)
  ... step 56/59  loss=0.3243  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 2.104e+00 (batch 56)
  ... step 58/59  loss=0.3643  (1.3s since last print)
  â†˜ grad L2 norm â‰ˆ 3.992e+00 (batch 58)
âœ… epoch 13 forward/backward done in 63.9s
  ðŸ”Ž val step 0: batch (8, 64, 2, 324, 1, 16) loss=1.0434
[13] train=0.4956  val=1.5679  RMSE(std)=[Qi:1.233, Qe:1.302, Î“:1.220]  RMSE(phys)=[Qi:81.229, Qe:110.019, Î“:48.977]  (3.9s)
âœ… Saved unified NN â†’ ./mnt/data/bin.cgyro.nn
ðŸŸ¦ Starting epoch 14/20 (train steps â‰ˆ 59)
  ... step 0/59  loss=0.3874  (0.3s since last print)
  â†˜ grad L2 norm â‰ˆ 2.877e+00 (batch 0)
  ... step 2/59  loss=0.2686  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 2.012e+00 (batch 2)
  ... step 4/59  loss=0.4383  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 2.529e+00 (batch 4)
  ... step 6/59  loss=0.3754  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 5.077e+00 (batch 6)
  ... step 8/59  loss=0.5170  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 2.225e+00 (batch 8)
  ... step 10/59  loss=0.5715  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 3.055e+00 (batch 10)
  ... step 12/59  loss=0.4514  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 2.450e+00 (batch 12)
  ... step 14/59  loss=0.3156  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 2.825e+00 (batch 14)
  ... step 16/59  loss=0.3421  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 2.293e+00 (batch 16)
  ... step 18/59  loss=0.5015  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 4.966e+00 (batch 18)
  ... step 20/59  loss=0.6252  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 4.683e+00 (batch 20)
  ... step 22/59  loss=0.4155  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 3.041e+00 (batch 22)
  ... step 24/59  loss=0.5206  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 4.363e+00 (batch 24)
  ... step 26/59  loss=0.5772  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 3.945e+00 (batch 26)
  ... step 28/59  loss=0.3026  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 2.505e+00 (batch 28)
  ... step 30/59  loss=0.4331  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 2.776e+00 (batch 30)
  ... step 32/59  loss=0.2174  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 1.875e+00 (batch 32)
  ... step 34/59  loss=0.4132  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 2.792e+00 (batch 34)
  ... step 36/59  loss=0.2779  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 2.925e+00 (batch 36)
  ... step 38/59  loss=0.2879  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 2.893e+00 (batch 38)
  ... step 40/59  loss=0.2496  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 3.247e+00 (batch 40)
  ... step 42/59  loss=0.4081  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 3.743e+00 (batch 42)
  ... step 44/59  loss=0.2981  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 2.785e+00 (batch 44)
  ... step 46/59  loss=0.5238  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 3.442e+00 (batch 46)
  ... step 48/59  loss=0.6164  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 4.278e+00 (batch 48)
  ... step 50/59  loss=0.3456  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 1.727e+00 (batch 50)
  ... step 52/59  loss=0.6268  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 5.137e+00 (batch 52)
  ... step 54/59  loss=0.3880  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 3.015e+00 (batch 54)
  ... step 56/59  loss=0.2386  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 5.662e+00 (batch 56)
  ... step 58/59  loss=0.4752  (1.3s since last print)
  â†˜ grad L2 norm â‰ˆ 4.354e+00 (batch 58)
âœ… epoch 14 forward/backward done in 63.8s
  ðŸ”Ž val step 0: batch (8, 64, 2, 324, 1, 16) loss=33.9833
[14] train=0.4185  val=40.0863  RMSE(std)=[Qi:6.341, Qe:6.623, Î“:6.016]  RMSE(phys)=[Qi:417.589, Qe:559.764, Î“:241.548]  (3.9s)
âœ… Saved unified NN â†’ ./mnt/data/bin.cgyro.nn
ðŸŸ¦ Starting epoch 15/20 (train steps â‰ˆ 59)
  ... step 0/59  loss=0.4046  (0.3s since last print)
  â†˜ grad L2 norm â‰ˆ 4.182e+00 (batch 0)
  ... step 2/59  loss=0.4914  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 4.456e+00 (batch 2)
  ... step 4/59  loss=0.5403  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 3.757e+00 (batch 4)
  ... step 6/59  loss=0.3069  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 2.464e+00 (batch 6)
  ... step 8/59  loss=0.6387  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 4.235e+00 (batch 8)
  ... step 10/59  loss=0.2278  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 2.473e+00 (batch 10)
  ... step 12/59  loss=0.4604  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 3.078e+00 (batch 12)
  ... step 14/59  loss=0.2980  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 4.317e+00 (batch 14)
  ... step 16/59  loss=0.2797  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 2.565e+00 (batch 16)
  ... step 18/59  loss=0.7265  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 7.217e+00 (batch 18)
  ... step 20/59  loss=0.3447  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 2.874e+00 (batch 20)
  ... step 22/59  loss=0.4911  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 2.903e+00 (batch 22)
  ... step 24/59  loss=0.3128  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 2.319e+00 (batch 24)
  ... step 26/59  loss=0.5129  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 4.137e+00 (batch 26)
  ... step 28/59  loss=0.3544  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 2.759e+00 (batch 28)
  ... step 30/59  loss=0.3775  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 3.682e+00 (batch 30)
  ... step 32/59  loss=0.4288  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 5.237e+00 (batch 32)
  ... step 34/59  loss=0.3982  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 5.487e+00 (batch 34)
  ... step 36/59  loss=0.4939  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 3.776e+00 (batch 36)
  ... step 38/59  loss=0.4283  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 4.358e+00 (batch 38)
  ... step 40/59  loss=0.3777  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 3.088e+00 (batch 40)
  ... step 42/59  loss=0.1569  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 2.405e+00 (batch 42)
  ... step 44/59  loss=0.2991  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 2.977e+00 (batch 44)
  ... step 46/59  loss=0.2603  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 2.506e+00 (batch 46)
  ... step 48/59  loss=0.3313  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 4.290e+00 (batch 48)
  ... step 50/59  loss=0.4979  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 4.355e+00 (batch 50)
  ... step 52/59  loss=0.4642  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 4.785e+00 (batch 52)
  ... step 54/59  loss=0.2754  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 3.357e+00 (batch 54)
  ... step 56/59  loss=0.3377  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 4.074e+00 (batch 56)
  ... step 58/59  loss=0.6106  (1.3s since last print)
  â†˜ grad L2 norm â‰ˆ 6.854e+00 (batch 58)
âœ… epoch 15 forward/backward done in 63.9s
  ðŸ”Ž val step 0: batch (8, 64, 2, 324, 1, 16) loss=1.5360
[15] train=0.3806  val=3.0248  RMSE(std)=[Qi:1.731, Qe:1.761, Î“:1.725]  RMSE(phys)=[Qi:114.008, Qe:148.864, Î“:69.258]  (3.9s)
âœ… Saved unified NN â†’ ./mnt/data/bin.cgyro.nn
ðŸŸ¦ Starting epoch 16/20 (train steps â‰ˆ 59)
  ... step 0/59  loss=0.2625  (0.3s since last print)
  â†˜ grad L2 norm â‰ˆ 2.327e+00 (batch 0)
  ... step 2/59  loss=0.3650  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 4.776e+00 (batch 2)
  ... step 4/59  loss=0.1670  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 3.063e+00 (batch 4)
  ... step 6/59  loss=0.1838  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 2.536e+00 (batch 6)
  ... step 8/59  loss=0.4767  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 7.794e+00 (batch 8)
  ... step 10/59  loss=0.4133  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 6.008e+00 (batch 10)
  ... step 12/59  loss=0.4253  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 4.656e+00 (batch 12)
  ... step 14/59  loss=0.1650  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 1.602e+00 (batch 14)
  ... step 16/59  loss=0.5202  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 5.480e+00 (batch 16)
  ... step 18/59  loss=0.2309  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 2.775e+00 (batch 18)
  ... step 20/59  loss=0.4161  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 4.440e+00 (batch 20)
  ... step 22/59  loss=0.3156  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 4.296e+00 (batch 22)
  ... step 24/59  loss=0.2974  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 2.991e+00 (batch 24)
  ... step 26/59  loss=0.5698  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 3.946e+00 (batch 26)
  ... step 28/59  loss=0.4075  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 2.961e+00 (batch 28)
  ... step 30/59  loss=0.3973  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 4.031e+00 (batch 30)
  ... step 32/59  loss=0.2428  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 1.999e+01 (batch 32)
  ... step 34/59  loss=0.2858  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 2.810e+00 (batch 34)
  ... step 36/59  loss=0.5000  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 3.393e+00 (batch 36)
  ... step 38/59  loss=0.3871  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 4.553e+00 (batch 38)
  ... step 40/59  loss=0.3133  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 4.964e+00 (batch 40)
  ... step 42/59  loss=0.1447  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 2.095e+00 (batch 42)
  ... step 44/59  loss=0.3632  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 4.981e+00 (batch 44)
  ... step 46/59  loss=0.5430  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 5.857e+00 (batch 46)
  ... step 48/59  loss=0.3023  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 3.733e+00 (batch 48)
  ... step 50/59  loss=0.2999  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 2.540e+00 (batch 50)
  ... step 52/59  loss=0.5309  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 4.066e+00 (batch 52)
  ... step 54/59  loss=0.1815  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 1.787e+00 (batch 54)
  ... step 56/59  loss=0.2081  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 2.354e+00 (batch 56)
  ... step 58/59  loss=0.1988  (1.3s since last print)
  â†˜ grad L2 norm â‰ˆ 2.330e+00 (batch 58)
âœ… epoch 16 forward/backward done in 63.8s
  ðŸ”Ž val step 0: batch (8, 64, 2, 324, 1, 16) loss=5.4713
[16] train=0.3634  val=6.3369  RMSE(std)=[Qi:2.554, Qe:2.512, Î“:2.486]  RMSE(phys)=[Qi:168.207, Qe:212.290, Î“:99.805]  (3.9s)
âœ… Saved unified NN â†’ ./mnt/data/bin.cgyro.nn
ðŸŸ¦ Starting epoch 17/20 (train steps â‰ˆ 59)
  ... step 0/59  loss=0.3796  (0.3s since last print)
  â†˜ grad L2 norm â‰ˆ 3.901e+00 (batch 0)
  ... step 2/59  loss=0.6006  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 5.490e+00 (batch 2)
  ... step 4/59  loss=0.3308  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 5.765e+00 (batch 4)
  ... step 6/59  loss=0.2600  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 4.440e+00 (batch 6)
  ... step 8/59  loss=0.3601  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 2.939e+00 (batch 8)
  ... step 10/59  loss=0.2651  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 2.968e+00 (batch 10)
  ... step 12/59  loss=0.1637  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 2.324e+00 (batch 12)
  ... step 14/59  loss=0.2094  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 1.633e+00 (batch 14)
  ... step 16/59  loss=0.2178  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 2.699e+00 (batch 16)
  ... step 18/59  loss=0.3759  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 4.087e+00 (batch 18)
  ... step 20/59  loss=0.3730  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 3.248e+00 (batch 20)
  ... step 22/59  loss=0.1340  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 1.525e+00 (batch 22)
  ... step 24/59  loss=0.3340  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 5.923e+00 (batch 24)
  ... step 26/59  loss=0.3373  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 5.002e+00 (batch 26)
  ... step 28/59  loss=0.3036  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 3.288e+00 (batch 28)
  ... step 30/59  loss=0.1636  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 2.938e+00 (batch 30)
  ... step 32/59  loss=0.3139  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 3.737e+00 (batch 32)
  ... step 34/59  loss=0.5871  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 6.057e+00 (batch 34)
  ... step 36/59  loss=0.4935  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 4.955e+00 (batch 36)
  ... step 38/59  loss=0.2592  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 2.980e+00 (batch 38)
  ... step 40/59  loss=0.3341  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 3.307e+00 (batch 40)
  ... step 42/59  loss=0.2545  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 3.862e+00 (batch 42)
  ... step 44/59  loss=0.2252  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 3.014e+00 (batch 44)
  ... step 46/59  loss=0.2135  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 3.594e+00 (batch 46)
  ... step 48/59  loss=0.3306  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 3.993e+00 (batch 48)
  ... step 50/59  loss=0.1882  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 2.094e+00 (batch 50)
  ... step 52/59  loss=0.2721  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 2.589e+00 (batch 52)
  ... step 54/59  loss=0.3332  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 4.989e+00 (batch 54)
  ... step 56/59  loss=0.4022  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 3.923e+00 (batch 56)
  ... step 58/59  loss=0.3979  (1.3s since last print)
  â†˜ grad L2 norm â‰ˆ 7.850e+00 (batch 58)
âœ… epoch 17 forward/backward done in 63.8s
  ðŸ”Ž val step 0: batch (8, 64, 2, 324, 1, 16) loss=2.4252
[17] train=0.3171  val=4.2934  RMSE(std)=[Qi:2.108, Qe:2.048, Î“:2.059]  RMSE(phys)=[Qi:138.848, Qe:173.136, Î“:82.669]  (3.9s)
âœ… Saved unified NN â†’ ./mnt/data/bin.cgyro.nn
ðŸŸ¦ Starting epoch 18/20 (train steps â‰ˆ 59)
  ... step 0/59  loss=0.2447  (0.3s since last print)
  â†˜ grad L2 norm â‰ˆ 4.774e+00 (batch 0)
  ... step 2/59  loss=0.2688  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 4.173e+00 (batch 2)
  ... step 4/59  loss=0.3588  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 3.520e+00 (batch 4)
  ... step 6/59  loss=0.1677  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 2.525e+00 (batch 6)
  ... step 8/59  loss=0.4105  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 4.567e+00 (batch 8)
  ... step 10/59  loss=0.4916  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 3.848e+00 (batch 10)
  ... step 12/59  loss=0.3841  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 3.466e+00 (batch 12)
  ... step 14/59  loss=0.3197  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 3.570e+00 (batch 14)
  ... step 16/59  loss=0.5843  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 5.112e+00 (batch 16)
  ... step 18/59  loss=0.1866  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 2.394e+00 (batch 18)
  ... step 20/59  loss=0.2839  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 3.894e+00 (batch 20)
  ... step 22/59  loss=0.3059  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 3.823e+00 (batch 22)
  ... step 24/59  loss=0.3792  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 5.260e+00 (batch 24)
  ... step 26/59  loss=0.2633  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 2.453e+00 (batch 26)
  ... step 28/59  loss=0.5976  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 6.572e+00 (batch 28)
  ... step 30/59  loss=0.2494  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 2.982e+00 (batch 30)
  ... step 32/59  loss=0.1126  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 1.937e+00 (batch 32)
  ... step 34/59  loss=0.2931  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 3.656e+00 (batch 34)
  ... step 36/59  loss=0.3761  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 6.047e+00 (batch 36)
  ... step 38/59  loss=0.3277  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 3.995e+00 (batch 38)
  ... step 40/59  loss=0.2873  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 3.555e+00 (batch 40)
  ... step 42/59  loss=0.3777  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 3.912e+00 (batch 42)
  ... step 44/59  loss=0.4252  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 6.178e+00 (batch 44)
  ... step 46/59  loss=0.2443  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 2.602e+00 (batch 46)
  ... step 48/59  loss=0.2819  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 3.646e+00 (batch 48)
  ... step 50/59  loss=0.1932  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 2.652e+00 (batch 50)
  ... step 52/59  loss=0.1574  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 2.012e+00 (batch 52)
  ... step 54/59  loss=0.1899  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 2.349e+00 (batch 54)
  ... step 56/59  loss=0.2482  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 3.057e+00 (batch 56)
  ... step 58/59  loss=0.2120  (1.3s since last print)
  â†˜ grad L2 norm â‰ˆ 5.252e+00 (batch 58)
âœ… epoch 18 forward/backward done in 63.9s
  ðŸ”Ž val step 0: batch (8, 64, 2, 324, 1, 16) loss=0.8499
[18] train=0.3060  val=2.2609  RMSE(std)=[Qi:1.488, Qe:1.534, Î“:1.489]  RMSE(phys)=[Qi:98.010, Qe:129.623, Î“:59.768]  (3.9s)
âœ… Saved unified NN â†’ ./mnt/data/bin.cgyro.nn
ðŸŸ¦ Starting epoch 19/20 (train steps â‰ˆ 59)
  ... step 0/59  loss=0.1703  (0.3s since last print)
  â†˜ grad L2 norm â‰ˆ 4.621e+00 (batch 0)
  ... step 2/59  loss=0.4753  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 4.189e+00 (batch 2)
  ... step 4/59  loss=0.2197  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 2.215e+00 (batch 4)
  ... step 6/59  loss=0.4031  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 3.705e+00 (batch 6)
  ... step 8/59  loss=0.2447  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 3.745e+00 (batch 8)
  ... step 10/59  loss=0.3192  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 3.250e+00 (batch 10)
  ... step 12/59  loss=0.2997  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 2.878e+00 (batch 12)
  ... step 14/59  loss=0.4213  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 2.924e+00 (batch 14)
  ... step 16/59  loss=0.2517  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 3.476e+00 (batch 16)
  ... step 18/59  loss=0.5167  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 4.432e+00 (batch 18)
  ... step 20/59  loss=0.1811  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 2.132e+00 (batch 20)
  ... step 22/59  loss=0.2724  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 3.375e+00 (batch 22)
  ... step 24/59  loss=0.1810  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 2.939e+00 (batch 24)
  ... step 26/59  loss=0.4637  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 6.594e+00 (batch 26)
  ... step 28/59  loss=0.2662  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 2.663e+00 (batch 28)
  ... step 30/59  loss=0.1710  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 2.408e+00 (batch 30)
  ... step 32/59  loss=0.5068  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 6.369e+00 (batch 32)
  ... step 34/59  loss=0.3328  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 3.824e+00 (batch 34)
  ... step 36/59  loss=0.1602  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 2.598e+00 (batch 36)
  ... step 38/59  loss=0.2622  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 2.144e+00 (batch 38)
  ... step 40/59  loss=0.2128  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 3.411e+00 (batch 40)
  ... step 42/59  loss=0.9556  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 1.153e+01 (batch 42)
  ... step 44/59  loss=0.3752  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 4.302e+00 (batch 44)
  ... step 46/59  loss=0.2732  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 4.319e+00 (batch 46)
  ... step 48/59  loss=0.2484  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 3.122e+00 (batch 48)
  ... step 50/59  loss=0.2192  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 3.189e+00 (batch 50)
  ... step 52/59  loss=0.2075  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 2.595e+00 (batch 52)
  ... step 54/59  loss=0.2068  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 2.864e+00 (batch 54)
  ... step 56/59  loss=0.1756  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 2.415e+00 (batch 56)
  ... step 58/59  loss=0.2090  (1.3s since last print)
  â†˜ grad L2 norm â‰ˆ 3.931e+00 (batch 58)
âœ… epoch 19 forward/backward done in 63.9s
  ðŸ”Ž val step 0: batch (8, 64, 2, 324, 1, 16) loss=0.9681
[19] train=0.2977  val=1.7224  RMSE(std)=[Qi:1.295, Qe:1.359, Î“:1.282]  RMSE(phys)=[Qi:85.282, Qe:114.838, Î“:51.488]  (3.9s)
âœ… Saved unified NN â†’ ./mnt/data/bin.cgyro.nn
ðŸŸ¦ Starting epoch 20/20 (train steps â‰ˆ 59)
  ... step 0/59  loss=0.2602  (0.3s since last print)
  â†˜ grad L2 norm â‰ˆ 3.189e+00 (batch 0)
  ... step 2/59  loss=0.2515  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 2.445e+00 (batch 2)
  ... step 4/59  loss=0.2522  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 2.690e+00 (batch 4)
  ... step 6/59  loss=0.2953  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 3.198e+00 (batch 6)
  ... step 8/59  loss=0.1712  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 1.835e+00 (batch 8)
  ... step 10/59  loss=0.2386  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 2.440e+00 (batch 10)
  ... step 12/59  loss=0.4612  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 6.623e+00 (batch 12)
  ... step 14/59  loss=0.2312  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 2.116e+00 (batch 14)
  ... step 16/59  loss=0.8745  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 9.494e+00 (batch 16)
  ... step 18/59  loss=0.3960  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 3.105e+00 (batch 18)
  ... step 20/59  loss=0.2427  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 3.708e+00 (batch 20)
  ... step 22/59  loss=0.2121  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 3.012e+00 (batch 22)
  ... step 24/59  loss=0.2054  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 2.665e+00 (batch 24)
  ... step 26/59  loss=0.3178  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 3.583e+00 (batch 26)
  ... step 28/59  loss=0.2103  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 3.208e+00 (batch 28)
  ... step 30/59  loss=0.1262  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 1.653e+00 (batch 30)
  ... step 32/59  loss=0.2715  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 5.192e+00 (batch 32)
  ... step 34/59  loss=0.3093  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 3.995e+00 (batch 34)
  ... step 36/59  loss=0.3296  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 4.865e+00 (batch 36)
  ... step 38/59  loss=0.2119  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 2.446e+00 (batch 38)
  ... step 40/59  loss=0.1992  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 3.979e+00 (batch 40)
  ... step 42/59  loss=0.1925  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 3.601e+00 (batch 42)
  ... step 44/59  loss=0.2469  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 3.006e+00 (batch 44)
  ... step 46/59  loss=0.2411  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 3.061e+00 (batch 46)
  ... step 48/59  loss=0.3556  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 4.394e+00 (batch 48)
  ... step 50/59  loss=0.1785  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 4.050e+00 (batch 50)
  ... step 52/59  loss=0.3596  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 5.012e+00 (batch 52)
  ... step 54/59  loss=0.3710  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 3.755e+00 (batch 54)
  ... step 56/59  loss=0.5773  (1.4s since last print)
  â†˜ grad L2 norm â‰ˆ 4.544e+00 (batch 56)
  ... step 58/59  loss=0.1036  (1.3s since last print)
  â†˜ grad L2 norm â‰ˆ 2.173e+00 (batch 58)
âœ… epoch 20 forward/backward done in 63.9s
  ðŸ”Ž val step 0: batch (8, 64, 2, 324, 1, 16) loss=1.6516
[20] train=0.2672  val=3.3934  RMSE(std)=[Qi:1.829, Qe:1.870, Î“:1.827]  RMSE(phys)=[Qi:120.452, Qe:158.054, Î“:73.361]  (3.9s)
âœ… Saved unified NN â†’ ./mnt/data/bin.cgyro.nn
Saved metrics â†’ ./mnt/data/myrun_logs_deep_debug_ordered_t/metrics.csv
âœ… Final unified NN â†’ ./mnt/data/bin.cgyro.nn
âœ… Training complete. Artifacts in: ./mnt/data/myrun_logs_deep_debug_ordered_t
