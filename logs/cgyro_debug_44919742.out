[build_datasets] windows: total=631  train=378  val=126  test=127

[train] dataset:
  y_mean: [[[149.2916  223.5924   88.81354]]]
  y_std : [[[71.23856 90.84779 43.31966]]]
  sample Y: min=-1.270e+00, max=2.095e+00, mean=-1.096e-01, std=7.501e-01

[val] dataset:
  y_mean: [[[149.2916  223.5924   88.81354]]]
  y_std : [[[71.23856 90.84779 43.31966]]]
  sample Y: min=-2.010e+00, max=2.771e+00, mean=-2.837e-01, std=1.211e+00

[test] dataset:
  y_mean: [[[149.2916  223.5924   88.81354]]]
  y_std : [[[71.23856 90.84779 43.31966]]]
  sample Y: min=-1.903e+00, max=3.119e+00, mean=-1.289e-02, std=1.572e+00
âœ… Saved flux histograms in ./mnt/data/myrun_logs_ot3
ğŸŸ¦ Starting epoch 1/30 (train steps â‰ˆ 24)
[2006544] Î¦2FluxDeep forward: input (16, 16, 2, 324, 1, 16)
  ... step 0/24  loss=0.8007  (2.7s since last print)
  â†˜ grad L2 norm â‰ˆ 8.657e+00 (batch 0)
  ... step 2/24  loss=1.1159  (0.8s since last print)
  â†˜ grad L2 norm â‰ˆ 9.177e+00 (batch 2)
  ... step 4/24  loss=1.0975  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 9.055e+00 (batch 4)
  ... step 6/24  loss=1.5336  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 1.157e+01 (batch 6)
  ... step 8/24  loss=1.0641  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 8.543e+00 (batch 8)
  ... step 10/24  loss=0.7937  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 8.117e+00 (batch 10)
  ... step 12/24  loss=1.1391  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 8.442e+00 (batch 12)
  ... step 14/24  loss=1.1316  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 9.190e+00 (batch 14)
  ... step 16/24  loss=0.8935  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 6.991e+00 (batch 16)
  ... step 18/24  loss=1.1398  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 8.780e+00 (batch 18)
  ... step 20/24  loss=1.3758  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 9.098e+00 (batch 20)
  ... step 22/24  loss=1.3784  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 9.516e+00 (batch 22)
âœ… epoch 1 forward/backward done in 15.7s
  ğŸ” val step 0: batch (16, 16, 2, 324, 1, 16) loss=1.7933
[01] train=1.0773  val=1.5702  RMSE(std)=[Qi:1.237, Qe:1.283, Î“:1.239]  RMSE(phys)=[Qi:88.128, Qe:116.547, Î“:53.663]  (1.3s)
âœ… Saved unified NN â†’ ./mnt/data/bin.cgyro.nn
ğŸŸ¦ Starting epoch 2/30 (train steps â‰ˆ 24)
  ... step 0/24  loss=0.7210  (0.1s since last print)
  â†˜ grad L2 norm â‰ˆ 6.772e+00 (batch 0)
  ... step 2/24  loss=1.5251  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 9.788e+00 (batch 2)
  ... step 4/24  loss=0.7804  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 6.917e+00 (batch 4)
  ... step 6/24  loss=0.8533  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 6.258e+00 (batch 6)
  ... step 8/24  loss=0.8962  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 7.231e+00 (batch 8)
  ... step 10/24  loss=1.0405  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 7.401e+00 (batch 10)
  ... step 12/24  loss=1.2914  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 7.964e+00 (batch 12)
  ... step 14/24  loss=0.6561  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 5.786e+00 (batch 14)
  ... step 16/24  loss=0.9795  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 6.602e+00 (batch 16)
  ... step 18/24  loss=1.3576  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 8.016e+00 (batch 18)
  ... step 20/24  loss=1.0017  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 6.944e+00 (batch 20)
  ... step 22/24  loss=0.7129  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 6.705e+00 (batch 22)
âœ… epoch 2 forward/backward done in 13.6s
  ğŸ” val step 0: batch (16, 16, 2, 324, 1, 16) loss=1.8513
[02] train=1.0187  val=1.5597  RMSE(std)=[Qi:1.233, Qe:1.287, Î“:1.226]  RMSE(phys)=[Qi:87.866, Qe:116.886, Î“:53.100]  (1.2s)
âœ… Saved unified NN â†’ ./mnt/data/bin.cgyro.nn
ğŸŸ¦ Starting epoch 3/30 (train steps â‰ˆ 24)
  ... step 0/24  loss=1.0153  (0.1s since last print)
  â†˜ grad L2 norm â‰ˆ 6.786e+00 (batch 0)
  ... step 2/24  loss=1.1639  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 7.340e+00 (batch 2)
  ... step 4/24  loss=1.2929  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 7.846e+00 (batch 4)
  ... step 6/24  loss=1.0951  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 8.285e+00 (batch 6)
  ... step 8/24  loss=1.2446  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 7.251e+00 (batch 8)
  ... step 10/24  loss=0.8635  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 6.065e+00 (batch 10)
  ... step 12/24  loss=0.6374  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 5.487e+00 (batch 12)
  ... step 14/24  loss=0.8435  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 6.770e+00 (batch 14)
  ... step 16/24  loss=1.2247  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 7.521e+00 (batch 16)
  ... step 18/24  loss=0.7792  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 5.661e+00 (batch 18)
  ... step 20/24  loss=0.9169  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 6.438e+00 (batch 20)
  ... step 22/24  loss=1.2128  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 7.001e+00 (batch 22)
âœ… epoch 3 forward/backward done in 13.6s
  ğŸ” val step 0: batch (16, 16, 2, 324, 1, 16) loss=1.9863
[03] train=1.0008  val=1.5306  RMSE(std)=[Qi:1.219, Qe:1.268, Î“:1.224]  RMSE(phys)=[Qi:86.872, Qe:115.158, Î“:53.021]  (1.2s)
âœ… Saved unified NN â†’ ./mnt/data/bin.cgyro.nn
ğŸŸ¦ Starting epoch 4/30 (train steps â‰ˆ 24)
  ... step 0/24  loss=1.0927  (0.1s since last print)
  â†˜ grad L2 norm â‰ˆ 7.576e+00 (batch 0)
  ... step 2/24  loss=1.4148  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 7.463e+00 (batch 2)
  ... step 4/24  loss=1.0905  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 6.877e+00 (batch 4)
  ... step 6/24  loss=0.9612  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 5.853e+00 (batch 6)
  ... step 8/24  loss=1.1476  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 6.974e+00 (batch 8)
  ... step 10/24  loss=0.6000  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 5.820e+00 (batch 10)
  ... step 12/24  loss=0.8360  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 5.822e+00 (batch 12)
  ... step 14/24  loss=0.7616  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 5.784e+00 (batch 14)
  ... step 16/24  loss=0.9731  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 6.682e+00 (batch 16)
  ... step 18/24  loss=1.0868  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 7.577e+00 (batch 18)
  ... step 20/24  loss=0.8644  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 6.186e+00 (batch 20)
  ... step 22/24  loss=1.2997  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 7.270e+00 (batch 22)
âœ… epoch 4 forward/backward done in 13.6s
  ğŸ” val step 0: batch (16, 16, 2, 324, 1, 16) loss=2.0512
[04] train=0.9619  val=1.5119  RMSE(std)=[Qi:1.201, Qe:1.268, Î“:1.219]  RMSE(phys)=[Qi:85.592, Qe:115.168, Î“:52.792]  (1.2s)
âœ… Saved unified NN â†’ ./mnt/data/bin.cgyro.nn
ğŸŸ¦ Starting epoch 5/30 (train steps â‰ˆ 24)
  ... step 0/24  loss=1.1365  (0.1s since last print)
  â†˜ grad L2 norm â‰ˆ 7.652e+00 (batch 0)
  ... step 2/24  loss=1.1932  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 7.498e+00 (batch 2)
  ... step 4/24  loss=0.6061  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 5.629e+00 (batch 4)
  ... step 6/24  loss=1.0749  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 7.323e+00 (batch 6)
  ... step 8/24  loss=1.1701  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 7.485e+00 (batch 8)
  ... step 10/24  loss=0.5036  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 4.909e+00 (batch 10)
  ... step 12/24  loss=0.8698  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 6.323e+00 (batch 12)
  ... step 14/24  loss=0.5424  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 6.145e+00 (batch 14)
  ... step 16/24  loss=1.1957  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 7.292e+00 (batch 16)
  ... step 18/24  loss=0.9818  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 1.051e+01 (batch 18)
  ... step 20/24  loss=0.7611  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 5.959e+00 (batch 20)
  ... step 22/24  loss=0.9811  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 8.476e+00 (batch 22)
âœ… epoch 5 forward/backward done in 13.6s
  ğŸ” val step 0: batch (16, 16, 2, 324, 1, 16) loss=1.6809
[05] train=0.9155  val=1.3411  RMSE(std)=[Qi:1.129, Qe:1.214, Î“:1.129]  RMSE(phys)=[Qi:80.403, Qe:110.301, Î“:48.920]  (1.2s)
âœ… Saved unified NN â†’ ./mnt/data/bin.cgyro.nn
ğŸŸ¦ Starting epoch 6/30 (train steps â‰ˆ 24)
  ... step 0/24  loss=0.8691  (0.1s since last print)
  â†˜ grad L2 norm â‰ˆ 6.950e+00 (batch 0)
  ... step 2/24  loss=0.7065  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 6.516e+00 (batch 2)
  ... step 4/24  loss=0.9764  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 6.229e+00 (batch 4)
  ... step 6/24  loss=0.5298  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 4.743e+00 (batch 6)
  ... step 8/24  loss=0.7270  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 6.186e+00 (batch 8)
  ... step 10/24  loss=0.8793  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 6.939e+00 (batch 10)
  ... step 12/24  loss=0.6146  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 6.832e+00 (batch 12)
  ... step 14/24  loss=0.6077  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 6.633e+00 (batch 14)
  ... step 16/24  loss=0.5965  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 6.453e+00 (batch 16)
  ... step 18/24  loss=0.8907  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 1.006e+01 (batch 18)
  ... step 20/24  loss=0.7565  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 5.960e+00 (batch 20)
  ... step 22/24  loss=0.9656  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 7.424e+00 (batch 22)
âœ… epoch 6 forward/backward done in 13.6s
  ğŸ” val step 0: batch (16, 16, 2, 324, 1, 16) loss=8.3439
[06] train=0.7862  val=10.7484  RMSE(std)=[Qi:2.900, Qe:3.253, Î“:3.641]  RMSE(phys)=[Qi:206.583, Qe:295.489, Î“:157.726]  (1.2s)
âœ… Saved unified NN â†’ ./mnt/data/bin.cgyro.nn
ğŸŸ¦ Starting epoch 7/30 (train steps â‰ˆ 24)
  ... step 0/24  loss=1.0305  (0.1s since last print)
  â†˜ grad L2 norm â‰ˆ 1.022e+01 (batch 0)
  ... step 2/24  loss=0.9035  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 9.213e+00 (batch 2)
  ... step 4/24  loss=0.7761  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 1.010e+01 (batch 4)
  ... step 6/24  loss=0.8930  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 8.343e+00 (batch 6)
  ... step 8/24  loss=0.6592  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 7.194e+00 (batch 8)
  ... step 10/24  loss=0.6590  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 7.763e+00 (batch 10)
  ... step 12/24  loss=0.8432  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 8.429e+00 (batch 12)
  ... step 14/24  loss=0.6599  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 6.161e+00 (batch 14)
  ... step 16/24  loss=0.6581  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 6.890e+00 (batch 16)
  ... step 18/24  loss=0.7056  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 6.482e+00 (batch 18)
  ... step 20/24  loss=0.5046  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 6.683e+00 (batch 20)
  ... step 22/24  loss=0.9108  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 8.793e+00 (batch 22)
âœ… epoch 7 forward/backward done in 13.6s
  ğŸ” val step 0: batch (16, 16, 2, 324, 1, 16) loss=12.0688
[07] train=0.7038  val=14.6455  RMSE(std)=[Qi:3.455, Qe:3.976, Î“:4.023]  RMSE(phys)=[Qi:246.133, Qe:361.246, Î“:174.290]  (1.2s)
âœ… Saved unified NN â†’ ./mnt/data/bin.cgyro.nn
ğŸŸ¦ Starting epoch 8/30 (train steps â‰ˆ 24)
  ... step 0/24  loss=0.5277  (0.1s since last print)
  â†˜ grad L2 norm â‰ˆ 4.876e+00 (batch 0)
  ... step 2/24  loss=0.6927  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 7.108e+00 (batch 2)
  ... step 4/24  loss=1.2039  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 9.080e+00 (batch 4)
  ... step 6/24  loss=0.5335  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 5.412e+00 (batch 6)
  ... step 8/24  loss=0.5250  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 6.427e+00 (batch 8)
  ... step 10/24  loss=0.5010  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 6.070e+00 (batch 10)
  ... step 12/24  loss=0.8008  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 7.580e+00 (batch 12)
  ... step 14/24  loss=0.6284  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 8.787e+00 (batch 14)
  ... step 16/24  loss=0.8362  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 9.798e+00 (batch 16)
  ... step 18/24  loss=0.6651  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 7.676e+00 (batch 18)
  ... step 20/24  loss=0.5827  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 7.457e+00 (batch 20)
  ... step 22/24  loss=0.7860  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 9.704e+00 (batch 22)
âœ… epoch 8 forward/backward done in 13.6s
  ğŸ” val step 0: batch (16, 16, 2, 324, 1, 16) loss=12.2791
[08] train=0.7125  val=14.9930  RMSE(std)=[Qi:3.489, Qe:4.190, Î“:3.906]  RMSE(phys)=[Qi:248.528, Qe:380.621, Î“:169.196]  (1.2s)
âœ… Saved unified NN â†’ ./mnt/data/bin.cgyro.nn
ğŸŸ¦ Starting epoch 9/30 (train steps â‰ˆ 24)
  ... step 0/24  loss=0.7869  (0.1s since last print)
  â†˜ grad L2 norm â‰ˆ 7.931e+00 (batch 0)
  ... step 2/24  loss=0.4497  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 6.108e+00 (batch 2)
  ... step 4/24  loss=0.5303  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 6.511e+00 (batch 4)
  ... step 6/24  loss=0.6512  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 6.167e+00 (batch 6)
  ... step 8/24  loss=0.5753  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 7.761e+00 (batch 8)
  ... step 10/24  loss=0.5764  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 8.705e+00 (batch 10)
  ... step 12/24  loss=0.7053  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 6.826e+00 (batch 12)
  ... step 14/24  loss=0.5602  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 6.543e+00 (batch 14)
  ... step 16/24  loss=0.6000  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 6.232e+00 (batch 16)
  ... step 18/24  loss=0.8766  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 7.979e+00 (batch 18)
  ... step 20/24  loss=0.6143  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 7.126e+00 (batch 20)
  ... step 22/24  loss=0.5690  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 5.399e+00 (batch 22)
âœ… epoch 9 forward/backward done in 13.6s
  ğŸ” val step 0: batch (16, 16, 2, 324, 1, 16) loss=3.9386
[09] train=0.6303  val=3.2368  RMSE(std)=[Qi:1.792, Qe:1.859, Î“:1.745]  RMSE(phys)=[Qi:127.683, Qe:168.853, Î“:75.572]  (1.2s)
âœ… Saved unified NN â†’ ./mnt/data/bin.cgyro.nn
ğŸŸ¦ Starting epoch 10/30 (train steps â‰ˆ 24)
  ... step 0/24  loss=0.6581  (0.1s since last print)
  â†˜ grad L2 norm â‰ˆ 7.527e+00 (batch 0)
  ... step 2/24  loss=0.4897  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 5.122e+00 (batch 2)
  ... step 4/24  loss=0.7024  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 8.010e+00 (batch 4)
  ... step 6/24  loss=0.4417  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 5.880e+00 (batch 6)
  ... step 8/24  loss=0.8750  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 9.331e+00 (batch 8)
  ... step 10/24  loss=0.5166  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 5.938e+00 (batch 10)
  ... step 12/24  loss=0.5650  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 5.613e+00 (batch 12)
  ... step 14/24  loss=0.5989  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 6.085e+00 (batch 14)
  ... step 16/24  loss=0.7252  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 6.279e+00 (batch 16)
  ... step 18/24  loss=0.6262  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 5.892e+00 (batch 18)
  ... step 20/24  loss=0.5446  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 4.658e+00 (batch 20)
  ... step 22/24  loss=0.3962  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 5.227e+00 (batch 22)
âœ… epoch 10 forward/backward done in 13.6s
  ğŸ” val step 0: batch (16, 16, 2, 324, 1, 16) loss=15.4360
[10] train=0.6191  val=17.4433  RMSE(std)=[Qi:3.953, Qe:4.476, Î“:4.083]  RMSE(phys)=[Qi:281.627, Qe:406.619, Î“:176.860]  (1.2s)
âœ… Saved unified NN â†’ ./mnt/data/bin.cgyro.nn
ğŸŸ¦ Starting epoch 11/30 (train steps â‰ˆ 24)
  ... step 0/24  loss=0.5755  (0.1s since last print)
  â†˜ grad L2 norm â‰ˆ 5.708e+00 (batch 0)
  ... step 2/24  loss=0.6578  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 5.969e+00 (batch 2)
  ... step 4/24  loss=0.6352  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 5.163e+00 (batch 4)
  ... step 6/24  loss=0.7082  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 6.098e+00 (batch 6)
  ... step 8/24  loss=0.8761  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 7.275e+00 (batch 8)
  ... step 10/24  loss=0.5762  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 6.140e+00 (batch 10)
  ... step 12/24  loss=0.6490  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 6.286e+00 (batch 12)
  ... step 14/24  loss=0.6086  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 5.423e+00 (batch 14)
  ... step 16/24  loss=0.4291  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 5.016e+00 (batch 16)
  ... step 18/24  loss=0.5674  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 5.519e+00 (batch 18)
  ... step 20/24  loss=0.4706  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 5.267e+00 (batch 20)
  ... step 22/24  loss=0.6663  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 6.399e+00 (batch 22)
âœ… epoch 11 forward/backward done in 13.6s
  ğŸ” val step 0: batch (16, 16, 2, 324, 1, 16) loss=6.5938
[11] train=0.6207  val=5.0056  RMSE(std)=[Qi:2.206, Qe:2.306, Î“:2.198]  RMSE(phys)=[Qi:157.137, Qe:209.506, Î“:95.234]  (1.2s)
âœ… Saved unified NN â†’ ./mnt/data/bin.cgyro.nn
ğŸŸ¦ Starting epoch 12/30 (train steps â‰ˆ 24)
  ... step 0/24  loss=0.4888  (0.1s since last print)
  â†˜ grad L2 norm â‰ˆ 4.804e+00 (batch 0)
  ... step 2/24  loss=0.7654  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 8.585e+00 (batch 2)
  ... step 4/24  loss=0.5202  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 4.794e+00 (batch 4)
  ... step 6/24  loss=0.6720  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 5.732e+00 (batch 6)
  ... step 8/24  loss=0.8787  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 7.798e+00 (batch 8)
  ... step 10/24  loss=0.7917  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 7.445e+00 (batch 10)
  ... step 12/24  loss=0.7033  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 6.375e+00 (batch 12)
  ... step 14/24  loss=0.6305  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 7.053e+00 (batch 14)
  ... step 16/24  loss=0.6661  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 6.140e+00 (batch 16)
  ... step 18/24  loss=0.5179  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 5.491e+00 (batch 18)
  ... step 20/24  loss=0.4713  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 4.679e+00 (batch 20)
  ... step 22/24  loss=0.6294  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 4.988e+00 (batch 22)
âœ… epoch 12 forward/backward done in 13.6s
  ğŸ” val step 0: batch (16, 16, 2, 324, 1, 16) loss=2.2711
[12] train=0.5895  val=1.2945  RMSE(std)=[Qi:1.144, Qe:1.159, Î“:1.110]  RMSE(phys)=[Qi:81.492, Qe:105.284, Î“:48.078]  (1.2s)
âœ… Saved unified NN â†’ ./mnt/data/bin.cgyro.nn
ğŸŸ¦ Starting epoch 13/30 (train steps â‰ˆ 24)
  ... step 0/24  loss=0.8332  (0.1s since last print)
  â†˜ grad L2 norm â‰ˆ 6.575e+00 (batch 0)
  ... step 2/24  loss=0.5390  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 5.221e+00 (batch 2)
  ... step 4/24  loss=0.6759  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 6.285e+00 (batch 4)
  ... step 6/24  loss=0.7100  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 6.412e+00 (batch 6)
  ... step 8/24  loss=0.4606  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 3.473e+00 (batch 8)
  ... step 10/24  loss=0.5204  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 6.004e+00 (batch 10)
  ... step 12/24  loss=0.4908  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 5.475e+00 (batch 12)
  ... step 14/24  loss=0.6824  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 6.396e+00 (batch 14)
  ... step 16/24  loss=0.3286  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 4.326e+00 (batch 16)
  ... step 18/24  loss=0.4807  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 5.833e+00 (batch 18)
  ... step 20/24  loss=0.3803  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 3.788e+00 (batch 20)
  ... step 22/24  loss=0.3662  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 4.408e+00 (batch 22)
âœ… epoch 13 forward/backward done in 13.6s
  ğŸ” val step 0: batch (16, 16, 2, 324, 1, 16) loss=5.4463
[13] train=0.5770  val=3.6709  RMSE(std)=[Qi:1.913, Qe:1.942, Î“:1.892]  RMSE(phys)=[Qi:136.272, Qe:176.445, Î“:81.981]  (1.2s)
âœ… Saved unified NN â†’ ./mnt/data/bin.cgyro.nn
ğŸŸ¦ Starting epoch 14/30 (train steps â‰ˆ 24)
  ... step 0/24  loss=0.6408  (0.1s since last print)
  â†˜ grad L2 norm â‰ˆ 6.878e+00 (batch 0)
  ... step 2/24  loss=0.5607  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 6.614e+00 (batch 2)
  ... step 4/24  loss=0.6445  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 4.998e+00 (batch 4)
  ... step 6/24  loss=0.6115  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 5.543e+00 (batch 6)
  ... step 8/24  loss=0.4768  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 5.502e+00 (batch 8)
  ... step 10/24  loss=0.4605  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 5.387e+00 (batch 10)
  ... step 12/24  loss=0.7902  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 6.102e+00 (batch 12)
  ... step 14/24  loss=0.4197  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 5.031e+00 (batch 14)
  ... step 16/24  loss=0.4964  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 3.952e+00 (batch 16)
  ... step 18/24  loss=0.6430  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 6.375e+00 (batch 18)
  ... step 20/24  loss=0.6373  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 6.830e+00 (batch 20)
  ... step 22/24  loss=0.6081  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 5.749e+00 (batch 22)
âœ… epoch 14 forward/backward done in 13.6s
  ğŸ” val step 0: batch (16, 16, 2, 324, 1, 16) loss=1.6883
[14] train=0.5692  val=0.9715  RMSE(std)=[Qi:0.983, Qe:1.018, Î“:0.955]  RMSE(phys)=[Qi:70.011, Qe:92.523, Î“:41.357]  (1.2s)
âœ… Saved unified NN â†’ ./mnt/data/bin.cgyro.nn
ğŸŸ¦ Starting epoch 15/30 (train steps â‰ˆ 24)
  ... step 0/24  loss=0.4215  (0.1s since last print)
  â†˜ grad L2 norm â‰ˆ 4.494e+00 (batch 0)
  ... step 2/24  loss=0.4566  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 4.318e+00 (batch 2)
  ... step 4/24  loss=0.4846  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 5.042e+00 (batch 4)
  ... step 6/24  loss=0.8329  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 6.227e+00 (batch 6)
  ... step 8/24  loss=0.5205  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 4.744e+00 (batch 8)
  ... step 10/24  loss=0.5090  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 5.271e+00 (batch 10)
  ... step 12/24  loss=0.7935  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 5.583e+00 (batch 12)
  ... step 14/24  loss=0.3585  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 5.495e+00 (batch 14)
  ... step 16/24  loss=0.5256  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 6.357e+00 (batch 16)
  ... step 18/24  loss=0.4379  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 5.782e+00 (batch 18)
  ... step 20/24  loss=0.6034  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 5.408e+00 (batch 20)
  ... step 22/24  loss=0.6055  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 5.626e+00 (batch 22)
âœ… epoch 15 forward/backward done in 13.6s
  ğŸ” val step 0: batch (16, 16, 2, 324, 1, 16) loss=1.4201
[15] train=0.5760  val=0.8042  RMSE(std)=[Qi:0.885, Qe:0.933, Î“:0.871]  RMSE(phys)=[Qi:63.046, Qe:84.791, Î“:37.723]  (1.2s)
âœ… Saved unified NN â†’ ./mnt/data/bin.cgyro.nn
ğŸŸ¦ Starting epoch 16/30 (train steps â‰ˆ 24)
  ... step 0/24  loss=0.8242  (0.1s since last print)
  â†˜ grad L2 norm â‰ˆ 7.965e+00 (batch 0)
  ... step 2/24  loss=0.6740  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 6.614e+00 (batch 2)
  ... step 4/24  loss=0.6999  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 6.513e+00 (batch 4)
  ... step 6/24  loss=0.4420  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 4.289e+00 (batch 6)
  ... step 8/24  loss=0.6133  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 5.387e+00 (batch 8)
  ... step 10/24  loss=0.4599  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 4.935e+00 (batch 10)
  ... step 12/24  loss=0.4284  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 4.336e+00 (batch 12)
  ... step 14/24  loss=0.4987  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 5.434e+00 (batch 14)
  ... step 16/24  loss=0.6534  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 6.226e+00 (batch 16)
  ... step 18/24  loss=0.2953  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 4.587e+00 (batch 18)
  ... step 20/24  loss=0.4662  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 4.494e+00 (batch 20)
  ... step 22/24  loss=0.6932  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 5.661e+00 (batch 22)
âœ… epoch 16 forward/backward done in 13.6s
  ğŸ” val step 0: batch (16, 16, 2, 324, 1, 16) loss=1.2278
[16] train=0.5648  val=0.7446  RMSE(std)=[Qi:0.834, Qe:0.907, Î“:0.846]  RMSE(phys)=[Qi:59.429, Qe:82.366, Î“:36.653]  (1.2s)
âœ… Saved unified NN â†’ ./mnt/data/bin.cgyro.nn
ğŸŸ¦ Starting epoch 17/30 (train steps â‰ˆ 24)
  ... step 0/24  loss=0.5716  (0.1s since last print)
  â†˜ grad L2 norm â‰ˆ 5.615e+00 (batch 0)
  ... step 2/24  loss=0.4581  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 4.325e+00 (batch 2)
  ... step 4/24  loss=0.4482  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 5.831e+00 (batch 4)
  ... step 6/24  loss=0.6477  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 6.181e+00 (batch 6)
  ... step 8/24  loss=0.4640  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 5.004e+00 (batch 8)
  ... step 10/24  loss=0.3742  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 4.576e+00 (batch 10)
  ... step 12/24  loss=0.6992  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 6.464e+00 (batch 12)
  ... step 14/24  loss=0.8229  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 8.193e+00 (batch 14)
  ... step 16/24  loss=0.3783  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 4.802e+00 (batch 16)
  ... step 18/24  loss=0.4946  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 5.536e+00 (batch 18)
  ... step 20/24  loss=0.5027  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 5.678e+00 (batch 20)
  ... step 22/24  loss=0.3941  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 4.966e+00 (batch 22)
âœ… epoch 17 forward/backward done in 13.6s
  ğŸ” val step 0: batch (16, 16, 2, 324, 1, 16) loss=1.1083
[17] train=0.5113  val=0.7257  RMSE(std)=[Qi:0.825, Qe:0.895, Î“:0.834]  RMSE(phys)=[Qi:58.752, Qe:81.341, Î“:36.122]  (1.2s)
âœ… Saved unified NN â†’ ./mnt/data/bin.cgyro.nn
ğŸŸ¦ Starting epoch 18/30 (train steps â‰ˆ 24)
  ... step 0/24  loss=0.6590  (0.1s since last print)
  â†˜ grad L2 norm â‰ˆ 5.624e+00 (batch 0)
  ... step 2/24  loss=0.5945  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 6.108e+00 (batch 2)
  ... step 4/24  loss=0.5217  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 7.357e+00 (batch 4)
  ... step 6/24  loss=0.4418  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 4.539e+00 (batch 6)
  ... step 8/24  loss=0.3512  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 4.609e+00 (batch 8)
  ... step 10/24  loss=0.4182  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 4.698e+00 (batch 10)
  ... step 12/24  loss=0.8726  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 7.051e+00 (batch 12)
  ... step 14/24  loss=0.4825  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 5.994e+00 (batch 14)
  ... step 16/24  loss=0.3950  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 4.695e+00 (batch 16)
  ... step 18/24  loss=0.6184  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 6.486e+00 (batch 18)
  ... step 20/24  loss=0.5424  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 4.741e+00 (batch 20)
  ... step 22/24  loss=0.4775  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 5.549e+00 (batch 22)
âœ… epoch 18 forward/backward done in 13.6s
  ğŸ” val step 0: batch (16, 16, 2, 324, 1, 16) loss=1.1934
[18] train=0.5319  val=0.7426  RMSE(std)=[Qi:0.834, Qe:0.902, Î“:0.848]  RMSE(phys)=[Qi:59.413, Qe:81.937, Î“:36.726]  (1.2s)
âœ… Saved unified NN â†’ ./mnt/data/bin.cgyro.nn
ğŸŸ¦ Starting epoch 19/30 (train steps â‰ˆ 24)
  ... step 0/24  loss=0.8460  (0.1s since last print)
  â†˜ grad L2 norm â‰ˆ 8.523e+00 (batch 0)
  ... step 2/24  loss=0.4201  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 4.653e+00 (batch 2)
  ... step 4/24  loss=0.6123  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 6.434e+00 (batch 4)
  ... step 6/24  loss=0.6022  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 6.930e+00 (batch 6)
  ... step 8/24  loss=0.6105  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 6.058e+00 (batch 8)
  ... step 10/24  loss=0.6152  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 6.978e+00 (batch 10)
  ... step 12/24  loss=0.7033  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 6.469e+00 (batch 12)
  ... step 14/24  loss=0.7251  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 7.076e+00 (batch 14)
  ... step 16/24  loss=0.5048  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 5.081e+00 (batch 16)
  ... step 18/24  loss=0.5091  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 7.013e+00 (batch 18)
  ... step 20/24  loss=0.5632  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 5.970e+00 (batch 20)
  ... step 22/24  loss=0.3991  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 4.100e+00 (batch 22)
âœ… epoch 19 forward/backward done in 13.6s
  ğŸ” val step 0: batch (16, 16, 2, 324, 1, 16) loss=0.9778
[19] train=0.5269  val=0.6500  RMSE(std)=[Qi:0.788, Qe:0.843, Î“:0.787]  RMSE(phys)=[Qi:56.105, Qe:76.570, Î“:34.088]  (1.2s)
âœ… Saved unified NN â†’ ./mnt/data/bin.cgyro.nn
ğŸŸ¦ Starting epoch 20/30 (train steps â‰ˆ 24)
  ... step 0/24  loss=0.5539  (0.1s since last print)
  â†˜ grad L2 norm â‰ˆ 6.216e+00 (batch 0)
  ... step 2/24  loss=0.5014  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 6.190e+00 (batch 2)
  ... step 4/24  loss=0.4778  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 4.210e+00 (batch 4)
  ... step 6/24  loss=0.2763  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 5.969e+00 (batch 6)
  ... step 8/24  loss=0.5028  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 5.221e+00 (batch 8)
  ... step 10/24  loss=0.5253  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 5.434e+00 (batch 10)
  ... step 12/24  loss=0.4246  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 4.642e+00 (batch 12)
  ... step 14/24  loss=0.4869  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 4.438e+00 (batch 14)
  ... step 16/24  loss=0.4985  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 4.848e+00 (batch 16)
  ... step 18/24  loss=0.4141  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 5.042e+00 (batch 18)
  ... step 20/24  loss=0.6966  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 7.758e+00 (batch 20)
  ... step 22/24  loss=0.4680  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 5.362e+00 (batch 22)
âœ… epoch 20 forward/backward done in 13.6s
  ğŸ” val step 0: batch (16, 16, 2, 324, 1, 16) loss=1.1667
[20] train=0.4899  val=0.7002  RMSE(std)=[Qi:0.818, Qe:0.876, Î“:0.815]  RMSE(phys)=[Qi:58.270, Qe:79.554, Î“:35.318]  (1.2s)
âœ… Saved unified NN â†’ ./mnt/data/bin.cgyro.nn
ğŸŸ¦ Starting epoch 21/30 (train steps â‰ˆ 24)
  ... step 0/24  loss=0.3878  (0.1s since last print)
  â†˜ grad L2 norm â‰ˆ 4.565e+00 (batch 0)
  ... step 2/24  loss=0.4653  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 5.158e+00 (batch 2)
  ... step 4/24  loss=0.4311  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 4.898e+00 (batch 4)
  ... step 6/24  loss=0.4894  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 4.716e+00 (batch 6)
  ... step 8/24  loss=0.5039  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 5.340e+00 (batch 8)
  ... step 10/24  loss=0.4603  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 5.367e+00 (batch 10)
  ... step 12/24  loss=0.4675  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 4.469e+00 (batch 12)
  ... step 14/24  loss=0.5230  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 6.497e+00 (batch 14)
  ... step 16/24  loss=0.5029  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 6.145e+00 (batch 16)
  ... step 18/24  loss=0.4477  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 5.361e+00 (batch 18)
  ... step 20/24  loss=0.3520  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 3.788e+00 (batch 20)
  ... step 22/24  loss=0.5170  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 5.675e+00 (batch 22)
âœ… epoch 21 forward/backward done in 13.6s
  ğŸ” val step 0: batch (16, 16, 2, 324, 1, 16) loss=1.2040
[21] train=0.4838  val=0.7580  RMSE(std)=[Qi:0.844, Qe:0.909, Î“:0.857]  RMSE(phys)=[Qi:60.121, Qe:82.610, Î“:37.139]  (1.2s)
âœ… Saved unified NN â†’ ./mnt/data/bin.cgyro.nn
ğŸŸ¦ Starting epoch 22/30 (train steps â‰ˆ 24)
  ... step 0/24  loss=0.5468  (0.1s since last print)
  â†˜ grad L2 norm â‰ˆ 6.506e+00 (batch 0)
  ... step 2/24  loss=0.5999  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 5.517e+00 (batch 2)
  ... step 4/24  loss=0.4045  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 4.835e+00 (batch 4)
  ... step 6/24  loss=0.7506  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 7.366e+00 (batch 6)
  ... step 8/24  loss=0.5095  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 7.507e+00 (batch 8)
  ... step 10/24  loss=0.4763  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 5.448e+00 (batch 10)
  ... step 12/24  loss=0.4508  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 6.932e+00 (batch 12)
  ... step 14/24  loss=0.3734  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 3.743e+00 (batch 14)
  ... step 16/24  loss=0.2966  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 4.571e+00 (batch 16)
  ... step 18/24  loss=0.3146  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 5.410e+00 (batch 18)
  ... step 20/24  loss=0.5108  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 5.332e+00 (batch 20)
  ... step 22/24  loss=0.5665  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 6.295e+00 (batch 22)
âœ… epoch 22 forward/backward done in 13.6s
  ğŸ” val step 0: batch (16, 16, 2, 324, 1, 16) loss=1.2252
[22] train=0.4586  val=0.8656  RMSE(std)=[Qi:0.918, Qe:0.954, Î“:0.920]  RMSE(phys)=[Qi:65.370, Qe:86.629, Î“:39.834]  (1.2s)
âœ… Saved unified NN â†’ ./mnt/data/bin.cgyro.nn
ğŸŸ¦ Starting epoch 23/30 (train steps â‰ˆ 24)
  ... step 0/24  loss=0.4274  (0.1s since last print)
  â†˜ grad L2 norm â‰ˆ 4.269e+00 (batch 0)
  ... step 2/24  loss=0.4169  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 4.491e+00 (batch 2)
  ... step 4/24  loss=0.5913  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 5.541e+00 (batch 4)
  ... step 6/24  loss=0.4863  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 6.070e+00 (batch 6)
  ... step 8/24  loss=0.4033  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 4.479e+00 (batch 8)
  ... step 10/24  loss=0.4712  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 6.268e+00 (batch 10)
  ... step 12/24  loss=0.5459  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 5.766e+00 (batch 12)
  ... step 14/24  loss=0.4483  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 5.274e+00 (batch 14)
  ... step 16/24  loss=0.4598  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 5.545e+00 (batch 16)
  ... step 18/24  loss=0.4205  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 4.911e+00 (batch 18)
  ... step 20/24  loss=0.5474  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 6.769e+00 (batch 20)
  ... step 22/24  loss=0.2254  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 3.993e+00 (batch 22)
âœ… epoch 23 forward/backward done in 13.6s
  ğŸ” val step 0: batch (16, 16, 2, 324, 1, 16) loss=1.0176
[23] train=0.4392  val=0.6767  RMSE(std)=[Qi:0.807, Qe:0.853, Î“:0.807]  RMSE(phys)=[Qi:57.514, Qe:77.491, Î“:34.948]  (1.2s)
âœ… Saved unified NN â†’ ./mnt/data/bin.cgyro.nn
ğŸŸ¦ Starting epoch 24/30 (train steps â‰ˆ 24)
  ... step 0/24  loss=0.3119  (0.1s since last print)
  â†˜ grad L2 norm â‰ˆ 3.934e+00 (batch 0)
  ... step 2/24  loss=0.3399  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 6.414e+00 (batch 2)
  ... step 4/24  loss=0.3728  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 5.049e+00 (batch 4)
  ... step 6/24  loss=0.4233  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 5.794e+00 (batch 6)
  ... step 8/24  loss=0.6150  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 7.155e+00 (batch 8)
  ... step 10/24  loss=0.5894  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 6.930e+00 (batch 10)
  ... step 12/24  loss=0.4228  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 5.464e+00 (batch 12)
  ... step 14/24  loss=0.4233  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 4.870e+00 (batch 14)
  ... step 16/24  loss=0.4629  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 4.476e+00 (batch 16)
  ... step 18/24  loss=0.4869  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 5.881e+00 (batch 18)
  ... step 20/24  loss=0.5435  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 6.961e+00 (batch 20)
  ... step 22/24  loss=0.7366  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 1.053e+01 (batch 22)
âœ… epoch 24 forward/backward done in 13.6s
  ğŸ” val step 0: batch (16, 16, 2, 324, 1, 16) loss=1.1869
[24] train=0.4467  val=0.9201  RMSE(std)=[Qi:0.950, Qe:0.973, Î“:0.954]  RMSE(phys)=[Qi:67.708, Qe:88.388, Î“:41.334]  (1.2s)
âœ… Saved unified NN â†’ ./mnt/data/bin.cgyro.nn
ğŸŸ¦ Starting epoch 25/30 (train steps â‰ˆ 24)
  ... step 0/24  loss=0.3715  (0.1s since last print)
  â†˜ grad L2 norm â‰ˆ 4.499e+00 (batch 0)
  ... step 2/24  loss=0.2740  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 4.742e+00 (batch 2)
  ... step 4/24  loss=0.3161  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 4.291e+00 (batch 4)
  ... step 6/24  loss=0.4851  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 7.911e+00 (batch 6)
  ... step 8/24  loss=0.3832  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 4.362e+00 (batch 8)
  ... step 10/24  loss=0.3921  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 4.634e+00 (batch 10)
  ... step 12/24  loss=0.3404  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 4.220e+00 (batch 12)
  ... step 14/24  loss=0.4574  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 6.445e+00 (batch 14)
  ... step 16/24  loss=0.6798  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 6.170e+00 (batch 16)
  ... step 18/24  loss=0.4053  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 4.813e+00 (batch 18)
  ... step 20/24  loss=0.6937  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 7.191e+00 (batch 20)
  ... step 22/24  loss=0.3042  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 3.423e+00 (batch 22)
âœ… epoch 25 forward/backward done in 13.6s
  ğŸ” val step 0: batch (16, 16, 2, 324, 1, 16) loss=1.1581
[25] train=0.4407  val=0.7505  RMSE(std)=[Qi:0.850, Qe:0.900, Î“:0.848]  RMSE(phys)=[Qi:60.548, Qe:81.789, Î“:36.721]  (1.2s)
âœ… Saved unified NN â†’ ./mnt/data/bin.cgyro.nn
ğŸŸ¦ Starting epoch 26/30 (train steps â‰ˆ 24)
  ... step 0/24  loss=0.3926  (0.1s since last print)
  â†˜ grad L2 norm â‰ˆ 4.595e+00 (batch 0)
  ... step 2/24  loss=0.3877  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 5.116e+00 (batch 2)
  ... step 4/24  loss=0.3524  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 4.283e+00 (batch 4)
  ... step 6/24  loss=0.2579  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 4.301e+00 (batch 6)
  ... step 8/24  loss=0.4420  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 4.678e+00 (batch 8)
  ... step 10/24  loss=0.4769  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 5.453e+00 (batch 10)
  ... step 12/24  loss=0.4232  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 4.437e+00 (batch 12)
  ... step 14/24  loss=0.3815  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 5.380e+00 (batch 14)
  ... step 16/24  loss=0.4790  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 4.487e+00 (batch 16)
  ... step 18/24  loss=0.3992  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 5.212e+00 (batch 18)
  ... step 20/24  loss=0.6099  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 5.305e+00 (batch 20)
  ... step 22/24  loss=0.3673  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 4.185e+00 (batch 22)
âœ… epoch 26 forward/backward done in 13.6s
  ğŸ” val step 0: batch (16, 16, 2, 324, 1, 16) loss=1.3095
[26] train=0.3909  val=0.7570  RMSE(std)=[Qi:0.854, Qe:0.907, Î“:0.847]  RMSE(phys)=[Qi:60.862, Qe:82.426, Î“:36.707]  (1.2s)
âœ… Saved unified NN â†’ ./mnt/data/bin.cgyro.nn
ğŸŸ¦ Starting epoch 27/30 (train steps â‰ˆ 24)
  ... step 0/24  loss=0.3873  (0.1s since last print)
  â†˜ grad L2 norm â‰ˆ 4.622e+00 (batch 0)
  ... step 2/24  loss=0.3737  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 5.121e+00 (batch 2)
  ... step 4/24  loss=0.3860  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 5.351e+00 (batch 4)
  ... step 6/24  loss=0.3244  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 4.028e+00 (batch 6)
  ... step 8/24  loss=0.3844  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 4.723e+00 (batch 8)
  ... step 10/24  loss=0.2779  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 3.657e+00 (batch 10)
  ... step 12/24  loss=0.3626  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 4.412e+00 (batch 12)
  ... step 14/24  loss=0.4690  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 5.062e+00 (batch 14)
  ... step 16/24  loss=0.2998  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 4.223e+00 (batch 16)
  ... step 18/24  loss=0.3876  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 6.239e+00 (batch 18)
  ... step 20/24  loss=0.2743  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 4.131e+00 (batch 20)
  ... step 22/24  loss=0.3050  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 4.841e+00 (batch 22)
âœ… epoch 27 forward/backward done in 13.6s
  ğŸ” val step 0: batch (16, 16, 2, 324, 1, 16) loss=1.0603
[27] train=0.3854  val=0.8969  RMSE(std)=[Qi:0.937, Qe:0.960, Î“:0.944]  RMSE(phys)=[Qi:66.725, Qe:87.253, Î“:40.890]  (1.2s)
âœ… Saved unified NN â†’ ./mnt/data/bin.cgyro.nn
ğŸŸ¦ Starting epoch 28/30 (train steps â‰ˆ 24)
  ... step 0/24  loss=0.4554  (0.1s since last print)
  â†˜ grad L2 norm â‰ˆ 5.842e+00 (batch 0)
  ... step 2/24  loss=0.2676  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 3.507e+00 (batch 2)
  ... step 4/24  loss=0.4554  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 5.213e+00 (batch 4)
  ... step 6/24  loss=0.2927  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 3.969e+00 (batch 6)
  ... step 8/24  loss=0.2877  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 3.767e+00 (batch 8)
  ... step 10/24  loss=0.3250  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 4.220e+00 (batch 10)
  ... step 12/24  loss=0.4823  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 6.751e+00 (batch 12)
  ... step 14/24  loss=0.3385  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 6.594e+00 (batch 14)
  ... step 16/24  loss=0.3103  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 4.738e+00 (batch 16)
  ... step 18/24  loss=0.3818  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 4.262e+00 (batch 18)
  ... step 20/24  loss=0.2653  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 4.822e+00 (batch 20)
  ... step 22/24  loss=0.2695  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 4.077e+00 (batch 22)
âœ… epoch 28 forward/backward done in 13.6s
  ğŸ” val step 0: batch (16, 16, 2, 324, 1, 16) loss=1.0852
[28] train=0.3513  val=0.8083  RMSE(std)=[Qi:0.891, Qe:0.916, Î“:0.889]  RMSE(phys)=[Qi:63.484, Qe:83.246, Î“:38.529]  (1.2s)
âœ… Saved unified NN â†’ ./mnt/data/bin.cgyro.nn
ğŸŸ¦ Starting epoch 29/30 (train steps â‰ˆ 24)
  ... step 0/24  loss=0.2668  (0.1s since last print)
  â†˜ grad L2 norm â‰ˆ 4.350e+00 (batch 0)
  ... step 2/24  loss=0.3246  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 4.832e+00 (batch 2)
  ... step 4/24  loss=0.2800  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 5.072e+00 (batch 4)
  ... step 6/24  loss=0.2530  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 3.676e+00 (batch 6)
  ... step 8/24  loss=0.3562  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 9.461e+00 (batch 8)
  ... step 10/24  loss=0.3685  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 3.624e+00 (batch 10)
  ... step 12/24  loss=0.2080  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 4.622e+00 (batch 12)
  ... step 14/24  loss=0.2831  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 3.692e+00 (batch 14)
  ... step 16/24  loss=0.3463  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 5.265e+00 (batch 16)
  ... step 18/24  loss=0.3813  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 6.101e+00 (batch 18)
  ... step 20/24  loss=0.2295  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 4.747e+00 (batch 20)
  ... step 22/24  loss=0.4297  (0.7s since last print)
  â†˜ grad L2 norm â‰ˆ 9.769e+00 (batch 22)
âœ… epoch 29 forward/backward done in 13.6s
  ğŸ” val step 0: batch (16, 16, 2, 324, 1, 16) loss=1.1232
[29] train=0.3419  val=0.7423  RMSE(std)=[Qi:0.851, Qe:0.889, Î“:0.844]  RMSE(phys)=[Qi:60.618, Qe:80.782, Î“:36.561]  (1.2s)
âœ… Saved unified NN â†’ ./mnt/data/bin.cgyro.nn
â¹ Early stopping after 29 epochs (no val improvement).
Saved metrics â†’ ./mnt/data/myrun_logs_ot3/metrics.csv
âœ… Final unified NN â†’ ./mnt/data/bin.cgyro.nn
âœ… Training complete. Artifacts in: ./mnt/data/myrun_logs_ot3
